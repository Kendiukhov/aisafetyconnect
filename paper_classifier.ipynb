{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c838e5b7",
   "metadata": {},
   "source": [
    "# Creating target categories list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82917811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('config/scraper_terms.json', 'r') as file:\n",
    "    taxonomy = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "289cd80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AI_Safety_Research_Mappings', 'technicalAiGovernance'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900a721d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Mechanistic_Interpretability', 'Scalable_Oversight', 'Adversarial_Robustness', 'Agent_Foundations', 'Alignment_Theory', 'Evaluations_Dangerous_Capabilities', 'Value_Learning_Alignment', 'Cooperative_AI', 'AI_Governance_Policy', 'Compute_Governance'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy['AI_Safety_Research_Mappings'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1c1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['assessment', 'access', 'verification', 'security', 'operationalization', 'ecosystemMonitoring'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy['technicalAiGovernance'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88790280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mechanistic_Interpretability',\n",
       " 'Scalable_Oversight',\n",
       " 'Adversarial_Robustness',\n",
       " 'Agent_Foundations',\n",
       " 'Alignment_Theory',\n",
       " 'Evaluations_Dangerous_Capabilities',\n",
       " 'Value_Learning_Alignment',\n",
       " 'Cooperative_AI',\n",
       " 'AI_Governance_Policy',\n",
       " 'Compute_Governance',\n",
       " 'Technical AI Governance']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_topics = list(taxonomy['AI_Safety_Research_Mappings'].keys())\n",
    "paper_topics.append('Technical AI Governance')\n",
    "paper_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f8342",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c40bd878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6ba47a6d-4b3c-4d69-bc1a-29d6445215ed",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Mesk√≥, E. Topol",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adri√† Garriga-Alonso",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edd112383ad494f5f2eba72b6f4ffae122ce61f</td>\n",
       "      <td>Interpretability in the Wild: a Circuit for In...</td>\n",
       "      <td>Kevin Wang, Alexandre Variengien, Arthur Conmy...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Research in mechanistic interpretability seeks...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>https://arxiv.org/pdf/2211.00593</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>644</td>\n",
       "      <td>1ff47a5be9a68e64e23ad2359d220370</td>\n",
       "      <td>10.48550/arXiv.2211.00593</td>\n",
       "      <td>2211.00593</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:28.298552+00:00</td>\n",
       "      <td>2025-09-29 20:02:03.480569+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0893549771094fac547432cb4f84e9605c911a86</td>\n",
       "      <td>The imperative for regulatory oversight of lar...</td>\n",
       "      <td>B. Mesk√≥, E. Topol</td>\n",
       "      <td>2023</td>\n",
       "      <td>The rapid advancements in artificial intellige...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>https://www.nature.com/articles/s41746-023-008...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>npj Digit. Medicine</td>\n",
       "      <td>Computer Science, Medicine, Medicine, Computer...</td>\n",
       "      <td>627</td>\n",
       "      <td>920cc7dbbd6a0bb608e11b65097d69ef</td>\n",
       "      <td>10.1038/s41746-023-00873-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f680d47a51a0e470fcb228bf0110c026535ead1b</td>\n",
       "      <td>Progress measures for grokking via mechanistic...</td>\n",
       "      <td>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neural networks often exhibit emergent behavio...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05217</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>517</td>\n",
       "      <td>953089e9556a8e0b37293683f8ff8807</td>\n",
       "      <td>10.48550/arXiv.2301.05217</td>\n",
       "      <td>2301.05217</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:13.784216+00:00</td>\n",
       "      <td>2025-09-29 20:01:43.521903+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefbd8b384a58f464827b19e30a6920ba976def9</td>\n",
       "      <td>Towards Automated Circuit Discovery for Mechan...</td>\n",
       "      <td>Arthur Conmy, Augustine N. Mavor-Parker, Aengu...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Through considerable effort and intuition, sev...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>https://arxiv.org/pdf/2304.14997</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>Neural Information Processing Systems</td>\n",
       "      <td>Computer Science, Computer Science, Engineering</td>\n",
       "      <td>356</td>\n",
       "      <td>a97a69c6234d51eeafeb50c9077b71ba</td>\n",
       "      <td>10.48550/arXiv.2304.14997</td>\n",
       "      <td>2304.14997</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:14.252982+00:00</td>\n",
       "      <td>2025-09-29 20:01:44.864490+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "1  6edd112383ad494f5f2eba72b6f4ffae122ce61f   \n",
       "2  0893549771094fac547432cb4f84e9605c911a86   \n",
       "3  f680d47a51a0e470fcb228bf0110c026535ead1b   \n",
       "4  eefbd8b384a58f464827b19e30a6920ba976def9   \n",
       "\n",
       "                                               title  \\\n",
       "0  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "1  Interpretability in the Wild: a Circuit for In...   \n",
       "2  The imperative for regulatory oversight of lar...   \n",
       "3  Progress measures for grokking via mechanistic...   \n",
       "4  Towards Automated Circuit Discovery for Mechan...   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0  David Rein, Betty Li Hou, Asa Cooper Stickland...  2023   \n",
       "1  Kevin Wang, Alexandre Variengien, Arthur Conmy...  2022   \n",
       "2                                 B. Mesk√≥, E. Topol  2023   \n",
       "3  Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...  2023   \n",
       "4  Arthur Conmy, Augustine N. Mavor-Parker, Aengu...  2023   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  We present GPQA, a challenging dataset of 448 ...   \n",
       "1  Research in mechanistic interpretability seeks...   \n",
       "2  The rapid advancements in artificial intellige...   \n",
       "3  Neural networks often exhibit emergent behavio...   \n",
       "4  Through considerable effort and intuition, sev...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1  https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2  https://www.semanticscholar.org/paper/08935497...   \n",
       "3  https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4  https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0               https://arxiv.org/pdf/2311.12022.pdf   \n",
       "1                   https://arxiv.org/pdf/2211.00593   \n",
       "2  https://www.nature.com/articles/s41746-023-008...   \n",
       "3                    http://arxiv.org/pdf/2301.05217   \n",
       "4                   https://arxiv.org/pdf/2304.14997   \n",
       "\n",
       "                                         scholar_url  \\\n",
       "0  https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1  https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2  https://www.semanticscholar.org/paper/08935497...   \n",
       "3  https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4  https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "\n",
       "                                               venue  \\\n",
       "0                                          arXiv.org   \n",
       "1  International Conference on Learning Represent...   \n",
       "2                                npj Digit. Medicine   \n",
       "3  International Conference on Learning Represent...   \n",
       "4              Neural Information Processing Systems   \n",
       "\n",
       "                                            keywords  citations  \\\n",
       "0  Computer Science, Biology, Physics, Computer S...       1065   \n",
       "1                 Computer Science, Computer Science        644   \n",
       "2  Computer Science, Medicine, Medicine, Computer...        627   \n",
       "3                 Computer Science, Computer Science        517   \n",
       "4    Computer Science, Computer Science, Engineering        356   \n",
       "\n",
       "                         title_hash                         doi    arxiv_id  \\\n",
       "0  d2390e0e97b7199093a42b27a5cf32bc                         NaN  2311.12022   \n",
       "1  1ff47a5be9a68e64e23ad2359d220370   10.48550/arXiv.2211.00593  2211.00593   \n",
       "2  920cc7dbbd6a0bb608e11b65097d69ef  10.1038/s41746-023-00873-0         NaN   \n",
       "3  953089e9556a8e0b37293683f8ff8807   10.48550/arXiv.2301.05217  2301.05217   \n",
       "4  a97a69c6234d51eeafeb50c9077b71ba   10.48550/arXiv.2304.14997  2304.14997   \n",
       "\n",
       "                                           s2_fields  \\\n",
       "0  [{'source': 'external', 'category': 'Computer ...   \n",
       "1  [{'source': 'external', 'category': 'Computer ...   \n",
       "2  [{'source': 'external', 'category': 'Computer ...   \n",
       "3  [{'source': 'external', 'category': 'Computer ...   \n",
       "4  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                         created_at                        updated_at  \n",
       "0  2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "1  2025-09-29 20:01:28.298552+00:00  2025-09-29 20:02:03.480569+00:00  \n",
       "2  2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "3  2025-09-29 20:01:13.784216+00:00  2025-09-29 20:01:43.521903+00:00  \n",
       "4  2025-09-29 20:01:14.252982+00:00  2025-09-29 20:01:44.864490+00:00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "academic_data = pd.read_csv('data/ai_safety_papers.csv')\n",
    "\n",
    "academic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e114a25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759, 17)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b7d29",
   "metadata": {},
   "source": [
    "# Categorization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f57c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "523e000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_topics.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee0eb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mechanistic_Interpretability', 'Scalable_Oversight', 'Adversarial_Robustness', 'Agent_Foundations', 'Alignment_Theory', 'Evaluations_Dangerous_Capabilities', 'Value_Learning_Alignment', 'Cooperative_AI', 'AI_Governance_Policy', 'Compute_Governance', 'Technical AI Governance', 'None']\n"
     ]
    }
   ],
   "source": [
    "print(paper_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e712431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class PaperCategory(BaseModel):\n",
    "    category: Literal[*paper_topics]= Field(description='The best category fit for AI safety. If no category matches, then None is used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3dddefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'category': {'description': 'The best category fit for AI safety. If no category matches, then None is used.',\n",
       "   'enum': ['Mechanistic_Interpretability',\n",
       "    'Scalable_Oversight',\n",
       "    'Adversarial_Robustness',\n",
       "    'Agent_Foundations',\n",
       "    'Alignment_Theory',\n",
       "    'Evaluations_Dangerous_Capabilities',\n",
       "    'Value_Learning_Alignment',\n",
       "    'Cooperative_AI',\n",
       "    'AI_Governance_Policy',\n",
       "    'Compute_Governance',\n",
       "    'Technical AI Governance',\n",
       "    'None'],\n",
       "   'title': 'Category',\n",
       "   'type': 'string'}},\n",
       " 'required': ['category'],\n",
       " 'title': 'PaperCategory',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PaperCategory.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d04360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8b9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e998aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_paper(title:str, authors:str, abstract:str, keywords:str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You should assign a single category to the paper given the informantion provided.\n",
    "    Our goal is to categorize papers related to AI Safety.\n",
    "    If the paper is not related to AI Safety, asign 'None' to its category.\n",
    "\n",
    "    # Paper Info\n",
    "\n",
    "    * title: {title}\n",
    "    * authors: {authors}\n",
    "    * abstract: {abstract}\n",
    "    * keywords: {keywords}\n",
    "\n",
    "    Categories available: {paper_topics}\n",
    "\n",
    "    Provide the response as JSON following this Pydantic schema: {PaperCategory.model_json_schema()}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model = 'gemini-2.5-flash',\n",
    "        contents = prompt,\n",
    "            config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": PaperCategory,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response.parsed.category\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "420d3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = categorizar_paper(\n",
    "    'GPQA: A Graduate-Level Google-Proof Q&A Benchmark',\n",
    "    'David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman',\n",
    "    'We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.',\n",
    "    'Computer Science, Biology, Physics, Computer Science, Chemistry'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bb1f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_data_categorizada = academic_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c22f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#academic_data_categorizada['AI Safety Category'] = academic_data.apply(\n",
    "#    lambda x: categorizar_paper(x['title'], x['authors'], x['abstract'], x['keywords']),\n",
    "#    axis = 1\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce189858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0fa6359d-8da6-4ff1-bf28-3666536a7501",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Mesk√≥, E. Topol",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adri√† Garriga-Alonso",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. ‚ÄîPRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human‚Äîin particular, in the gray matter of the cerebral cortex‚Äîis missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "10",
         "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Sam Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilƒó Luko≈°i≈´tƒó, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, C. McKinnon, Chris Olah, D. Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, John Kernion, Jamie Kerr, J. Mueller, Jeffrey Ladish, J. Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noem'i Mercado, Nova Dassarma, Robin Larson, Sam McCandlish, S. Kundu, Scott Johnston, Shauna Kravec, S. E. Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom B. Brown, T. Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Benjamin Mann, Jared Kaplan",
         "2022",
         "Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks.",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "https://arxiv.org/pdf/2211.03540",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "arXiv.org",
         "Computer Science, Computer Science, Linguistics",
         "149",
         "bd891ffa97410f74480c289f6510913c",
         "10.48550/arXiv.2211.03540",
         "2211.0354",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Linguistics'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "11",
         "f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "An Incentive-Compatible Energy Trading Framework for Neighborhood Area Networks With Shared Energy Storage",
         "C. Mediwaththe, M. Shaw, S. Halgamuge, David B. Smith, P. Scott",
         "2020",
         "Here, a novel energy trading system is proposed for demand-side management of a neighborhood area network (NAN) consisting of a shared energy storage (SES) provider, users with non-dispatchable energy generation, and an electricity retailer. In a leader‚Äìfollower Stackelberg game, the SES provider first maximizes their revenue by setting a price signal and trading energy with the grid. Then, by following the SES provider's actions, the retailer minimizes social cost for the users, i.e., the sum of the total users‚Äô cost when they interact with the SES and the total cost for supplying grid energy to the users. A pricing strategy, which incorporates mechanism design, is proposed to make the system incentive-compatible by rewarding users who disclose true energy usage information. A unique Stackelberg equilibrium is achieved where the SES provider's revenue is maximized and the user-level social cost is minimized, which also rewards the retailer. A case study with realistic energy demand and generation data demonstrates 28‚Äì45% peak demand reduction of the NAN, depending on the number of participating users, compared to a system without SES. Simulation results confirm that the retailer can also benefit financially, in addition to the SES provider and the users.",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "https://arxiv.org/pdf/2008.10384",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "IEEE Transactions on Sustainable Energy",
         "Engineering, Computer Science, Engineering, Economics, Environmental Science",
         "114",
         "203c35336c8ae692de21ba24e812a8e8",
         "10.1109/TSTE.2019.2895387",
         "2008.10384",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "12",
         "dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
         "Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",
         "2024",
         "As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in mathematical reasoning. It consists of 3,400 test cases, primarily focused on competition- and Olympiad-level math problems. Each test case contains a step-by-step solution with error location annotated by human experts. Models are required to identify the earliest step that contains an error, or conclude that all steps are correct. We conduct extensive evaluation on ProcessBench, involving two types of models: process reward models (PRMs) and critic models, where for the latter we prompt general language models to critique each solution step by step. We draw two main observations: (1) Existing PRMs typically fail to generalize to more challenging math problems beyond GSM8K and MATH. They underperform both critic models (i.e., prompted general language models) and our own trained PRM that is straightforwardly fine-tuned on the PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has demonstrated the critique capability competitive with the proprietary model GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We hope ProcessBench can foster future research in reasoning process assessment, paving the way toward scalable oversight of language models.",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "https://arxiv.org/pdf/2412.06559.pdf",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Mathematics, Computer Science",
         "104",
         "171b07e013043a4f09b897d234418135",
         "10.48550/arXiv.2412.06559",
         "2412.06559",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "13",
         "41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "A new science of emotion: implications for functional neurological disorder.",
         "Johannes Jungilligens, Sara Paredes-Echeverri, S. Popkirov, L. F. Barrett, D. Perez",
         "2022",
         "Functional neurological disorder (FND) reflects impairments in brain networks leading to distressing motor, sensory, and/or cognitive symptoms that demonstrate positive clinical signs on examination incongruent with other conditions. A central issue in historical and contemporary formulations of FND has been the mechanistic and etiological role of emotions. However, the debate has mostly omitted fundamental questions about the nature of emotions in the first place. In this perspective article, we first outline a set of relevant working principles of the brain (e.g., allostasis, predictive processing, interoception, and affect), followed by a focused review of the theory of constructed emotion to introduce a new understanding of what emotions are. Building on this theoretical framework, we formulate how altered emotion category construction can be an integral component of the pathophysiology of FND and related functional somatic symptoms. In doing so, we address several themes for the FND field including: 1) how energy regulation and the process of emotion category construction relate to symptom generation, including revisiting alexithymia, \"panic attack without panic\", dissociation, insecure attachment, and the influential role of life experiences; 2) re-interpret select neurobiological research findings in FND cohorts through the lens of the theory of constructed emotion to illustrate its potential mechanistic relevance; and 3) discuss therapeutic implications. While we continue to support that FND is mechanistically and etiologically heterogenous, consideration of how the theory of constructed emotion relates to the generation and maintenance of functional neurological and functional somatic symptoms offers an integrated viewpoint that cuts across neurology, psychiatry, psychology, and cognitive-affective neuroscience.",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "https://academic.oup.com/brain/article-pdf/145/8/2648/49120115/awac204.pdf",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "Brain : a journal of neurology",
         "Medicine, Psychology",
         "101",
         "a22d0fe84e5c1374d4c95b8a6396a8d9",
         "10.1093/brain/awac204",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "14",
         "1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "Targeting High Ability Entrepreneurs Using Community Information: Mechanism Design in the Field",
         "Reshmaan N. Hussam, Natalia Rigol, Benjamin N. Roth",
         "2022",
         "Identifying high-growth microentrepreneurs in low-income countries remains a challenge due to a scarcity of verifiable information. With a cash grant experiment in India we demonstrate that community knowledge can help target high-growth microentrepreneurs; while the average marginal return to capital in our sample is 9.4 percent per month, microentrepreneurs reported in the top third of the community are estimated to have marginal returns to capital between 24 percent and 30 percent per month. Further we find evidence that community members distort their predictions when they can influence the distribution of resources. Finally, we demonstrate that simple mechanisms can realign incentives for truthful reporting. (JEL D82, G21, I38, L25, L26, O12, O16)",
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         null,
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "The American Economic Review",
         "Business, Economics, Business",
         "97",
         "5643d31ff930134acee2c1071dac09b5",
         "10.1257/aer.20200751",
         null,
         "[{'source': 'external', 'category': 'Business'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Business'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "15",
         "1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "AI-Generated Incentive Mechanism and Full-Duplex Semantic Communications for Information Sharing",
         "Hongyang Du, Jiacheng Wang, Dusist Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim",
         "2023",
         "The next generation of Internet services, such as Metaverse, rely on mixed reality (MR) technology to provide immersive user experiences. However, limited computation power of MR headset-mounted devices (HMDs) hinders the deployment of such services. Therefore, we propose an efficient information-sharing scheme based on full-duplex device-to-device (D2D) semantic communications to address this issue. Our approach enables users to avoid heavy and repetitive computational tasks, such as artificial intelligence-generated content (AIGC) in the view images of all MR users. Specifically, a user can transmit the generated content and semantic information extracted from their view image to nearby users, who can then use this information to obtain the spatial matching of computation results under their view images. We analyze the performance of full-duplex D2D communications, including the achievable rate and bit error probability, by using generalized small-scale fading models. To facilitate semantic information sharing among users, we design a contract theoretic AI-generated incentive mechanism. The proposed diffusion model generates the optimal contract design, outperforming two deep reinforcement learning algorithms, i.e., proximal policy optimization and soft actor-critic algorithms. Our numerical analysis experiment proves the effectiveness of our proposed methods. The code for this paper is available at https://github.com/HongyangDu/SemSharing.",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "https://www.techrxiv.org/articles/preprint/AI-Generated_Incentive_Mechanism_and_Full-Duplex_Semantic_Communications_for_Information_Sharing/22209178/1/files/39468979.pdf",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "IEEE Journal on Selected Areas in Communications",
         "Engineering, Computer Science, Computer Science",
         "96",
         "4265596316b0f66567d76928f99a27fd",
         "10.1109/JSAC.2023.3287547",
         "2303.01896",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "16",
         "8efaf945b1b649bf905e0b9624d23760335aa614",
         "Uncertainty in Mechanism Design",
         "Giuseppe Lopomo, Luca Rigotti, Chris Shannon",
         "2021",
         "We consider mechanism design problems with Knightian uncertainty formalized using incomplete preferences, as in Bewley (1986). Without completeness, decision making depends on a set of beliefs, and an action is preferred to another if and only if it has larger expected utility for all beliefs in this set. We consider two natural notions of incentive compatibility in this setting: maximal incentive compatibility requires that no strategy has larger expected utility than reporting truthfully for all beliefs, while optimal incentive compatibility requires that reporting truthfully has larger expected utility than all other strategies for all beliefs. In a model with a continuum of types, we show that optimal incentive compatibility is equivalent to ex-post incentive compatibility under fairly general conditions on beliefs. In a model with a discrete type space, we characterize full extraction of rents generated from private information. We show that full extraction is generically possible with maximal incentive compatible mechanisms, but requires sufficient disagreement across types, which neither holds nor fails generically, with optimal incentive compatible mechanisms.",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         "https://arxiv.org/pdf/2108.12633",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         null,
         "Economics, Economics",
         "90",
         "36c493c55efcd610b95cacde98fab544",
         "10.2139/ssrn.3774581",
         "2108.12633",
         "[{'source': 'external', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "17",
         "6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
         "Atticus Geiger, D. Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah D. Goodman, Christopher Potts, Thomas F. Icard",
         "2023",
         "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "https://arxiv.org/pdf/2301.04709.pdf",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         null,
         "Computer Science, Computer Science, Philosophy",
         "80",
         "b3611594ff729546b6130e75d7322abd",
         null,
         "2301.04709",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:15.857258+00:00",
         "2025-09-29 20:01:45.343601+00:00"
        ],
        [
         "18",
         "0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Rationally Design a Sulfur Cathode with Solid‚ÄêPhase Conversion Mechanism for High Cycle‚ÄêStable Li‚ÄìS Batteries",
         "Bin He, Zhixiang Rao, Zexiao Cheng, Dongdong Liu, Danqi He, Jie Chen, Ziyun Miao, Lixia Yuan, Zhen Li, Yunhui Huang",
         "2021",
         "Solid‚Äìsolid reactions are very effective for solving the main challenges of lithium‚Äìsulfur (Li‚ÄìS) batteries, such as the shuttle effect of polysulfides and the high dependence of electrolyte consumption. However, the low sulfur content and sluggish redox kinetics of such cathodes dramatically limit the practical energy density of Li‚ÄìS batteries. Here a rationally designed hierarchical cathode to simultaneously solve above‚Äêmentioned challenges is reported. With nanoscale sulfur as the core, selenium‚Äêdoped sulfurized polyacrylonitrile (PAN/S7Se) as the shell and micron‚Äêscale secondary particle morphology, the proposed cathode realizes excellent solid‚Äìsolid reaction kinetics in a commercial carbonate electrolyte under high active species loading and a relatively low electrolyte/sulfur ratio. Such an approach provides a promising solution toward practical lithium sulfur batteries.",
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         null,
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Advanced Energy Materials",
         "Materials Science, Materials Science, Chemistry, Engineering",
         "78",
         "55c45ab4d8c970aeb6f70267874c70d1",
         "10.1002/aenm.202003690",
         null,
         "[{'source': 'external', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "19",
         "1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nonnegative spatial factorization applied to spatial genomics",
         "F. W. Townes, B. Engelhardt",
         "2022",
         "This paper presents nonnegative spatial factorization, a general framework for spatially aware and interpretable dimension reduction for high-dimensional spatial data, and its application to spatial transcriptomics analysis. Nonnegative matrix factorization (NMF) is widely used to analyze high-dimensional count data because, in contrast to real-valued alternatives such as factor analysis, it produces an interpretable parts-based representation. However, in applications such as spatial transcriptomics, NMF fails to incorporate known structure between observations. Here, we present nonnegative spatial factorization (NSF), a spatially-aware probabilistic dimension reduction model based on transformed Gaussian processes that naturally encourages sparsity and scales to tens of thousands of observations. NSF recovers ground truth factors more accurately than real-valued alternatives such as MEFISTO in simulations, and has lower out-of-sample prediction error than probabilistic NMF on three spatial transcriptomics datasets from mouse brain and liver. Since not all patterns of gene expression have spatial correlations, we also propose a hybrid extension of NSF that combines spatial and nonspatial components, enabling quantification of spatial importance for both observations and features. A TensorFlow implementation of NSF is available from https://github.com/willtownes/nsf-paper .",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "https://www.nature.com/articles/s41592-022-01687-w.pdf",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nature Methods",
         "Medicine, Computer Science, Biology",
         "72",
         "86d4a32c9b25afc8510904668935d1b6",
         "10.1038/s41592-022-01687-w",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "20",
         "7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration",
         "T. Bodrito, Alexandre Zouaoui, J. Chanussot, J. Mairal",
         "2021",
         "Hyperspectral imaging offers new perspectives for diverse applications, ranging from the monitoring of the environment using airborne or satellite remote sensing, precision farming, food safety, planetary exploration, or astrophysics. Unfortunately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth\"clean\"hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difficult, in contrast to traditional RGB imaging problems where deep models tend to shine. In this paper, we advocate instead for a hybrid approach based on sparse coding principles that retains the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data. We show on various denoising benchmarks that our method is computationally efficient and significantly outperforms the state of the art.",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "https://arxiv.org/pdf/2111.09708.pdf",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "Neural Information Processing Systems",
         "Computer Science, Engineering, Environmental Science, Computer Science, Engineering",
         "70",
         "043f0c78b6d43bf864f00572f1fa44be",
         null,
         "2111.09708",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "21",
         "70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Parcels and particles: Markov blankets in the brain",
         "Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr, Ines Hip'olito, L. Magrou, Adeel Razi",
         "2020",
         "At the inception of human brain mapping, two principles of functional anatomy underwrote most conceptions‚Äîand analyses‚Äîof distributed brain responses: namely, functional segregation and integration. There are currently two main approaches to characterizing functional integration. The first is a mechanistic modeling of connectomics in terms of directed effective connectivity that mediates neuronal message passing and dynamics on neuronal circuits. The second phenomenological approach usually characterizes undirected functional connectivity (i.e., measurable correlations), in terms of intrinsic brain networks, self-organized criticality, dynamical instability, and so on. This paper describes a treatment of effective connectivity that speaks to the emergence of intrinsic brain networks and critical dynamics. It is predicated on the notion of Markov blankets that play a fundamental role in the self-organization of far from equilibrium systems. Using the apparatus of the renormalization group, we show that much of the phenomenology found in network neuroscience is an emergent property of a particular partition of neuronal states, over progressively coarser scales. As such, it offers a way of linking dynamics on directed graphs to the phenomenology of intrinsic brain networks.",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "https://direct.mit.edu/netn/article-pdf/5/1/211/1889785/netn_a_00175.pdf",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Network Neuroscience",
         "Biology, Medicine, Computer Science, Physics",
         "70",
         "a28f67baf975f5d1bee41d5db29f602d",
         "10.1162/netn_a_00175",
         "2007.09704",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Physics'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "22",
         "980255db598dc210d6a784db247d159d3ea1cf3f",
         "Interpretable Multi-Modal Image Registration Network Based on Disentangled Convolutional Sparse Coding",
         "Xin Deng, Enpeng Liu, Shengxi Li, Yiping Duan, Mai Xu",
         "2023",
         "Multi-modal image registration aims to spatially align two images from different modalities to make their feature points match with each other. Captured by different sensors, the images from different modalities often contain many distinct features, which makes it challenging to find their accurate correspondences. With the success of deep learning, many deep networks have been proposed to align multi-modal images, however, they are mostly lack of interpretability. In this paper, we first model the multi-modal image registration problem as a disentangled convolutional sparse coding (DCSC) model. In this model, the multi-modal features that are responsible for alignment (RA features) are well separated from the features that are not responsible for alignment (nRA features). By only allowing the RA features to participate in the deformation field prediction, we can eliminate the interference of the nRA features to improve the registration accuracy and efficiency. The optimization process of the DCSC model to separate the RA and nRA features is then turned into a deep network, namely Interpretable Multi-modal Image Registration Network (InMIR-Net). To ensure the accurate separation of RA and nRA features, we further design an accompanying guidance network (AG-Net) to supervise the extraction of RA features in InMIR-Net. The advantage of InMIR-Net is that it provides a universal framework to tackle both rigid and non-rigid multi-modal image registration tasks. Extensive experimental results verify the effectiveness of our method on both rigid and non-rigid registrations on various multi-modal image datasets, including RGB/depth images, RGB/near-infrared (NIR) images, RGB/multi-spectral images, T1/T2 weighted magnetic resonance (MR) images and computed tomography (CT)/MR images. The codes are available at https://github.com/lep990816/Interpretable-Multi-modal-Image-Registration.",
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         null,
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         "IEEE Transactions on Image Processing",
         "Medicine, Computer Science, Computer Science, Engineering",
         "66",
         "540673f1f88c28586b4306e40b8d041f",
         "10.1109/TIP.2023.3240024",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "23",
         "41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Evolution of central neural circuits: state of the art and perspectives",
         "Ruair√≠ J. V. Roberts, S. Pop, L. Prieto-Godino",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Nature Reviews Neuroscience",
         "Medicine, Biology",
         "62",
         "a1837ac9580622b09b74da0595b69e74",
         "10.1038/s41583-022-00644-y",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "24",
         "79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Reducing the Cognitive Footprint of Brain Tumor Surgery",
         "N. Dadario, Bledi C. Brahimaj, J. Yeung, M. Sughrue",
         "2021",
         "The surgical management of brain tumors is based on the principle that the extent of resection improves patient outcomes. Traditionally, neurosurgeons have considered that lesions in ‚Äúnon-eloquent‚Äù cerebrum can be more aggressively surgically managed compared to lesions in ‚Äúeloquent‚Äù regions with more known functional relevance. Furthermore, advancements in multimodal imaging technologies have improved our ability to extend the rate of resection while minimizing the risk of inducing new neurologic deficits, together referred to as the ‚Äúonco-functional balance.‚Äù However, despite the common utilization of invasive techniques such as cortical mapping to identify eloquent tissue responsible for language and motor functions, glioma patients continue to present post-operatively with poor cognitive morbidity in higher-order functions. Such observations are likely related to the difficulty in interpreting the highly-dimensional information these technologies present to us regarding cognition in addition to our classically poor understanding of the functional and structural neuroanatomy underlying complex higher-order cognitive functions. Furthermore, reduction of the brain into isolated cortical regions without consideration of the complex, interacting brain networks which these regions function within to subserve higher-order cognition inherently prevents our successful navigation of true eloquent and non-eloquent cerebrum. Fortunately, recent large-scale movements in the neuroscience community, such as the Human Connectome Project (HCP), have provided updated neural data detailing the many intricate macroscopic connections between cortical regions which integrate and process the information underlying complex human behavior within a brain ‚Äúconnectome.‚Äù Connectomic data can provide us better maps on how to understand convoluted cortical and subcortical relationships between tumor and human cerebrum such that neurosurgeons can begin to make more informed decisions during surgery to maximize the onco-functional balance. However, connectome-based neurosurgery and related applications for neurorehabilitation are relatively nascent and require further work moving forward to optimize our ability to add highly valuable connectomic data to our surgical armamentarium. In this manuscript, we review four concepts with detailed examples which will help us better understand post-operative cognitive outcomes and provide a guide for how to utilize connectomics to reduce cognitive morbidity following cerebral surgery.",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "https://www.frontiersin.org/articles/10.3389/fneur.2021.711646/pdf",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Frontiers in Neurology",
         "Medicine, Medicine, Psychology",
         "61",
         "e26c187369f3f43944783d2070633188",
         "10.3389/fneur.2021.711646",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "25",
         "9854f38388b01991f461a25fefd1f67fecb9731f",
         "The Architecture of Human Memory: Insights from Human Single-Neuron Recordings",
         "Ueli Rutishauser, L. Reddy, F. Mormann, J. Sarnthein",
         "2020",
         "Deciphering the mechanisms of human memory is a central goal of neuroscience, both from the point of view of the fundamental biology of memory and for its translational relevance. Here, we review some contributions that recordings from neurons in humans implanted with electrodes for clinical purposes have made toward this goal. Recordings from the medial temporal lobe, including the hippocampus, reveal the existence of two classes of cells: those encoding highly selective and invariant representations of abstract concepts, and memory-selective cells whose activity is related to familiarity and episodic retrieval. Insights derived from observing these cells in behaving humans include that semantic representations are activated before episodic representations, that memory content and memory strength are segregated, and that the activity of both types of cells is related to subjective awareness as expected from a substrate for declarative memory. Visually selective cells can remain persistently active for several seconds, thereby revealing a cellular substrate for working memory in humans. An overarching insight is that the neural code of human memory is interpretable at the single-neuron level. Jointly, intracranial recording studies are starting to reveal aspects of the building blocks of human memory at the single-cell level. This work establishes a bridge to cellular-level work in animals on the one hand, and the extensive literature on noninvasive imaging in humans on the other hand. More broadly, this work is a step toward a detailed mechanistic understanding of human memory that is needed to develop therapies for human memory disorders.",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "https://www.jneurosci.org/content/jneuro/41/5/883.full.pdf",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "Journal of Neuroscience",
         "Medicine, Biology",
         "57",
         "ffce458267bc401455e35aa57197a0e9",
         "10.1523/JNEUROSCI.1648-20.2020",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "26",
         "85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "Mechanisms and mathematical modelling of ROS production by the mitochondrial electron transport chain.",
         "Sandeep Chenna, W. Koopman, J. Prehn, N. Connolly",
         "2022",
         "Reactive oxygen species (ROS) are recognised both as damaging molecules and intracellular signalling entities. In addition to its role in ATP generation, the mitochondrial electron transport chain (ETC) constitutes a relevant source of mitochondrial ROS, in particular during pathological conditions. Mitochondrial ROS homeostasis depends on species- and site-dependent ROS production, their bioreactivity, diffusion, and scavenging. However, our quantitative understanding of mitochondrial ROS homeostasis has thus far been hampered by technical limitations, including lack of truly site- and/or ROS-specific reporter molecules. In this context, the use of computational models is of great value to complement and interpret empirical data, as well as to predict variables that are difficult to assess experimentally. During the last decades, various mechanistic models of ETC-mediated ROS production have been developed. Although these often-complex models have generated novel insights, their parameterisation, analysis, and integration with other computational models is not straightforward. In contrast, phenomenological (sometimes termed \"minimal\") models use a relatively small set of equations to describe empirical relationship(s) between ROS-related and other parameters, and generally aim to explore system behaviour and generate hypotheses for experimental validation. In this review, we first discuss ETC-linked ROS homeostasis and introduce various detailed mechanistic models. Next, we present how bioenergetic parameters (e.g. NADH/NAD+ ratio, mitochondrial membrane potential) relate to site-specific ROS production within the ETC and how these relationships can be used to design minimal models of ROS homeostasis. Finally, we illustrate how minimal models have been applied to explore pathophysiological aspects of ROS.",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "https://figshare.com/articles/journal_contribution/Mechanisms_and_mathematical_modeling_of_ROS_production_by_the_mitochondrial_electron_transport_chain/20308254/1/files/36272712.pdf",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "American Journal of Physiology - Cell Physiology",
         "Medicine, Mathematics, Medicine",
         "56",
         "1a1ddb8e840f90dc765583768b6ce610",
         "10.1152/ajpcell.00455.2021",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Medicine'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "27",
         "8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "Open Problems in Mechanistic Interpretability",
         "Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, Stella Biderman, Adri√† Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, Eric Todd, Atticus Geiger, Mor Geva, Jesse Hoogland, Daniel Murfet, Thomas McGrath",
         "2025",
         "Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "https://arxiv.org/pdf/2501.16496.pdf",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "arXiv.org",
         "Computer Science, Computer Science, Philosophy",
         "52",
         "91df2ef4eadf077383bb23722f77664f",
         "10.48550/arXiv.2501.16496",
         "2501.16496",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:20.370015+00:00",
         "2025-09-29 20:01:51.158008+00:00"
        ],
        [
         "28",
         "1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "High-throughput genetic clustering of type 2 diabetes loci reveals heterogeneous mechanistic pathways of metabolic disease",
         "Hyunkyung Kim, K. Westerman, Kirk Smith, Joshua Chiou, J. Cole, T. Majarian, Marcin von Grotthuss, S. Kwak, Jaegil Kim, J. Mercader, J. Florez, K. Gaulton, A. Manning, M. Udler",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "https://link.springer.com/content/pdf/10.1007/s00125-022-05848-6.pdf",
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "Diabetologia",
         "Medicine, Medicine, Biology",
         "50",
         "6177f0d87f15e961d672e7d0629df25d",
         "10.1007/s00125-022-05848-6",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "29",
         "9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Non-negative Matrix Factorization: A Survey",
         "Jiangzhang Gan, Tong Liu, Li Li, Jilian Zhang",
         "2021",
         "\n Non-negative matrix factorization (NMF) is a powerful tool for data science researchers, and it has been successfully applied to data mining and machine learning community, due to its advantages such as simple form, good interpretability and less storage space. In this paper, we give a detailed survey on existing NMF methods, including a comprehensive analysis of their design principles, characteristics and drawbacks. In addition, we also discuss various variants of NMF methods and analyse properties and applications of these variants. Finally, we evaluate the performance of nine NMF methods through numerical experiments, and the results show that NMF methods perform well in clustering tasks.",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "https://mro.massey.ac.nz/bitstreams/7dbd6b5e-4d71-490a-b1b6-654e40181693/download",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Computer/law journal",
         "Computer Science, Mathematics, Computer Science, Mathematics",
         "50",
         "59e53699c3921eb318bb078214c055c5",
         "10.1093/COMJNL/BXAB103",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "30",
         "2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
         "Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, Ziyu Yao",
         "2024",
         "Mechanistic interpretability (MI) is an emerging sub-field of interpretability that seeks to understand a neural network model by reverse-engineering its internal computations. Recently, MI has garnered significant attention for interpreting transformer-based language models (LMs), resulting in many novel insights yet introducing new challenges. However, there has not been work that comprehensively reviews these insights and challenges, particularly as a guide for newcomers to this field. To fill this gap, we provide a comprehensive survey from a task-centric perspective, organizing the taxonomy of MI research around specific research questions or tasks. We outline the fundamental objects of study in MI, along with the techniques, evaluation methods, and key findings for each task in the taxonomy. In particular, we present a task-centric taxonomy as a roadmap for beginners to navigate the field by helping them quickly identify impactful problems in which they are most interested and leverage MI for their benefit. Finally, we discuss the current gaps in the field and suggest potential future directions for MI research.",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "https://arxiv.org/pdf/2407.02646.pdf",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "arXiv.org",
         "Computer Science, Computer Science",
         "50",
         "315f88620b6902745a1f3b994fd0e831",
         "10.48550/arXiv.2407.02646",
         "2407.02646",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.481838+00:00",
         "2025-09-29 20:01:43.961857+00:00"
        ],
        [
         "31",
         "7748391c938dc6f6a5bae6ac56f33faf37686714",
         "The rotational and divergent components of atmospheric circulation on tidally locked planets",
         "M. Hammond, N. Lewis",
         "2021",
         "Significance Tidally locked exoplanets have a permanent day side and night side. Understanding the atmospheric circulation on these planets is crucial for interpreting telescope observations and assessing their habitability. We show that the main components of the circulation‚Äîa jet going around the planet, stationary atmospheric waves, and direct flow from the day side to the night side‚Äîcan be separated using a simple mathematical decomposition. This decomposition will significantly aid future study of tidally locked atmospheres. As an illustration, we use it to quantify heat transport due to different components of the circulation. This analysis reveals that the direct day‚Äìnight component can dominate heat transport from the day side to the night side, even when the jet is strong. Tidally locked exoplanets likely host global atmospheric circulations with a superrotating equatorial jet, planetary-scale stationary waves, and thermally driven overturning circulation. In this work, we show that each of these features can be separated from the total circulation by using a Helmholtz decomposition, which splits the circulation into rotational (divergence-free) and divergent (vorticity-free) components. This technique is applied to the simulated circulation of a terrestrial planet and a gaseous hot Jupiter. For both planets, the rotational component comprises the equatorial jet and stationary waves, and the divergent component contains the overturning circulation. Separating out each component allows us to evaluate their spatial structure and relative contribution to the total flow. In contrast with previous work, we show that divergent velocities are not negligible when compared with rotational velocities and that divergent, overturning circulation takes the form of a single, roughly isotropic cell that ascends on the day side and descends on the night side. These conclusions are drawn for both the terrestrial case and the hot Jupiter. To illustrate the utility of the Helmholtz decomposition for studying atmospheric processes, we compute the contribution of each of the circulation components to heat transport from day side to night side. Surprisingly, we find that the divergent circulation dominates day‚Äìnight heat transport in the terrestrial case and accounts for around half of the heat transport for the hot Jupiter. The relative contributions of the rotational and divergent components to day‚Äìnight heat transport are likely sensitive to multiple planetary parameters and atmospheric processes and merit further study.",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "https://www.pnas.org/doi/pdf/10.1073/pnas.2022705118",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "Proceedings of the National Academy of Sciences of the United States of America",
         "Medicine, Physics, Physics, Environmental Science",
         "48",
         "abff31af6dcd5fe122dec99d8ade4088",
         "10.1073/pnas.2022705118",
         "2102.1176",
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "32",
         "02ad427b0d20fb976741e332f69c2fd00c751164",
         "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
         "Dan Braun, Jordan K. Taylor, Nicholas Goldowsky-Dill, Lee Sharkey",
         "2024",
         "Identifying the features learned by neural networks is a core challenge in mechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse, overcomplete dictionary that reconstructs a network's internal activations, have been used to identify these features. However, SAEs may learn more about the structure of the datatset than the computational structure of the network. There is therefore only indirect reason to believe that the directions found in these dictionaries are functionally important to the network. We propose end-to-end (e2e) sparse dictionary learning, a method for training SAEs that ensures the features learned are functionally important by minimizing the KL divergence between the output distributions of the original model and the model with SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a Pareto improvement: They explain more network performance, require fewer total features, and require fewer simultaneously active features per datapoint, all with no cost to interpretability. We explore geometric and qualitative differences between e2e SAE features and standard SAE features. E2e dictionary learning brings us closer to methods that can explain network behavior concisely and accurately. We release our library for training e2e SAEs and reproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "https://arxiv.org/pdf/2405.12241.pdf",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "46",
         "5dc8cc7891318ba16ac9c75ba5693d16",
         "10.48550/arXiv.2405.12241",
         "2405.12241",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "33",
         "f8029060e91209f048b3f9882f2cdd3607785ccd",
         "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability",
         "Ziming Liu, Eric Gan, Max Tegmark",
         "2023",
         "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that BIMT discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "http://arxiv.org/pdf/2305.08746",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "arXiv.org",
         "Computer Science, Physics, Mathematics, Biology, Computer Science",
         "46",
         "e067eaaff103d512e5af5296af1cdb46",
         "10.48550/arXiv.2305.08746",
         "2305.08746",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Physics'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.083803+00:00",
         "2025-09-29 20:01:45.576156+00:00"
        ],
        [
         "34",
         "e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "On scalable oversight with weak LLMs judging strong LLMs",
         "Zachary Kenton, Noah Y. Siegel, J'anos Kram'ar, Jonah Brown-Cohen, Samuel Albanie, Jannis Bulian, Rishabh Agarwal, David Lindner, Yunhao Tang, Noah D. Goodman, Rohin Shah",
         "2024",
         "Scalable oversight protocols aim to enable humans to accurately supervise superhuman AI. In this paper we study debate, where two AI's compete to convince a judge; consultancy, where a single AI tries to convince a judge that asks questions; and compare to a baseline of direct question-answering, where the judge just answers outright without the AI. We use large language models (LLMs) as both AI agents and as stand-ins for human judges, taking the judge models to be weaker than agent models. We benchmark on a diverse range of asymmetries between judges and agents, extending previous work on a single extractive QA task with information asymmetry, to also include mathematics, coding, logic and multimodal reasoning asymmetries. We find that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer. Comparing debate to direct question answering, the results depend on the type of task: in extractive QA tasks with information asymmetry debate outperforms direct question answering, but in other tasks without information asymmetry the results are mixed. Previous work assigned debaters/consultants an answer to argue for. When we allow them to instead choose which answer to argue for, we find judges are less frequently convinced by the wrong answer in debate than in consultancy. Further, we find that stronger debater models increase judge accuracy, though more modestly than in previous studies.",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "https://arxiv.org/pdf/2407.04622.pdf",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "44",
         "9c1fb35a2858675c73be477fb0ece0b3",
         "10.48550/arXiv.2407.04622",
         "2407.04622",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "35",
         "0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "PVC-SLP: Perceptual Vibrotactile-Signal Compression Based-on Sparse Linear Prediction",
         "Rania Hassen, Ba≈üak G√ºle√ßy√ºz, E. Steinbach",
         "2021",
         "Developing a signal compression technique that is able to achieve a low bit rate while maintaining high perceptual signal quality is a classical signal processing problem vigorously studied for audio, speech, image, and video type of signals. Yet, until recently, there has been limited effort directed toward the compression of vibrotactile signals, which represent a crucial element of rich touch (haptic) information. A vibrotactile signal; produced when stroking a textured surface with a tool-tip or bare-finger; like other signals contains a great deal of redundant and imperceptible information that can be exploited for efficient compression. This paper presents PVC-SLP, a vibrotactile perceptual coding approach. PVC-SLP employs a model of tactile sensitivity; called ASF (Acceleration Sensitivity Function); for perceptual coding. The ASF is inspired by the four channels model that mediate the perception of vibrotactile stimuli in the glabrous skin. The compression algorithm introduces sparsity constraints in a linear prediction scheme both on the residual and the predictor coefficients. The perceptual quantization of the residual is developed through the use of ASF. The quantization parameters of the residual and the predictor coefficients were jointly optimized; by means of both squared error and perceptual quality measures; to find the sweet spot of the rate-distortion curve. PVC-SLP coding performance is evaluated using two publicly available databases that collectively comprise 1281 vibrotactile signals covering 193 material classes. Furthermore, we compare PVC-SLP with a recent vibrotactile compression method and show that PVC-SLP perceptually outperforms existing method by a sizable margin. Most recently, PVC-SLP has been selected to become part of the haptic codec standard currently under preparation by IEEE P1918.1.1, aka Haptic Codecs for the Tactile Internet.",
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         null,
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "IEEE transactions on multimedia",
         "Computer Science, Computer Science",
         "44",
         "99db78f4eb2492099f409ede6822e163",
         "10.1109/tmm.2020.3042674",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "36",
         "ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Hybrid modelling of water resource recovery facilities: status and opportunities.",
         "M. Y. Schneider, Ward Quaghebeur, Sina Borzooei, A. Froemelt, Feiyi Li, R. Saagi, Matthew John Wade, Jun‚ÄêJie Zhu, E. Torfs",
         "2022",
         "Mathematical modelling is an indispensable tool to support water resource recovery facility (WRRF) operators and engineers with the ambition of creating a truly circular economy and assuring a sustainable future. Despite the successful application of mechanistic models in the water sector, they show some important limitations and do not fully profit from the increasing digitalisation of systems and processes. Recent advances in data-driven methods have provided options for harnessing the power of Industry 4.0, but they are often limited by the lack of interpretability and extrapolation capabilities. Hybrid modelling (HM) combines these two modelling paradigms and aims to leverage both the rapidly increasing volumes of data collected, as well as the continued pursuit of greater process understanding. Despite the potential of HM in a sector that is undergoing a significant digital and cultural transformation, the application of hybrid models remains vague. This article presents an overview of HM methodologies applied to WRRFs and aims to stimulate the wider adoption and development of HM. We also highlight challenges and research needs for HM design and architecture, good modelling practice, data assurance, and software compatibility. HM is a paradigm for WRRF modelling to transition towards a more resource-efficient, resilient, and sustainable future.",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "https://iwaponline.com/wst/article-pdf/85/9/2503/1064960/wst085092503.pdf",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Water Science and Technology",
         "Medicine, Environmental Science, Engineering",
         "42",
         "46d3af83fe7d76740b0f84253214e6c5",
         "10.2166/wst.2022.115",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "37",
         "63a87feede94433b44b2c2b194e5902c3c5158f2",
         "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation",
         "Aaditya K. Singh, Ted Moskovitz, Felix Hill, S. C. Chan, Andrew M. Saxe",
         "2024",
         "In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning -- the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By clamping subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to\"go right\"for an induction head.",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "https://arxiv.org/pdf/2404.07129.pdf",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "International Conference on Machine Learning",
         "Computer Science",
         "41",
         "160d0353f52a1dccf893bdae96e30380",
         "10.48550/arXiv.2404.07129",
         "2404.07129",
         "[{'source': 'external', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.524693+00:00",
         "2025-09-29 20:02:01.691828+00:00"
        ],
        [
         "38",
         "680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
         "Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe",
         "2024",
         "How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate this kind of easy-to-hard generalization using simple finetuning methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect easy data rather than hard data for finetuning, since hard data is generally noisier and costlier to collect. Our experiments use open models up to 70b in size and four publicly available question-answering datasets with questions ranging in difficulty from 3rd grade science questions to college level STEM questions and general-knowledge trivia. We conclude that easy-to-hard generalization in LMs is surprisingly strong for the tasks studied. Our code is available at: https://github.com/allenai/easy-to-hard-generalization",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "https://arxiv.org/pdf/2401.06751.pdf",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "39",
         "fd9c2650583db7080c93fe4ad97bc16a",
         "10.48550/arXiv.2401.06751",
         "2401.06751",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "39",
         "d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "Multi-Modal Convolutional Dictionary Learning",
         "Fangyuan Gao, Xin Deng, Mai Xu, Jingyi Xu, P. Dragotti",
         "2022",
         "Convolutional dictionary learning has become increasingly popular in signal and image processing for its ability to overcome the limitations of traditional patch-based dictionary learning. Although most studies on convolutional dictionary learning mainly focus on the unimodal case, real-world image processing tasks usually involve images from multiple modalities, e.g., visible and near-infrared (NIR) images. Thus, it is necessary to explore convolutional dictionary learning across different modalities. In this paper, we propose a novel multi-modal convolutional dictionary learning algorithm, which efficiently correlates different image modalities and fully considers neighborhood information at the image level. In this model, each modality is represented by two convolutional dictionaries, in which one dictionary is for common feature representation and the other is for unique feature representation. The model is constrained by the requirement that the convolutional sparse representations (CSRs) for the common features should be the same across different modalities, considering that these images are captured from the same scene. We propose a new training method based on the alternating direction method of multipliers (ADMM) to alternatively learn the common and unique dictionaries in the discrete Fourier transform (DFT) domain. We show that our model converges in less than 20 iterations between the convolutional dictionary updating and the CSRs calculation. The effectiveness of the proposed dictionary learning algorithm is demonstrated on various multimodal image processing tasks, achieves better performance than both dictionary learning methods and deep learning based methods with limited training data.",
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         null,
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "IEEE Transactions on Image Processing",
         "Computer Science, Medicine, Computer Science, Environmental Science",
         "39",
         "e087496c780892e3207eb83d96645f87",
         "10.1109/TIP.2022.3141251",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "40",
         "2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "Diffusion Models for Audio Restoration: A review [Special Issue On Model-Based and Data-Driven Audio Signal Processing]",
         "Jean-Marie Lemercier, Julius Richter, Simon Welker, Eloi Moliner, V. V√§lim√§ki, Timo Gerkmann",
         "2024",
         "With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift toward data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged as powerful techniques for learning complex data distributions. However, relying solely on DNN-based learning approaches carries the risk of reducing interpretability, particularly when employing end-to-end models. Nonetheless, data-driven approaches allow more flexibility in comparison to statistical model-based frameworks, whose performance depends on distributional and statistical assumptions that can be difficult to guarantee. Here, we aim to show that diffusion models can combine the best of both worlds and offer the opportunity to design audio restoration algorithms with a good degree of interpretability and a remarkable performance in terms of sound quality. In this article, we review the use of diffusion models for audio restoration. We explain the diffusion formalism and its application to the conditional generation of clean audio signals. We believe that diffusion models open an exciting field of research with the potential to spawn new audio restoration algorithms that are natural-sounding and remain robust in difficult acoustic situations.",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "https://arxiv.org/pdf/2402.09821.pdf",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Computer Science, Engineering",
         "37",
         "e188cd7a5af5364280ca4c2fd54355b5",
         "10.1109/MSP.2024.3445871",
         "2402.09821",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "41",
         "5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Interpretability of artificial neural network models in artificial intelligence versus neuroscience",
         "Kohitij Kar, Simon Kornblith, Evelina Fedorenko",
         "2022",
         "Computationally explicit hypotheses of brain function derived from machine learning (ML)-based models have recently revolutionized neuroscience. Despite the unprecedented ability of these artificial neural networks (ANNs) to capture responses in biological neural networks (brains), and our full access to all internal model components (unlike the brain), ANNs are often referred to as black-boxes with limited interpretability. Interpretability, however, is a multi-faceted construct that is used differently across fields. In particular, interpretability, or explainability, efforts in Artificial Intelligence (AI) focus on understanding how different model components contribute to its output (i.e., decision making). In contrast, the neuroscientific interpretability of ANNs requires explicit alignment between model components and neuroscientific constructs (e.g., different brain areas or phenomena, like recurrence or top-down feedback). Given the widespread calls to improve the interpretability of AI systems, we here highlight these different notions of interpretability and argue that the neuroscientific interpretability of ANNs can be pursued in parallel with, but independently from, the ongoing efforts in AI. Certain ML techniques (e.g., deep dream) can be leveraged in both fields, to ask what stimulus optimally activates the specific model features (feature visualization by optimization), or how different features contribute to the model's output (feature attribution). However, without appropriate brain alignment, certain features will remain uninterpretable to neuroscientists.",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "https://arxiv.org/pdf/2206.03951",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Nat. Mac. Intell.",
         "Computer Science, Biology, Computer Science, Philosophy",
         "36",
         "7387e8bb067dd5c477ba0c3fe39df6a4",
         "10.1038/s42256-022-00592-3",
         "2206.03951",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:59.476166+00:00",
         "2025-09-29 20:01:59.476166+00:00"
        ],
        [
         "42",
         "c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Application of non-negative matrix factorization in oncology: one approach for establishing precision medicine",
         "Ryuji Hamamoto, Ken Takasawa, Hidenori Machino, Kazuma Kobayashi, Satoshi Takahashi, Amina Bolatkan, Norio Shinkai, Akira Sakai, R. Aoyama, Masayoshi Yamada, Ken Asada, M. Komatsu, Koji Okamoto, H. Kameoka, S. Kaneko",
         "2022",
         "Abstract The increase in the expectations of artificial intelligence (AI) technology has led to machine learning technology being actively used in the medical field. Non-negative matrix factorization (NMF) is a machine learning technique used for image analysis, speech recognition, and language processing; recently, it is being applied to medical research. Precision medicine, wherein important information is extracted from large-scale medical data to provide optimal medical care for every individual, is considered important in medical policies globally, and the application of machine learning techniques to this end is being handled in several ways. NMF is also introduced differently because of the characteristics of its algorithms. In this review, the importance of NMF in the field of medicine, with a focus on the field of oncology, is described by explaining the mathematical science of NMF and the characteristics of the algorithm, providing examples of how NMF can be used to establish precision medicine, and presenting the challenges of NMF. Finally, the direction regarding the effective use of NMF in the field of oncology is also discussed.",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "https://academic.oup.com/bib/article-pdf/23/4/bbac246/45017265/bbac246.pdf",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Briefings Bioinform.",
         "Medicine, Computer Science, Medicine, Computer Science",
         "35",
         "cea76d54281f58364f2cdbd89a30795c",
         "10.1093/bib/bbac246",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "43",
         "59b988fda9c1737465921a9bade731d511500718",
         "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
         "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
         "2024",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         "arXiv.org",
         "Computer Science, Psychology",
         "35",
         "ba9e6b607a4904c9b0fa98dd7fb06b26",
         "10.48550/arXiv.2408.01416",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:40.147869+00:00",
         "2025-09-30 00:45:40.147869+00:00"
        ],
        [
         "44",
         "b437d4398b443234aa253156404e12326ba899a5",
         "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
         "Mitchell Ostrow, Adam Eisen, L. Kozachkov, I. Fiete",
         "2023",
         "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "https://arxiv.org/pdf/2306.10168",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "Neural Information Processing Systems",
         "Biology, Computer Science, Computer Science",
         "35",
         "fada21b27d9df8d40aef2026b27654ac",
         "10.48550/arXiv.2306.10168",
         "2306.10168",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:41.941797+00:00",
         "2025-09-29 20:01:41.941797+00:00"
        ],
        [
         "45",
         "557dce8787129ca623fcb2cca2e76e9920347b69",
         "Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms",
         "Alireza Fallah, A. Makhdoumi, Azarakhsh Malekian, A. Ozdaglar",
         "2022",
         "We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "https://arxiv.org/pdf/2201.03968.pdf",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "ACM Conference on Economics and Computation",
         "Computer Science, Computer Science, Economics",
         "34",
         "6f74ae4cba716c1607ae234c9694a38e",
         "10.1145/3490486.3538329",
         "2201.03968",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "46",
         "d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP",
         "Vedant Palit, Rohan Pandey, Aryaman Arora, Paul Pu Liang",
         "2023",
         "Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have identified neural circuits that copy spans of text, capture factual knowledge, and more, they remain unusable for multimodal models since adapting these tools to the vision-language domain requires considerable architectural changes. In this work, we adapt a unimodal causal tracing tool to BLIP to enable the study of the neural mechanisms underlying image-conditioned text generation. We demonstrate our approach on a visual question answering dataset, highlighting the causal relevance of later layer representations for all tokens. Furthermore, we release our BLIP causal tracing tool as open source to enable further experimentation in vision-language mechanistic interpretability by the community. Our code is available at this URL.",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "https://arxiv.org/pdf/2308.14179",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
         "Computer Science, Computer Science",
         "34",
         "9cf5a58ea2e4185711ce7b8677794afc",
         "10.1109/ICCVW60793.2023.00307",
         "2308.14179",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.758641+00:00",
         "2025-09-29 20:01:46.494319+00:00"
        ],
        [
         "47",
         "6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning",
         "Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang",
         "2023",
         "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "https://arxiv.org/pdf/2311.07954.pdf",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "North American Chapter of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "32",
         "c392393c2dc5c78e3dc51c1d7ab07def",
         "10.48550/arXiv.2311.07954",
         "2311.07954",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "48",
         "f3658afcd181e4078e1e96ff86eac224fd92faab",
         "ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability",
         "ZhongXiang Sun, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu, Xiao Zhang, Weijie Yu, Han Li",
         "2024",
         "Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric (internal) knowledge. However, even with accurate and relevant retrieved content, RAG models can still produce hallucinations by generating outputs that conflict with the retrieved information. Detecting such hallucinations requires disentangling how Large Language Models (LLMs) utilize external and parametric knowledge. Current detection methods often focus on one of these mechanisms or without decoupling their intertwined effects, making accurate detection difficult. In this paper, we investigate the internal mechanisms behind hallucinations in RAG scenarios. We discover hallucinations occur when the Knowledge FFNs in LLMs overemphasize parametric knowledge in the residual stream, while Copying Heads fail to effectively retain or integrate external knowledge from retrieved content. Based on these findings, we propose ReDeEP, a novel method that detects hallucinations by decoupling LLM's utilization of external context and parametric knowledge. Our experiments show that ReDeEP significantly improves RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by modulating the contributions of Knowledge FFNs and Copying Heads.",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "https://arxiv.org/pdf/2410.11414.pdf",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "32",
         "ac30ae75b45154f43567d24b201cee78",
         "10.48550/arXiv.2410.11414",
         "2410.11414",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.714672+00:00",
         "2025-09-29 20:01:43.739899+00:00"
        ],
        [
         "49",
         "7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Orthogonal Non-negative Tensor Factorization based Multi-view Clustering",
         "Jing Li, Quanxue Gao, Qianqian Wang, Ming Yang, Wei Xia",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Mathematics",
         "31",
         "20a966da2d81a77230eb9bf78d244a46",
         null,
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 759
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edd112383ad494f5f2eba72b6f4ffae122ce61f</td>\n",
       "      <td>Interpretability in the Wild: a Circuit for In...</td>\n",
       "      <td>Kevin Wang, Alexandre Variengien, Arthur Conmy...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Research in mechanistic interpretability seeks...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>https://arxiv.org/pdf/2211.00593</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>644</td>\n",
       "      <td>1ff47a5be9a68e64e23ad2359d220370</td>\n",
       "      <td>10.48550/arXiv.2211.00593</td>\n",
       "      <td>2211.00593</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:28.298552+00:00</td>\n",
       "      <td>2025-09-29 20:02:03.480569+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0893549771094fac547432cb4f84e9605c911a86</td>\n",
       "      <td>The imperative for regulatory oversight of lar...</td>\n",
       "      <td>B. Mesk√≥, E. Topol</td>\n",
       "      <td>2023</td>\n",
       "      <td>The rapid advancements in artificial intellige...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>https://www.nature.com/articles/s41746-023-008...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>npj Digit. Medicine</td>\n",
       "      <td>Computer Science, Medicine, Medicine, Computer...</td>\n",
       "      <td>627</td>\n",
       "      <td>920cc7dbbd6a0bb608e11b65097d69ef</td>\n",
       "      <td>10.1038/s41746-023-00873-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f680d47a51a0e470fcb228bf0110c026535ead1b</td>\n",
       "      <td>Progress measures for grokking via mechanistic...</td>\n",
       "      <td>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neural networks often exhibit emergent behavio...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05217</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>517</td>\n",
       "      <td>953089e9556a8e0b37293683f8ff8807</td>\n",
       "      <td>10.48550/arXiv.2301.05217</td>\n",
       "      <td>2301.05217</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:13.784216+00:00</td>\n",
       "      <td>2025-09-29 20:01:43.521903+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefbd8b384a58f464827b19e30a6920ba976def9</td>\n",
       "      <td>Towards Automated Circuit Discovery for Mechan...</td>\n",
       "      <td>Arthur Conmy, Augustine N. Mavor-Parker, Aengu...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Through considerable effort and intuition, sev...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>https://arxiv.org/pdf/2304.14997</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>Neural Information Processing Systems</td>\n",
       "      <td>Computer Science, Computer Science, Engineering</td>\n",
       "      <td>356</td>\n",
       "      <td>a97a69c6234d51eeafeb50c9077b71ba</td>\n",
       "      <td>10.48550/arXiv.2304.14997</td>\n",
       "      <td>2304.14997</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:14.252982+00:00</td>\n",
       "      <td>2025-09-29 20:01:44.864490+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2</td>\n",
       "      <td>Mechanistic Interpretability of GPT-like Model...</td>\n",
       "      <td>Anurag Mishra</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability research seeks to...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.17073.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>3771d70ffd60f9c3f692d0e8f989f74d</td>\n",
       "      <td>10.48550/arXiv.2505.17073</td>\n",
       "      <td>2505.17073</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.786419+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.195754+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>663292eaef24c22c0692f1b4a9120d24662d7fc7</td>\n",
       "      <td>Causal Intervention Framework for Variational ...</td>\n",
       "      <td>Dip Roy</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability of deep learning ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.03530.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>2f8d578153eefbc0b11361f9e71a0194</td>\n",
       "      <td>10.48550/arXiv.2505.03530</td>\n",
       "      <td>2505.03530</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.332786+00:00</td>\n",
       "      <td>2025-09-29 20:01:57.450585+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>49072764553763f1686121fd03e3dadda259f273</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>2024</td>\n",
       "      <td>Recent research (arXiv:2310.11453, arXiv:2402....</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>https://arxiv.org/pdf/2405.17703.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>81612dabd9dc5de68fc08c32d1ed9a14</td>\n",
       "      <td>10.48550/arXiv.2405.17703</td>\n",
       "      <td>2405.17703</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.685040+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.957507+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_id  \\\n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "1    6edd112383ad494f5f2eba72b6f4ffae122ce61f   \n",
       "2    0893549771094fac547432cb4f84e9605c911a86   \n",
       "3    f680d47a51a0e470fcb228bf0110c026535ead1b   \n",
       "4    eefbd8b384a58f464827b19e30a6920ba976def9   \n",
       "..                                        ...   \n",
       "754  f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2   \n",
       "755  663292eaef24c22c0692f1b4a9120d24662d7fc7   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "757  49072764553763f1686121fd03e3dadda259f273   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "1    Interpretability in the Wild: a Circuit for In...   \n",
       "2    The imperative for regulatory oversight of lar...   \n",
       "3    Progress measures for grokking via mechanistic...   \n",
       "4    Towards Automated Circuit Discovery for Mechan...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic Interpretability of GPT-like Model...   \n",
       "755  Causal Intervention Framework for Variational ...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "757  Mechanistic Interpretability of Binary and Ter...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                               authors  year  \\\n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...  2023   \n",
       "1    Kevin Wang, Alexandre Variengien, Arthur Conmy...  2022   \n",
       "2                                   B. Mesk√≥, E. Topol  2023   \n",
       "3    Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...  2023   \n",
       "4    Arthur Conmy, Augustine N. Mavor-Parker, Aengu...  2023   \n",
       "..                                                 ...   ...   \n",
       "754                                      Anurag Mishra  2025   \n",
       "755                                            Dip Roy  2025   \n",
       "756                    Marcos Florencio, Thomas Barton  2025   \n",
       "757                                           Jason Li  2024   \n",
       "758                     Tristan Trim, Triston Grayston  2024   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    We present GPQA, a challenging dataset of 448 ...   \n",
       "1    Research in mechanistic interpretability seeks...   \n",
       "2    The rapid advancements in artificial intellige...   \n",
       "3    Neural networks often exhibit emergent behavio...   \n",
       "4    Through considerable effort and intuition, sev...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic interpretability research seeks to...   \n",
       "755  Mechanistic interpretability of deep learning ...   \n",
       "756  Architectural obfuscation - e.g., permuting hi...   \n",
       "757  Recent research (arXiv:2310.11453, arXiv:2402....   \n",
       "758  This paper explores the mechanistic interpreta...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                               pdf_url  \\\n",
       "0                 https://arxiv.org/pdf/2311.12022.pdf   \n",
       "1                     https://arxiv.org/pdf/2211.00593   \n",
       "2    https://www.nature.com/articles/s41746-023-008...   \n",
       "3                      http://arxiv.org/pdf/2301.05217   \n",
       "4                     https://arxiv.org/pdf/2304.14997   \n",
       "..                                                 ...   \n",
       "754               https://arxiv.org/pdf/2505.17073.pdf   \n",
       "755               https://arxiv.org/pdf/2505.03530.pdf   \n",
       "756               https://arxiv.org/pdf/2506.18053.pdf   \n",
       "757               https://arxiv.org/pdf/2405.17703.pdf   \n",
       "758               https://arxiv.org/pdf/2411.00867.pdf   \n",
       "\n",
       "                                           scholar_url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                                 venue  \\\n",
       "0                                            arXiv.org   \n",
       "1    International Conference on Learning Represent...   \n",
       "2                                  npj Digit. Medicine   \n",
       "3    International Conference on Learning Represent...   \n",
       "4                Neural Information Processing Systems   \n",
       "..                                                 ...   \n",
       "754                                          arXiv.org   \n",
       "755                                          arXiv.org   \n",
       "756                                          arXiv.org   \n",
       "757                                          arXiv.org   \n",
       "758                                          arXiv.org   \n",
       "\n",
       "                                              keywords  citations  \\\n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "1                   Computer Science, Computer Science        644   \n",
       "2    Computer Science, Medicine, Medicine, Computer...        627   \n",
       "3                   Computer Science, Computer Science        517   \n",
       "4      Computer Science, Computer Science, Engineering        356   \n",
       "..                                                 ...        ...   \n",
       "754                 Computer Science, Computer Science          0   \n",
       "755                 Computer Science, Computer Science          0   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "757                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "\n",
       "                           title_hash                         doi    arxiv_id  \\\n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                         NaN  2311.12022   \n",
       "1    1ff47a5be9a68e64e23ad2359d220370   10.48550/arXiv.2211.00593  2211.00593   \n",
       "2    920cc7dbbd6a0bb608e11b65097d69ef  10.1038/s41746-023-00873-0         NaN   \n",
       "3    953089e9556a8e0b37293683f8ff8807   10.48550/arXiv.2301.05217  2301.05217   \n",
       "4    a97a69c6234d51eeafeb50c9077b71ba   10.48550/arXiv.2304.14997  2304.14997   \n",
       "..                                ...                         ...         ...   \n",
       "754  3771d70ffd60f9c3f692d0e8f989f74d   10.48550/arXiv.2505.17073  2505.17073   \n",
       "755  2f8d578153eefbc0b11361f9e71a0194   10.48550/arXiv.2505.03530  2505.03530   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34   10.48550/arXiv.2506.18053  2506.18053   \n",
       "757  81612dabd9dc5de68fc08c32d1ed9a14   10.48550/arXiv.2405.17703  2405.17703   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82   10.48550/arXiv.2411.00867  2411.00867   \n",
       "\n",
       "                                             s2_fields  \\\n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "1    [{'source': 'external', 'category': 'Computer ...   \n",
       "2    [{'source': 'external', 'category': 'Computer ...   \n",
       "3    [{'source': 'external', 'category': 'Computer ...   \n",
       "4    [{'source': 'external', 'category': 'Computer ...   \n",
       "..                                                 ...   \n",
       "754  [{'source': 'external', 'category': 'Computer ...   \n",
       "755  [{'source': 'external', 'category': 'Computer ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "757  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                           created_at                        updated_at  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "1    2025-09-29 20:01:28.298552+00:00  2025-09-29 20:02:03.480569+00:00  \n",
       "2    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "3    2025-09-29 20:01:13.784216+00:00  2025-09-29 20:01:43.521903+00:00  \n",
       "4    2025-09-29 20:01:14.252982+00:00  2025-09-29 20:01:44.864490+00:00  \n",
       "..                                ...                               ...  \n",
       "754  2025-09-29 20:01:25.786419+00:00  2025-09-29 20:01:55.195754+00:00  \n",
       "755  2025-09-29 20:01:25.332786+00:00  2025-09-29 20:01:57.450585+00:00  \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00  \n",
       "757  2025-09-29 20:01:19.685040+00:00  2025-09-29 20:01:48.957507+00:00  \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00  \n",
       "\n",
       "[759 rows x 17 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_data_categorizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a58d7",
   "metadata": {},
   "source": [
    "# Creating a batch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eb655b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n"
     ]
    }
   ],
   "source": [
    "for index, row in academic_data.iterrows():\n",
    "    print(row['title'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "021de0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "\n",
    "for index, row in academic_data.iterrows():\n",
    "    single_request = {}\n",
    "\n",
    "    single_request['contents']  = [{\n",
    "        'parts': [{\n",
    "            'text': f\"\"\"\n",
    "                # Paper Info\n",
    "\n",
    "                * title: {row['title']}\n",
    "                * authors: {row['authors']}\n",
    "                * abstract: {row['abstract']}\n",
    "                * keywords: {row['keywords']}\n",
    "                \"\"\"\n",
    "        }]\n",
    "    }]\n",
    "\n",
    "    single_request['config'] = {\n",
    "        'system_instruction': {'parts': [{\n",
    "            'text': \"\"\"\n",
    "                You should assign a single category to the paper given the informantion provided.\n",
    "                Our goal is to categorize papers related to AI Safety.\n",
    "                If the paper is not related to AI Safety, asign 'None' to its category.\n",
    "\n",
    "                Categories available: {paper_topics}\n",
    "\n",
    "                Provide the response as JSON following this Pydantic schema: {PaperCategory.model_json_schema()}\n",
    "            \"\"\"\n",
    "        }]},\n",
    "        'response_mime_type': 'application/json',\n",
    "        'response_schema': PaperCategory\n",
    "    }\n",
    "    \n",
    "    requests.append(single_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea44ea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contents': [{'parts': [{'text': '\\n                # Paper Info\\n\\n                * title: GPQA: A Graduate-Level Google-Proof Q&A Benchmark\\n                * authors: David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman\\n                * abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.\\n                * keywords: Computer Science, Biology, Physics, Computer Science, Chemistry\\n                '}]}], 'config': {'system_instruction': {'parts': [{'text': \"\\n                You should assign a single category to the paper given the informantion provided.\\n                Our goal is to categorize papers related to AI Safety.\\n                If the paper is not related to AI Safety, asign 'None' to its category.\\n\\n                Categories available: {paper_topics}\\n\\n                Provide the response as JSON following this Pydantic schema: {PaperCategory.model_json_schema()}\\n            \"}]}, 'response_mime_type': 'application/json', 'response_schema': <class '__main__.PaperCategory'>}}\n"
     ]
    }
   ],
   "source": [
    "print(requests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66931394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb948e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='batches/6vazui0un6lzsfyhlrg1qf3ipvzpfry4k04n' display_name='structured-output-job-1' state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'> error=None create_time=datetime.datetime(2025, 10, 13, 12, 23, 33, 822312, tzinfo=TzInfo(0)) start_time=None end_time=None update_time=datetime.datetime(2025, 10, 13, 12, 23, 33, 822312, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/f1mikco318ugvyhiiec01ssbppc1f6dmb8vg' display_name='structured-output-job-1' state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 55, 49, 929575, tzinfo=TzInfo(0)) start_time=None end_time=None update_time=datetime.datetime(2025, 10, 13, 9, 55, 49, 929575, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/qrwe9llbxk3hex83alggi4xjiwchfk2pj98x' display_name='structured-output-job-1' state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 54, 19, 407633, tzinfo=TzInfo(0)) start_time=None end_time=None update_time=datetime.datetime(2025, 10, 13, 9, 54, 19, 407633, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/qjmbbwo1woevvt280diltf3ijkagu11p9zcm' display_name='structured-output-job-1' state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 53, 53, 976316, tzinfo=TzInfo(0)) start_time=None end_time=None update_time=datetime.datetime(2025, 10, 13, 9, 53, 53, 976316, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ba92e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Could not parse the batch name', 'status': 'INVALID_ARGUMENT'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatches/structured-output-job-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/google/genai/batches.py:1533\u001b[39m, in \u001b[36mBatches.get\u001b[39m\u001b[34m(self, name, config)\u001b[39m\n\u001b[32m   1530\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   1531\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1535\u001b[39m response_dict = {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.body \u001b[38;5;28;01melse\u001b[39;00m json.loads(response.body)\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/google/genai/_api_client.py:1292\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1284\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1287\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1288\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1289\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1290\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1291\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1292\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1293\u001b[39m   response_body = (\n\u001b[32m   1294\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1295\u001b[39m   )\n\u001b[32m   1296\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/google/genai/_api_client.py:1128\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1125\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/google/genai/_api_client.py:1105\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1098\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1099\u001b[39m       method=http_request.method,\n\u001b[32m   1100\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1103\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1104\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1107\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1108\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/nlp/lib/python3.13/site-packages/google/genai/errors.py:108\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    106\u001b[39m status_code = response.status_code\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    110\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Could not parse the batch name', 'status': 'INVALID_ARGUMENT'}}"
     ]
    }
   ],
   "source": [
    "client.batches.get(name=\"batches/structured-output-job-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02f43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polling status for job: batches/6vazui0un6lzsfyhlrg1qf3ipvzpfry4k04n\n",
      "Job not finished. Current state: JOB_STATE_PENDING. Waiting 30 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob not finished. Current state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_job_inline.state.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Waiting 30 seconds...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob finished with state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_job_inline.state.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print the response\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "inline_batch_job = client.batches.create(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    src=requests,\n",
    "    config={\n",
    "        'display_name': \"structured-output-job-1\"\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d649b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inline_batch_job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# wait for the job to finish\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m job_name = \u001b[43minline_batch_job\u001b[49m.name\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPolling status for job: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'inline_batch_job' is not defined"
     ]
    }
   ],
   "source": [
    "# wait for the job to finish\n",
    "job_name = inline_batch_job.name\n",
    "print(f\"Polling status for job: {job_name}\")\n",
    "\n",
    "while True:\n",
    "    batch_job_inline = client.batches.get(name=job_name)\n",
    "    if batch_job_inline.state.name in ('JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED', 'JOB_STATE_CANCELLED', 'JOB_STATE_EXPIRED'):\n",
    "        break\n",
    "    print(f\"Job not finished. Current state: {batch_job_inline.state.name}. Waiting 30 seconds...\")\n",
    "    time.sleep(30)\n",
    "\n",
    "print(f\"Job finished with state: {batch_job_inline.state.name}\")\n",
    "\n",
    "# print the response\n",
    "for i, inline_response in enumerate(batch_job_inline.dest.inlined_responses, start=1):\n",
    "    print(f\"\\n--- Response {i} ---\")\n",
    "\n",
    "    # Check for a successful response\n",
    "    if inline_response.response:\n",
    "        # The .text property is a shortcut to the generated text.\n",
    "        print(inline_response.response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13dbe9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='batches/6vazui0un6lzsfyhlrg1qf3ipvzpfry4k04n' display_name='structured-output-job-1' state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'> error=None create_time=datetime.datetime(2025, 10, 13, 12, 23, 33, 822312, tzinfo=TzInfo(0)) start_time=None end_time=datetime.datetime(2025, 10, 14, 23, 37, 27, 675244, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 10, 14, 23, 37, 27, 675244, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/f1mikco318ugvyhiiec01ssbppc1f6dmb8vg' display_name='structured-output-job-1' state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 55, 49, 929575, tzinfo=TzInfo(0)) start_time=None end_time=datetime.datetime(2025, 10, 14, 23, 14, 19, 899276, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 10, 14, 23, 14, 19, 899276, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/qrwe9llbxk3hex83alggi4xjiwchfk2pj98x' display_name='structured-output-job-1' state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 54, 19, 407633, tzinfo=TzInfo(0)) start_time=None end_time=datetime.datetime(2025, 10, 14, 23, 2, 16, 175375, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 10, 14, 23, 2, 16, 175374, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n",
      "name='batches/qjmbbwo1woevvt280diltf3ijkagu11p9zcm' display_name='structured-output-job-1' state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'> error=None create_time=datetime.datetime(2025, 10, 13, 9, 53, 53, 976316, tzinfo=TzInfo(0)) start_time=None end_time=datetime.datetime(2025, 10, 14, 22, 56, 36, 308351, tzinfo=TzInfo(0)) update_time=datetime.datetime(2025, 10, 14, 22, 56, 36, 308351, tzinfo=TzInfo(0)) model='models/gemini-2.5-flash' src=None dest=None\n"
     ]
    }
   ],
   "source": [
    "for job in client.batches.list():\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ff0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
