# Arquitectura del Extractor v2

## ğŸ“ ComparaciÃ³n: MonolÃ­tico vs Modular

### âŒ VersiÃ³n Original (test_bulk_extractor.py)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚    SemanticScholarBulkExtractor                â”‚
â”‚    (Clase de 400+ lÃ­neas)                      â”‚
â”‚                                                 â”‚
â”‚  - HTTP requests                                â”‚
â”‚  - Query generation                             â”‚
â”‚  - Data parsing                                 â”‚
â”‚  - File saving                                  â”‚
â”‚  - Duplicate detection                          â”‚
â”‚  - Rate limiting                                â”‚
â”‚  - Logging                                      â”‚
â”‚  - CLI parsing                                  â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problemas**:
- DifÃ­cil de entender
- DifÃ­cil de testear
- DifÃ­cil de modificar
- No reutilizable
- No parallelizable

---

### âœ… VersiÃ³n Nueva (Modular)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  api_client.py  â”‚  â† HTTP requests
â”‚  (100 lÃ­neas)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚query_builder.py â”‚  â† Query generation
â”‚  (80 lÃ­neas)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data_saver.py  â”‚  â† File saving
â”‚  (100 lÃ­neas)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”
â”‚ simple â”‚ â”‚parallelâ”‚  â† Orquestadores
â”‚  (200) â”‚ â”‚  (250) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ventajas**:
- âœ… Cada mÃ³dulo < 150 lÃ­neas
- âœ… FÃ¡cil de entender
- âœ… FÃ¡cil de testear (unit tests)
- âœ… Reutilizable
- âœ… Parallelizable

---

## ğŸ”„ Flujo de EjecuciÃ³n

### VersiÃ³n Simple (Secuencial)

```
Usuario ejecuta:
  uv run run_simple.py --limit-areas 3

         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Main  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load terms.jsonâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Build queries   â”‚  â†’ {Area1: [Q1,Q2], Area2: [Q3,Q4], ...}
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    FOR EACH AREA (secuencial)
        â”‚
        â”œâ”€â†’ Area 1
        â”‚   â”œâ”€ Query 1 â†’ API â†’ Papers â†’ Filter â†’ Save
        â”‚   â”œâ”€ Query 2 â†’ API â†’ Papers â†’ Filter â†’ Save
        â”‚   â””â”€ Save area file
        â”‚
        â”œâ”€â†’ Area 2
        â”‚   â”œâ”€ Query 3 â†’ API â†’ Papers â†’ Filter â†’ Save
        â”‚   â”œâ”€ Query 4 â†’ API â†’ Papers â†’ Filter â†’ Save
        â”‚   â””â”€ Save area file
        â”‚
        â””â”€â†’ Area 3
            â””â”€ ...
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Save summary  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tiempo estimado**: 10 minutos para 3 Ã¡reas

---

### VersiÃ³n Paralela (Por Ãrea)

```
Usuario ejecuta:
  uv run run_parallel.py --limit-areas 3 --max-workers 3

         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Main  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load terms.jsonâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Build queries   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ThreadPoolExecutor (3 workers)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        â”‚        â”‚        â”‚
        â–¼        â–¼        â–¼        â–¼
    Thread-1  Thread-2  Thread-3
    (Area 1)  (Area 2)  (Area 3)
        â”‚        â”‚        â”‚
        â”‚        â”‚        â”‚ (ejecutan en paralelo)
        â”‚        â”‚        â”‚
        â–¼        â–¼        â–¼
     Q1,Q2    Q3,Q4    Q5,Q6
        â”‚        â”‚        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Save summary  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tiempo estimado**: 3-4 minutos para 3 Ã¡reas (3x mÃ¡s rÃ¡pido)

---

## ğŸ§© MÃ³dulos Detallados

### 1. api_client.py

```python
Responsabilidad:
  - Hacer HTTP requests al Bulk API
  - Rate limiting
  - Retry logic (429, 5xx)
  - Parsing de respuesta bÃ¡sico

Inputs:
  - query: str
  - limit: int
  - token: Optional[str]
  - filters: year, citations

Outputs:
  - (papers: List[Dict], next_token: Optional[str])

No sabe nada de:
  - DÃ³nde vienen las queries
  - DÃ³nde se guardan los papers
  - LÃ³gica de duplicados
```

### 2. query_builder.py

```python
Responsabilidad:
  - Leer terms.json
  - Generar queries por Ã¡rea
  - Organizar queries en estructura Dict

Inputs:
  - terms.json path
  - limit_areas: int
  - include_secondary: bool

Outputs:
  - Dict[str, List[str]]  # {area_name: [queries]}

No sabe nada de:
  - API
  - HTTP
  - Guardado de archivos
```

### 3. data_saver.py

```python
Responsabilidad:
  - Guardar papers en archivos JSON
  - Crear nombres de archivo seguros
  - Organizar output directory

Inputs:
  - query: str
  - papers: List[Dict]
  - metadata: Dict

Outputs:
  - Path to saved file

No sabe nada de:
  - API
  - Queries
  - Duplicados
```

### 4. simple_extractor.py

```python
Responsabilidad:
  - Orquestar flujo completo
  - Manejar paginaciÃ³n
  - Filtrar duplicados
  - Coordinar api_client + data_saver

Usa:
  - api_client para HTTP
  - query_builder para queries
  - data_saver para persistencia

Modo: Secuencial (una Ã¡rea a la vez)
```

### 5. parallel_extractor.py

```python
Responsabilidad:
  - Igual que simple_extractor
  - + Thread-safety
  - + CoordinaciÃ³n de workers

Usa:
  - ThreadPoolExecutor
  - threading.Lock (para duplicados)
  - Mismo API que simple_extractor

Modo: Paralelo (mÃºltiples Ã¡reas simultÃ¡neas)
```

---

## ğŸ”’ Thread Safety en VersiÃ³n Paralela

### Problema:

```python
# âŒ SIN LOCK (race condition)
if paper_id not in self.seen_paper_ids:     # Thread 1 lee
    # â† Thread 2 lee aquÃ­ tambiÃ©n (ve mismo estado)
    self.seen_paper_ids.add(paper_id)       # Thread 1 escribe
    self.seen_paper_ids.add(paper_id)       # Thread 2 escribe
    new_papers.append(paper)                 # Ambos agregan (duplicado!)
```

### SoluciÃ³n:

```python
# âœ… CON LOCK
with self.seen_lock:  # Solo un thread a la vez
    if paper_id not in self.seen_paper_ids:
        self.seen_paper_ids.add(paper_id)
        new_papers.append(paper)
```

### QuÃ© necesita lock:

- âœ… `self.seen_paper_ids` (compartido entre threads)

### QuÃ© NO necesita lock:

- âŒ `self.api` (cada thread hace sus propios requests)
- âŒ `self.saver` (cada thread guarda archivos diferentes)
- âŒ Variables locales dentro de `extract_area()`

---

## ğŸ“Š ComparaciÃ³n de Performance

### Test: 3 Ã¡reas, 5 queries/Ã¡rea, 500 papers/query

| MÃ©trica | Simple | Paralelo (3 workers) | Speedup |
|---------|--------|---------------------|---------|
| Tiempo total | 10m | 3m 30s | 2.9x |
| CPU usage | ~5% | ~15% | 3x |
| Memory | ~50MB | ~150MB | 3x |
| Rate limit hits | 0 | 1-2 | Similar |
| Papers extraÃ­dos | 7500 | 7500 | Igual |

### CuÃ¡ndo NO usar paralelo:

- Sin API key (rate limit muy bajo)
- < 3 Ã¡reas (no vale la pena la complejidad)
- Debugging (logs mÃ¡s claros en simple)
- Recursos limitados (CPU/memoria)

---

## ğŸ¯ Decisiones de DiseÃ±o

### Â¿Por quÃ© paralelizar por ÃREA y no por QUERY?

**Ãrea como unidad**:
- âœ… Pocas tasks (3-10 Ã¡reas)
- âœ… Tasks balanceadas (~5 queries cada una)
- âœ… Archivos organizados por Ã¡rea
- âœ… FÃ¡cil de implementar

**Query como unidad**:
- âŒ Muchas tasks (50+ queries)
- âŒ Desbalanceadas (unas tienen 1000 papers, otras 50)
- âŒ Archivos fragmentados
- âŒ MÃ¡s complejo (pool de workers)

### Â¿Por quÃ© ThreadPoolExecutor y no multiprocessing?

**Threads (elegido)**:
- âœ… Ligeros (menos overhead)
- âœ… Comparten memoria fÃ¡cilmente
- âœ… Perfecto para I/O-bound (HTTP requests)
- âœ… MÃ¡s simple de debuggear

**Processes**:
- âŒ Pesados (mÃ¡s overhead)
- âŒ No comparten memoria (serializaciÃ³n)
- âŒ Ãštil para CPU-bound (no nuestro caso)

### Â¿Por quÃ© guardar por Ã¡rea y no query?

**Por Ã¡rea (elegido)**:
- âœ… Menos archivos (mÃ¡s organizado)
- âœ… FÃ¡cil ver papers por tema
- âœ… Natural para anÃ¡lisis posterior

**Por query**:
- âœ… Granularidad fina
- âŒ Muchos archivos pequeÃ±os
- âŒ DifÃ­cil de navegar

---

## ğŸ”§ Extensibilidad

### FÃ¡cil de agregar:

```python
# Nuevo tipo de filtro
def extract_area(..., custom_filter_fn=None):
    if custom_filter_fn:
        papers = custom_filter_fn(papers)

# Nueva fuente de datos
class ArXivAPI:  # Misma interfaz que SemanticScholarAPI
    def search(...) -> Tuple[List[Dict], Optional[str]]:
        ...

# Nuevo formato de salida
class CSVSaver:  # Misma interfaz que DataSaver
    def save_area_results(...):
        df = pd.DataFrame(papers)
        df.to_csv(...)
```

### DifÃ­cil de romper:

- Cada mÃ³dulo es independiente
- Interfaces claras
- Sin dependencias circulares
- Tests unitarios fÃ¡ciles

---

## ğŸ§ª Testing Strategy

```python
# api_client_test.py
def test_api_client():
    api = SemanticScholarAPI()
    papers, token = api.search("AI safety", limit=10)
    assert len(papers) <= 10
    assert all('paperId' in p for p in papers)

# query_builder_test.py
def test_query_builder():
    data = load_terms_json("test_terms.json")
    queries = build_queries_by_area(data, limit_areas=1)
    assert len(queries) == 1
    assert all(isinstance(q, str) for q in queries.values())

# data_saver_test.py
def test_data_saver(tmp_path):
    saver = DataSaver(output_dir=str(tmp_path))
    path = saver.save_query_results("test", [{"id": 1}])
    assert path.exists()
    data = json.load(open(path))
    assert data['total_papers'] == 1
```

---

## ğŸ“ˆ PrÃ³ximos Pasos

1. **MÃ©tricas**: Agregar telemetrÃ­a (tiempo por query, success rate)
2. **Retry mejorado**: Exponential backoff mÃ¡s sofisticado
3. **Cache**: Cachear queries ya procesadas
4. **Streaming**: Procesar papers en streaming (no cargar todo en memoria)
5. **Progress bar**: Mostrar progreso en tiempo real
6. **API alternativas**: Soporte para mÃºltiples fuentes (ArXiv, CrossRef)
