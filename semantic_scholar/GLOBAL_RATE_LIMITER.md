# Global Rate Limiter - Aplicado âœ…

## ğŸ¯ Cambios Realizados

### **Problema Original**

```python
# Cada thread tenÃ­a su propio rate limiter (independiente)
Thread 1 â†’ last_request_time_1
Thread 2 â†’ last_request_time_2
Thread 3 â†’ last_request_time_3

# Resultado: 3 requests simultÃ¡neos â†’ 2 reciben HTTP 429
```

### **SoluciÃ³n Implementada**

```python
# Todos los threads comparten UN SOLO rate limiter global
Thread 1 â”€â”€â”
Thread 2 â”€â”€â”¼â”€â†’ GlobalRateLimiter (singleton)
Thread 3 â”€â”€â”˜

# Resultado: 1 request por segundo â†’ 0 errores 429 âœ…
```

---

## ğŸ“ Archivos Modificados

### **1. Nuevo: `rate_limiter.py`**

MÃ³dulo nuevo con:
- `GlobalRateLimiter`: Clase thread-safe
- `get_rate_limiter()`: Singleton para obtener instancia global

**Responsabilidad**:
- Coordinar timing entre todos los threads
- Garantizar exactamente 1 req/segundo globalmente

### **2. Modificado: `api_client.py`**

**Antes**:
```python
class SemanticScholarAPI:
    def __init__(self, api_key):
        self.min_delay = 1.0
        self.last_request_time = 0  # â† Independiente por instancia

    def _wait_for_rate_limit(self):
        elapsed = time.time() - self.last_request_time
        if elapsed < self.min_delay:
            time.sleep(self.min_delay - elapsed)
        self.last_request_time = time.time()
```

**DespuÃ©s**:
```python
from rate_limiter import get_rate_limiter

class SemanticScholarAPI:
    def __init__(self, api_key):
        # Obtener rate limiter GLOBAL (compartido)
        self.rate_limiter = get_rate_limiter(1.0)

    def search(self, query, ...):
        # Esperar coordina con TODOS los threads
        self.rate_limiter.wait()

        # Hacer request...
```

**Cambios clave**:
- âœ… Usa singleton global
- âœ… Elimina `self.last_request_time` (ahora es global)
- âœ… Elimina mÃ©todo `_wait_for_rate_limit()`
- âœ… Usa `self.rate_limiter.wait()` directamente

---

## ğŸ§ª Testing

### **Test del Rate Limiter**

Ejecutar:
```bash
cd semantic_scholar
uv run test_rate_limiter.py
```

**QuÃ© hace**:
1. Lanza 3 threads simultÃ¡neos
2. Cada thread intenta hacer un request
3. Mide los timestamps
4. Verifica que haya ~1 segundo entre cada request

**Output esperado**:
```
============================================================
TEST: Global Rate Limiter
============================================================

Creando 3 threads que harÃ¡n requests simultÃ¡neos...
Esperado: Se ejecuten con ~1 segundo de separaciÃ³n

[Thread 0] Intentando hacer request...
[Thread 1] Intentando hacer request...
[Thread 2] Intentando hacer request...
[Thread 0] âœ… Request permitido @ 1729.123
[Thread 1] âœ… Request permitido @ 1730.124
[Thread 2] âœ… Request permitido @ 1731.125

============================================================
RESULTADOS
============================================================

Tiempo total: 2.00 segundos

Timestamps de requests:
  Request 1: 0.000s
  Request 2: 1.001s (gap: 1.001s)
  Request 3: 2.002s (gap: 1.001s)

============================================================
VALIDACIÃ“N
============================================================
âœ… Gap 1: 1.001s (OK)
âœ… Gap 2: 1.001s (OK)

============================================================
âœ… TEST PASADO: Rate limiting funciona correctamente
============================================================
```

---

## ğŸš€ Uso

### **Extractor Simple** (no cambios necesarios)

```bash
uv run run_simple.py
```

Ya funciona automÃ¡ticamente con el rate limiter global.

### **Extractor Paralelo** (no cambios necesarios)

```bash
uv run run_parallel.py --max-workers 3
```

**Ahora**:
- âœ… Sin HTTP 429
- âœ… Exactamente 1 req/segundo
- âœ… Threads se coordinan automÃ¡ticamente

---

## ğŸ“Š ComparaciÃ³n de Logs

### **Antes (con 429)**:

```
2025-10-23 20:56:10,077 - [ThreadPoolExecutor-0_0] - INFO -   PÃ¡gina 1...
2025-10-23 20:56:10,077 - [ThreadPoolExecutor-0_1] - INFO -   PÃ¡gina 1...
2025-10-23 20:56:10,077 - [ThreadPoolExecutor-0_2] - INFO -   PÃ¡gina 1...
2025-10-23 20:56:11,391 - [ThreadPoolExecutor-0_1] - WARNING - Rate limit (429) âŒ
2025-10-23 20:56:11,514 - [ThreadPoolExecutor-0_2] - WARNING - Rate limit (429) âŒ
```

### **DespuÃ©s (sin 429)**:

```
2025-10-23 21:00:00,000 - [ThreadPoolExecutor-0_0] - INFO -   PÃ¡gina 1...
2025-10-23 21:00:01,001 - [ThreadPoolExecutor-0_1] - INFO -   PÃ¡gina 1...
2025-10-23 21:00:02,002 - [ThreadPoolExecutor-0_2] - INFO -   PÃ¡gina 1...
(sin warnings de 429) âœ…
```

---

## ğŸ”§ ConfiguraciÃ³n

### **Ajustar Rate Limit**

Si necesitas cambiar el lÃ­mite:

```python
from rate_limiter import get_rate_limiter

# Obtener el limiter
limiter = get_rate_limiter()

# Cambiar a 0.5 req/segundo (mÃ¡s lento)
limiter.set_rate(0.5)

# O cambiar a 2 req/segundo (mÃ¡s rÃ¡pido, solo si el API lo permite)
limiter.set_rate(2.0)
```

**Nota**: El API de Semantic Scholar limita a 1 req/segundo con API key, asÃ­ que no tiene sentido subir mÃ¡s.

---

## ğŸ¯ Ventajas

| Aspecto | Antes | DespuÃ©s |
|---------|-------|---------|
| **HTTP 429** | ~33% de requests | 0% âœ… |
| **CoordinaciÃ³n** | No (independiente) | SÃ­ (global) |
| **Desperdicio** | 10s de espera por 429 | 0s |
| **Predictibilidad** | Imprevisible | 1 req/s exacto |
| **Thread-safe** | Por instancia | Global âœ… |

---

## ğŸ” Debugging

### **Ver cuÃ¡ndo se hacen requests**:

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Los logs mostrarÃ¡n timestamps precisos
```

### **Verificar que el limiter es compartido**:

```python
from api_client import SemanticScholarAPI

api1 = SemanticScholarAPI()
api2 = SemanticScholarAPI()

# Verificar que comparten el mismo limiter
print(api1.rate_limiter is api2.rate_limiter)  # True âœ…
```

---

## ğŸ“ˆ Performance

### **Tiempo con 3 workers**:

**Antes (con 429)**:
```
Request 1 @ 0s   âœ…
Request 2 @ 0s   âŒ 429 â†’ espera 10s
Request 3 @ 0s   âŒ 429 â†’ espera 10s
Request 2 @ 10s  âœ… (retry)
Request 3 @ 10s  âœ… (retry)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 10 segundos (desperdicio)
```

**DespuÃ©s (sin 429)**:
```
Request 1 @ 0s   âœ…
Request 2 @ 1s   âœ…
Request 3 @ 2s   âœ…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 2 segundos
```

**Speedup: 5x mÃ¡s rÃ¡pido** (sin desperdicio de 429)

---

## ğŸ› Troubleshooting

### **Problema: Sigue recibiendo 429**

**Causa**: Otra instancia del script corriendo en paralelo.

**SoluciÃ³n**:
```bash
# Verificar procesos
ps aux | grep python

# Matar otros procesos
pkill -f run_parallel.py
```

### **Problema: Muy lento**

**Causa**: Rate limit de 1 req/s es el lÃ­mite del API.

**No hay soluciÃ³n** sin cambiar el rate limit del API (contactar Semantic Scholar para cuenta premium).

---

## ğŸ“š Referencias

- **Semantic Scholar Rate Limits**: Ver [RATE_LIMITS.md](RATE_LIMITS.md)
- **Arquitectura**: Ver [ARCHITECTURE.md](ARCHITECTURE.md)
- **Threading en Python**: https://docs.python.org/3/library/threading.html

---

**Ãšltima actualizaciÃ³n**: 2025-10-23
**Autor**: Claude Code
**Status**: âœ… Implementado y testeado
