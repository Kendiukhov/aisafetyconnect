{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487d951d",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "```pip install pandas rapidfuzz sentence_transformers  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b6dee",
   "metadata": {},
   "source": [
    "# Identifying the data\n",
    "\n",
    "This just are some cells to upload and check the data.\n",
    "\n",
    "\n",
    "## LessWrong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4556f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c94e51d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "userId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "username",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "displayName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "karma",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "afKarma",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ai_safety_tags",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "post_count_in_ai_safety",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "slug",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "jobTitle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "organization",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "careerStage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "website",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "linkedinProfileURL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "githubProfileURL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twitterProfileURL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postCount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "commentCount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "createdAt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "profileTagIds",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "0b067357-9709-4cfc-b1ed-673467153fb6",
       "rows": [
        [
         "0",
         "nmk3nLpQE89dMRzzN",
         "Eliezer_Yudkowsky",
         "Eliezer Yudkowsky",
         "153177",
         "1907",
         "['MIRI', 'MIRI']",
         "2",
         "nmk3nLpQE89dMRzzN",
         "eliezer_yudkowsky",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "952",
         "7699",
         "2009-02-23T21:58:56.739Z",
         "[]"
        ],
        [
         "1",
         "r38pkCm7wF4M44MDQ",
         "Raemon",
         "Raemon",
         "59085",
         "731",
         "['MIRI', 'AI Governance']",
         "2",
         "r38pkCm7wF4M44MDQ",
         "raemon",
         "LessWrong team member / moderator. I've been a LessWrong organizer since 2011, with roughly equal focus on the cultural, practical and intellectual aspects of the community. My first project was creating the Secular Solstice and helping groups across the world run their own version of it. More recently I've been interested in improving my own epistemic standards and helping others to do so as well.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "491",
         "8582",
         "2010-09-09T02:09:20.629Z",
         "[]"
        ],
        [
         "2",
         "N9zj5qpTfqmbn9dro",
         "Zvi",
         "Zvi",
         "53718",
         "146",
         "['AI Governance', 'AI Governance', 'Chain-of-Thought Alignment']",
         "3",
         "N9zj5qpTfqmbn9dro",
         "zvi",
         "",
         null,
         null,
         null,
         "thezvi.wordpress.com",
         null,
         null,
         null,
         "1000",
         "1476",
         "2009-03-31T20:54:54.077Z",
         "[]"
        ],
        [
         "3",
         "2aoRX3ookcCozcb3m",
         "RobbBB",
         "Rob Bensinger",
         "22702",
         "1384",
         "['MIRI', 'MIRI', 'MIRI', 'MIRI', 'MIRI']",
         "5",
         "2aoRX3ookcCozcb3m",
         "robbbb",
         "Communications @ MIRI. Unless otherwise indicated, my posts and comments here reflect my own views, and not necessarily my employer's. (Though we agree about an awful lot.)",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "125",
         "2232",
         "2012-08-10T00:50:11.669Z",
         "[]"
        ],
        [
         "4",
         "dfZAq9eZxs4BB4Ji5",
         "ryan_greenblatt",
         "ryan_greenblatt",
         "19977",
         "4823",
         "['Outer Alignment', 'AI Governance', 'AI Governance']",
         "3",
         "dfZAq9eZxs4BB4Ji5",
         "ryan_greenblatt",
         "I'm the chief scientist at Redwood Research.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "50",
         "1893",
         "2021-06-08T20:21:15.520Z",
         "[]"
        ],
        [
         "5",
         "BCmzFRdQhqLPREvat",
         "ricraz",
         "Richard_Ngo",
         "19906",
         "2854",
         "['Inner Alignment', 'Inner Alignment', 'AI Governance']",
         "3",
         "BCmzFRdQhqLPREvat",
         "ricraz",
         "Formerly alignment and governance researcher at DeepMind and OpenAI. Now independent.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "169",
         "1114",
         "2013-07-14T15:42:06.397Z",
         "[]"
        ],
        [
         "6",
         "n6LYNw2uGfYnD4pX2",
         "lsusr",
         "lsusr",
         "18664",
         "25",
         "['Mesa-Optimization']",
         "1",
         "n6LYNw2uGfYnD4pX2",
         "lsusr",
         "Here is a [list of all my public writings and videos (from before February 2025).](https://www.lsusr.com/)",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "290",
         "1735",
         "2019-08-03T22:27:09.960Z",
         "[]"
        ],
        [
         "7",
         "4fh2AAe3n7oBviyxx",
         "orthonormal",
         "orthonormal",
         "17953",
         "288",
         "['Mesa-Optimization']",
         "1",
         "4fh2AAe3n7oBviyxx",
         "orthonormal",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "70",
         "2824",
         "2009-03-22T16:06:51.665Z",
         "[]"
        ],
        [
         "8",
         "AThTtkDufXp3rmMDa",
         "evhub",
         "evhub",
         "14730",
         "4677",
         "['MIRI']",
         "1",
         "AThTtkDufXp3rmMDa",
         "evhub",
         "Evan Hubinger (he/him/his) ([evanjhub@gmail.com](mailto:evanjhub@gmail.com))\n\nHead of [Alignment Stress-Testing](https://www.alignmentforum.org/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic) at [Anthropic](https://www.anthropic.com/). My posts and comments are my own and do not represent Anthropic's positions, policies, strategies, or opinions.\n\nPreviously: MIRI, OpenAI\n\nSee: “[Why I'm joining Anthropic](https://www.lesswrong.com/posts/7jn5aDadcMH6sFeJe/why-i-m-joining-anthropic)”\n\nSelected work:\n\n*   “[Auditing language models for hidden objectives](https://www.alignmentforum.org/posts/wSKPuBfgkkqfTpmWJ/auditing-language-models-for-hidden-objectives)”\n*   “[Alignment faking in large language models](https://www.alignmentforum.org/posts/njAZwT8nkHnjipJku/alignment-faking-in-large-language-models)”\n*   “[Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://www.alignmentforum.org/posts/ZAsJv7xijKTfZkMtr/sleeper-agents-training-deceptive-llms-that-persist-through)”\n*   “[Conditioning Predictive Models](https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX)”\n*   “[An overview of 11 proposals for building safe advanced AI](https://www.alignmentforum.org/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai)”\n*   “[Risks from Learned Optimization](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB)”",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "72",
         "805",
         "2017-01-17T06:05:22.405Z",
         "[]"
        ],
        [
         "9",
         "rx7xLaHCh3m7Po385",
         "Buck",
         "Buck",
         "14669",
         "3100",
         "['AI Governance']",
         "1",
         "rx7xLaHCh3m7Po385",
         "buck",
         "CEO at Redwood Research.\n\nAI safety is a highly collaborative field--almost all the points I make were either explained to me by someone else, or developed in conversation with other people. I'm saying this here because it would feel repetitive to say \"these ideas were developed in collaboration with various people\" in all my comments, but I want to have it on the record that the ideas I present were almost entirely not developed by me in isolation.\n\nPlease contact me via email (bshlegeris@gmail.com) instead of messaging me on LessWrong.\n\nIf we are ever arguing on LessWrong and you feel like it's kind of heated and would go better if we just talked about it verbally, please feel free to contact me and I'll probably be willing to call to discuss briefly.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "47",
         "569",
         "2018-04-20T18:36:03.024Z",
         "[]"
        ],
        [
         "10",
         "gSKzrqGFdS7DkXhuE",
         "jessica.liu.taylor",
         "jessicata",
         "10263",
         "824",
         "['MIRI', 'MIRI']",
         "2",
         "gSKzrqGFdS7DkXhuE",
         "jessica-liu-taylor",
         "Jessica Taylor. CS undergrad and Master's at Stanford; former research fellow at MIRI.\n\nI work on decision theory, social epistemology, strategy, naturalized agency, mathematical foundations, decentralized networking systems and applications, theory of mind, and functional programming languages.\n\nBlog: [unstableontology.com](http://unstableontology.com)\n\nTwitter: [https://twitter.com/jessi_cata](https://twitter.com/jessi_cata)",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "70",
         "966",
         "2017-06-18T22:55:04.584Z",
         "[]"
        ],
        [
         "11",
         "fjERoRhgjipqw3z2b",
         "Mitchell_Porter",
         "Mitchell_Porter",
         "9273",
         "6",
         "['AI Governance']",
         "1",
         "fjERoRhgjipqw3z2b",
         "mitchell_porter",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "48",
         "2412",
         "2009-05-28T02:36:19.394Z",
         "[]"
        ],
        [
         "12",
         "g8JkZfL8PTqAefpvx",
         "JenniferRM",
         "JenniferRM",
         "8978",
         "18",
         "['Mesa-Optimization']",
         "1",
         "g8JkZfL8PTqAefpvx",
         "jenniferrm",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "34",
         "1377",
         "2009-03-06T17:16:50.600Z",
         "[]"
        ],
        [
         "13",
         "DgsGzjyBXN8XSK22q",
         "DanielFilan",
         "DanielFilan",
         "8942",
         "1868",
         "['Inner Alignment', 'AI Governance', 'Mesa-Optimization']",
         "3",
         "DgsGzjyBXN8XSK22q",
         "danielfilan",
         "",
         null,
         null,
         null,
         "http://danielfilan.com",
         null,
         null,
         null,
         "152",
         "1396",
         "2014-01-30T11:04:39.341Z",
         "[]"
        ],
        [
         "14",
         "nDpieb7g8huozpx9j",
         "Thane Ruthenis",
         "Thane Ruthenis",
         "8911",
         "852",
         "['Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization']",
         "5",
         "nDpieb7g8huozpx9j",
         "thane-ruthenis",
         "Agent-foundations researcher. Working on [Synthesizing Standalone World-Models](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking), aiming at a technical solution to the AGI risk fit for worlds where alignment is punishingly hard and we only get one try.\n\nCurrently looking for additional funders ($1k+, [details](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking#Funding)). Consider reaching out if you're interested, or [donating](https://manifund.org/projects/synthesizing-standalone-world-models) directly.\n\nOr [get me to pay *you* money](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking#Bounties) ($5-$100) by spotting holes in my agenda or providing other useful information.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "46",
         "1000",
         "2022-03-20T15:21:33.973Z",
         "[]"
        ],
        [
         "15",
         "mfgrYb4LMk7NWXsSB",
         "tailcalled",
         "tailcalled",
         "7887",
         "77",
         "['MIRI']",
         "1",
         "mfgrYb4LMk7NWXsSB",
         "tailcalled",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "107",
         "2411",
         "2015-01-27T20:50:11.327Z",
         "[]"
        ],
        [
         "16",
         "XLwKyCK7JmC292ZCC",
         "Chris_Leong",
         "Chris_Leong",
         "7708",
         "458",
         "['MIRI', 'Inner Alignment']",
         "2",
         "XLwKyCK7JmC292ZCC",
         "chris_leong",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "229",
         "2181",
         "2009-05-28T03:08:43.251Z",
         "[]"
        ],
        [
         "17",
         "TCjNiBLBPyhZq5BuM",
         "Seth Herd",
         "Seth Herd",
         "7411",
         "239",
         "['Inner Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment']",
         "5",
         "TCjNiBLBPyhZq5BuM",
         "seth-herd",
         "Message me here or at seth dot herd at gmail dot com.\n\nI was a researcher in cognitive psychology and cognitive neuroscience for two decades and change. I studied complex human thought using neural network models of brain function. I'm applying that knowledge to figuring out how we can align AI as developers make it to \"think for itself\" in all the ways that make humans capable and dangerous.\n\nIf you're new to alignment, see the Research Overview section below. Field veterans who are curious about my particular take and approach should see the More on My Approach section at the end of the profile.\n\nImportant posts:\n----------------\n\n*   On LLM-based agents as a route to takeover-capable AGI\n    *   [LLM AGI will have memory, and memory changes alignment](https://www.lesswrong.com/posts/aKncW36ZdEnzxLo8A/llm-agi-will-have-memory-and-memory-changes-alignment)\n    *   [Brief argument for short timelines being quite possible](https://www.lesswrong.com/posts/oC4wv4nTrs2yrP5hz/what-are-the-strongest-arguments-for-very-short-timelines?commentId=3vSTG4gZgvz9ki5LP)\n    *   [Capabilities and alignment of LLM cognitive architectures](https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures)\n        *   Cognitive psychology perspective on routes to LLM-based AGI with no breakthroughs needed\n*   AGI risk interactions with societal power structures and incentives:\n    *   [Whether governments will control AGI is important and neglected](https://www.lesswrong.com/posts/fFqABwAHMvhHSFmce/whether-governments-will-control-agi-is-important-and)\n    *   [If we solve alignment, do we die anyway?](https://www.lesswrong.com/posts/kLpFvEBisPagBLTtM/if-we-solve-alignment-do-we-die-anyway-1)\n        *   Risks of proliferating human-controlled AGI\n    *   [Fear of centralized power vs. fear of misaligned AGI: Vitalik Buterin on 80,000 Hours](https://www.lesswrong.com/posts/6iJrd8c9jxRstxJyE/fear-of-centralized-power-vs-fear-of-misaligned-agi-vitalik)\n*   On the psychology of alignment as a field:\n    *   [Cruxes of disagreement on alignment difficulty](https://www.lesswrong.com/posts/ye78Dip8YNgLBKGcy/seth-herd-s-shortform?commentId=FpdvoZsmmrNLekkz9)\n    *   [Motivated reasoning/confirmation bias as the most important cognitive bias](https://www.lesswrong.com/posts/j789HDCKLoiKGjBik/which-biases-are-most-important-to-overcome#LW8zAxTguKj8ibDfX)\n*   On technical alignment of LLM-based AGI agents:\n    *   [System 2 Alignment](https://www.lesswrong.com/posts/cus5CGmLrjBRgcPSF/system-2-alignment) on how developers will try to align LLM agent AGI\n    *   [Seven sources of goals in LLM agents](https://www.lesswrong.com/posts/nHDhst47yzDCpGstx/seven-sources-of-goals-in-llm-agents) brief problem statement\n    *   [Internal independent review for language model agent alignment](https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent)\n*   On AGI alignment targets assuming technical alignment\n    *   [Problems with instruction-following as an alignment target](https://www.lesswrong.com/posts/CSFa9rvGNGAfCzBk6/problems-with-instruction-following-as-an-alignment-target)\n    *   [Instruction-following AGI is easier and more likely than value aligned AGI](https://www.lesswrong.com/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than)\n    *   [Goals selected from learned knowledge: an alternative to RL alignment](https://www.alignmentforum.org/posts/DfJCTp4MxmTFnYvgF/goals-selected-from-learned-knowledge-an-alternative-to-rl)\n*   On communicating AGI risks:\n    *   [Anthropomorphizing AI might be good, actually](https://www.lesswrong.com/posts/JfgME2Kdo5tuWkP59/anthropomorphizing-ai-might-be-good-actually)\n    *   [Humanity isn’t remotely longtermist, so arguments for AGI x-risk should focus on the near term](https://www.lesswrong.com/posts/fdracpKGbH4xqprQK/humanity-isn-t-remotely-longtermist-so-arguments-for-agi-x)\n    *   [AI scares and changing public beliefs](https://www.lesswrong.com/posts/ou5raNNjamAaahtWG/ai-scares-and-changing-public-beliefs)\n\nResearch Overview:\n------------------\n\n*Alignment* is the study of how to give AIs goals or values aligned with ours, so we're not in competition with our own creations. Recent breakthroughs in AI like ChatGPT make it possible we'll have smarter-than-human AIs soon. So we'd better get ready. If their goals don't align well enough with ours, they'll probably outsmart us and get their way — and treat us as we do ants or monkeys. See this [excellent intro video](https://www.youtube.com/watch?v=-H7e4XlMgg0) for more. \n\nThere are [good and deep reasons](https://www.lesswrong.com/posts/LLRtjkvh9AackwuNB/on-a-list-of-lethalities) to think that aligning AI will be very hard. But I think we have [promising solutions](https://alignmentforum.org/posts/xqqhwbH2mq6i4iLmK/we-have-promising-alignment-plans-with-low-taxes) that bypass most of those difficulties, and could be relatively easy to use for the types of AGI we're most likely to develop first. \n\nThat doesn't mean I think building AGI is safe. Humans often screw up complex projects, particularly on the first try, and we won't get many tries. If it were up to me I'd Shut It All Down, but I don't see how we could get all of humanity to stop building AGI. So I focus on finding alignment solutions for the types of AGI people are building.\n\nIn brief I think we can probably [build and align language model agents](https://alignmentforum.org/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures) (or language model cognitive architectures) even when they're more autonomous and competent than humans. We'd use a [stacking suite of alignment methods](https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent) that can mostly or entirely [avoid using RL for alignment](https://alignmentforum.org/posts/DfJCTp4MxmTFnYvgF/goals-selected-from-learned-knowledge-an-alternative-to-rl), and achieve corrigibility (human-in-the-loop error correction) by having a [central goal of following instructions](https://alignmentforum.org/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than). This scenario leaves multiple humans in charge of ASIs, creating some dangerous dynamics, but those problems might be navigated, too. \n\nBio\n---\n\nI did computational cognitive neuroscience research from getting my PhD in 2006 until the end of 2022. I've worked on computational theories of vision, executive function, episodic memory, and decision-making, using neural network models of brain function to integrate data across levels of analysis from psychological down to molecular mechanisms of learning in neurons, and everything in between. I've focused on the interactions between different brain neural networks that are needed to explain complex thought. [Here's a list of my publications.](https://sethaherd.com/neuroscience-publications/) \n\nI was increasingly concerned with AGI applications of the research, and reluctant to publish my full theories lest they be used to accelerate AI progress. I'm incredibly excited to now be working full-time on alignment, currently as a research fellow at the [Astera Institute](https://astera.org).  \n\nMore on My Approach\n-------------------\n\nThe field of AGI alignment is \"pre-paradigmatic.\" So I spend a lot of my time thinking about what problems need to be solved, and how we should go about solving them. Solving the wrong problems seems like a waste of time we can't afford.\n\nWhen LLMs suddenly started looking intelligent and useful, I noted that applying cognitive neuroscience ideas to them might well enable them to reach AGI and soon ASI levels. Current LLMs are like humans with no episodic memory for their experiences, and very little executive function for planning and goal-directed self-control. Adding those cognitive systems to LLMs can make them into cognitive architectures with all of humans' cognitive capacities - a [\"real\" artificial general intelligence](https://www.lesswrong.com/posts/YW249knFccwATGxki/real-agi) that will soon be able to outsmart humans. \n\nMy work since then has convinced me that we could probably also align such an AGI so that it stays aligned even if it grows much smarter than we are.  Instead of trying to give it a definition of ethics it can't misunderstand or re-interpret (value alignment mis-specification), we'll continue doing with the alignment target developers currently use: [Instruction-following](https://www.lesswrong.com/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than). It's counter-intuitive to imagine an intelligent entity that wants nothing more than to follow instructions, but there's no logical reason this can't be done.  An instruction-following proto-AGI can be instructed to act as a helpful collaborator in keeping it aligned as it grows smarter. \n\nThere are significant problems to be solved in prioritizing instructions; we would need an agent to prioritize more recent instructions over previous ones, including hypothetical future instructions. \n\nI increasingly suspect we should be actively working to build such intelligences. It seems like our our best hope of survival, since I don't see how we can convince the whole world to pause AGI efforts, and other routes to AGI seem much harder to align since they won't \"think\" in English. Thus far, I haven't been able to engage enough careful critique of my ideas to know if this is wishful thinking, so I haven't embarked on actually helping develop language model cognitive architectures.\n\nEven though these approaches are pretty straightforward, they'd have to be implemented carefully. Humans often get things wrong on their first try at a complex project. So my p(doom) estimate of our long-term survival as a species is in the 50% range, too complex to call. That's despite having a pretty good mix of relevant knowledge and having spent a lot of time working through various scenarios. So I think anyone with a very high or very low estimate is overestimating their certainty.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "43",
         "1817",
         "2022-09-05T00:45:45.715Z",
         "[]"
        ],
        [
         "18",
         "QpvwBD5AtmmFDTC3T",
         "leogao",
         "leogao",
         "7176",
         "890",
         "['Mesa-Optimization']",
         "1",
         "QpvwBD5AtmmFDTC3T",
         "leogao",
         "",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "32",
         "499",
         "2020-04-19T18:50:05.381Z",
         "[]"
        ],
        [
         "19",
         "x5S2Kuj6TfQTGuo63",
         "thomas-kwa",
         "Thomas Kwa",
         "7018",
         "566",
         "['MIRI']",
         "1",
         "x5S2Kuj6TfQTGuo63",
         "thomas-kwa",
         "Member of technical staff at [METR](https://metr.org/).\n\nPreviously: [Vivek Hebbar's team at MIRI](https://www.lesswrong.com/posts/qbcuk8WwFnTZcXTd6/thomas-kwa-s-miri-research-experience) **→** [Adrià Garriga-Alonso](https://agarri.ga/) on [](https://agarri.ga/) [various empirical alignment projects](https://www.lesswrong.com/posts/bf3vciB36dnd75ZKJ/thomas-kwa-s-research-journal) → METR.\n\nI have signed no contracts or agreements whose existence I cannot mention.",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "26",
         "800",
         "2019-12-09T06:28:45.933Z",
         "[]"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>username</th>\n",
       "      <th>displayName</th>\n",
       "      <th>karma</th>\n",
       "      <th>afKarma</th>\n",
       "      <th>ai_safety_tags</th>\n",
       "      <th>post_count_in_ai_safety</th>\n",
       "      <th>_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>bio</th>\n",
       "      <th>...</th>\n",
       "      <th>organization</th>\n",
       "      <th>careerStage</th>\n",
       "      <th>website</th>\n",
       "      <th>linkedinProfileURL</th>\n",
       "      <th>githubProfileURL</th>\n",
       "      <th>twitterProfileURL</th>\n",
       "      <th>postCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>profileTagIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmk3nLpQE89dMRzzN</td>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>Eliezer Yudkowsky</td>\n",
       "      <td>153177</td>\n",
       "      <td>1907</td>\n",
       "      <td>[MIRI, MIRI]</td>\n",
       "      <td>2</td>\n",
       "      <td>nmk3nLpQE89dMRzzN</td>\n",
       "      <td>eliezer_yudkowsky</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>952</td>\n",
       "      <td>7699</td>\n",
       "      <td>2009-02-23T21:58:56.739Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r38pkCm7wF4M44MDQ</td>\n",
       "      <td>Raemon</td>\n",
       "      <td>Raemon</td>\n",
       "      <td>59085</td>\n",
       "      <td>731</td>\n",
       "      <td>[MIRI, AI Governance]</td>\n",
       "      <td>2</td>\n",
       "      <td>r38pkCm7wF4M44MDQ</td>\n",
       "      <td>raemon</td>\n",
       "      <td>LessWrong team member / moderator. I've been a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>491</td>\n",
       "      <td>8582</td>\n",
       "      <td>2010-09-09T02:09:20.629Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N9zj5qpTfqmbn9dro</td>\n",
       "      <td>Zvi</td>\n",
       "      <td>Zvi</td>\n",
       "      <td>53718</td>\n",
       "      <td>146</td>\n",
       "      <td>[AI Governance, AI Governance, Chain-of-Though...</td>\n",
       "      <td>3</td>\n",
       "      <td>N9zj5qpTfqmbn9dro</td>\n",
       "      <td>zvi</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thezvi.wordpress.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>1476</td>\n",
       "      <td>2009-03-31T20:54:54.077Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2aoRX3ookcCozcb3m</td>\n",
       "      <td>RobbBB</td>\n",
       "      <td>Rob Bensinger</td>\n",
       "      <td>22702</td>\n",
       "      <td>1384</td>\n",
       "      <td>[MIRI, MIRI, MIRI, MIRI, MIRI]</td>\n",
       "      <td>5</td>\n",
       "      <td>2aoRX3ookcCozcb3m</td>\n",
       "      <td>robbbb</td>\n",
       "      <td>Communications @ MIRI. Unless otherwise indica...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>2232</td>\n",
       "      <td>2012-08-10T00:50:11.669Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfZAq9eZxs4BB4Ji5</td>\n",
       "      <td>ryan_greenblatt</td>\n",
       "      <td>ryan_greenblatt</td>\n",
       "      <td>19977</td>\n",
       "      <td>4823</td>\n",
       "      <td>[Outer Alignment, AI Governance, AI Governance]</td>\n",
       "      <td>3</td>\n",
       "      <td>dfZAq9eZxs4BB4Ji5</td>\n",
       "      <td>ryan_greenblatt</td>\n",
       "      <td>I'm the chief scientist at Redwood Research.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1893</td>\n",
       "      <td>2021-06-08T20:21:15.520Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BCmzFRdQhqLPREvat</td>\n",
       "      <td>ricraz</td>\n",
       "      <td>Richard_Ngo</td>\n",
       "      <td>19906</td>\n",
       "      <td>2854</td>\n",
       "      <td>[Inner Alignment, Inner Alignment, AI Governance]</td>\n",
       "      <td>3</td>\n",
       "      <td>BCmzFRdQhqLPREvat</td>\n",
       "      <td>ricraz</td>\n",
       "      <td>Formerly alignment and governance researcher a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>1114</td>\n",
       "      <td>2013-07-14T15:42:06.397Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6LYNw2uGfYnD4pX2</td>\n",
       "      <td>lsusr</td>\n",
       "      <td>lsusr</td>\n",
       "      <td>18664</td>\n",
       "      <td>25</td>\n",
       "      <td>[Mesa-Optimization]</td>\n",
       "      <td>1</td>\n",
       "      <td>n6LYNw2uGfYnD4pX2</td>\n",
       "      <td>lsusr</td>\n",
       "      <td>Here is a [list of all my public writings and ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "      <td>1735</td>\n",
       "      <td>2019-08-03T22:27:09.960Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4fh2AAe3n7oBviyxx</td>\n",
       "      <td>orthonormal</td>\n",
       "      <td>orthonormal</td>\n",
       "      <td>17953</td>\n",
       "      <td>288</td>\n",
       "      <td>[Mesa-Optimization]</td>\n",
       "      <td>1</td>\n",
       "      <td>4fh2AAe3n7oBviyxx</td>\n",
       "      <td>orthonormal</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>2824</td>\n",
       "      <td>2009-03-22T16:06:51.665Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AThTtkDufXp3rmMDa</td>\n",
       "      <td>evhub</td>\n",
       "      <td>evhub</td>\n",
       "      <td>14730</td>\n",
       "      <td>4677</td>\n",
       "      <td>[MIRI]</td>\n",
       "      <td>1</td>\n",
       "      <td>AThTtkDufXp3rmMDa</td>\n",
       "      <td>evhub</td>\n",
       "      <td>Evan Hubinger (he/him/his) ([evanjhub@gmail.co...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>805</td>\n",
       "      <td>2017-01-17T06:05:22.405Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rx7xLaHCh3m7Po385</td>\n",
       "      <td>Buck</td>\n",
       "      <td>Buck</td>\n",
       "      <td>14669</td>\n",
       "      <td>3100</td>\n",
       "      <td>[AI Governance]</td>\n",
       "      <td>1</td>\n",
       "      <td>rx7xLaHCh3m7Po385</td>\n",
       "      <td>buck</td>\n",
       "      <td>CEO at Redwood Research.\\n\\nAI safety is a hig...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>569</td>\n",
       "      <td>2018-04-20T18:36:03.024Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gSKzrqGFdS7DkXhuE</td>\n",
       "      <td>jessica.liu.taylor</td>\n",
       "      <td>jessicata</td>\n",
       "      <td>10263</td>\n",
       "      <td>824</td>\n",
       "      <td>[MIRI, MIRI]</td>\n",
       "      <td>2</td>\n",
       "      <td>gSKzrqGFdS7DkXhuE</td>\n",
       "      <td>jessica-liu-taylor</td>\n",
       "      <td>Jessica Taylor. CS undergrad and Master's at S...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>966</td>\n",
       "      <td>2017-06-18T22:55:04.584Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fjERoRhgjipqw3z2b</td>\n",
       "      <td>Mitchell_Porter</td>\n",
       "      <td>Mitchell_Porter</td>\n",
       "      <td>9273</td>\n",
       "      <td>6</td>\n",
       "      <td>[AI Governance]</td>\n",
       "      <td>1</td>\n",
       "      <td>fjERoRhgjipqw3z2b</td>\n",
       "      <td>mitchell_porter</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>2412</td>\n",
       "      <td>2009-05-28T02:36:19.394Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g8JkZfL8PTqAefpvx</td>\n",
       "      <td>JenniferRM</td>\n",
       "      <td>JenniferRM</td>\n",
       "      <td>8978</td>\n",
       "      <td>18</td>\n",
       "      <td>[Mesa-Optimization]</td>\n",
       "      <td>1</td>\n",
       "      <td>g8JkZfL8PTqAefpvx</td>\n",
       "      <td>jenniferrm</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>1377</td>\n",
       "      <td>2009-03-06T17:16:50.600Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DgsGzjyBXN8XSK22q</td>\n",
       "      <td>DanielFilan</td>\n",
       "      <td>DanielFilan</td>\n",
       "      <td>8942</td>\n",
       "      <td>1868</td>\n",
       "      <td>[Inner Alignment, AI Governance, Mesa-Optimiza...</td>\n",
       "      <td>3</td>\n",
       "      <td>DgsGzjyBXN8XSK22q</td>\n",
       "      <td>danielfilan</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://danielfilan.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>1396</td>\n",
       "      <td>2014-01-30T11:04:39.341Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nDpieb7g8huozpx9j</td>\n",
       "      <td>Thane Ruthenis</td>\n",
       "      <td>Thane Ruthenis</td>\n",
       "      <td>8911</td>\n",
       "      <td>852</td>\n",
       "      <td>[Mesa-Optimization, Mesa-Optimization, Mesa-Op...</td>\n",
       "      <td>5</td>\n",
       "      <td>nDpieb7g8huozpx9j</td>\n",
       "      <td>thane-ruthenis</td>\n",
       "      <td>Agent-foundations researcher. Working on [Synt...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>1000</td>\n",
       "      <td>2022-03-20T15:21:33.973Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mfgrYb4LMk7NWXsSB</td>\n",
       "      <td>tailcalled</td>\n",
       "      <td>tailcalled</td>\n",
       "      <td>7887</td>\n",
       "      <td>77</td>\n",
       "      <td>[MIRI]</td>\n",
       "      <td>1</td>\n",
       "      <td>mfgrYb4LMk7NWXsSB</td>\n",
       "      <td>tailcalled</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>2411</td>\n",
       "      <td>2015-01-27T20:50:11.327Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XLwKyCK7JmC292ZCC</td>\n",
       "      <td>Chris_Leong</td>\n",
       "      <td>Chris_Leong</td>\n",
       "      <td>7708</td>\n",
       "      <td>458</td>\n",
       "      <td>[MIRI, Inner Alignment]</td>\n",
       "      <td>2</td>\n",
       "      <td>XLwKyCK7JmC292ZCC</td>\n",
       "      <td>chris_leong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "      <td>2181</td>\n",
       "      <td>2009-05-28T03:08:43.251Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCjNiBLBPyhZq5BuM</td>\n",
       "      <td>Seth Herd</td>\n",
       "      <td>Seth Herd</td>\n",
       "      <td>7411</td>\n",
       "      <td>239</td>\n",
       "      <td>[Inner Alignment, Chain-of-Thought Alignment, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TCjNiBLBPyhZq5BuM</td>\n",
       "      <td>seth-herd</td>\n",
       "      <td>Message me here or at seth dot herd at gmail d...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>1817</td>\n",
       "      <td>2022-09-05T00:45:45.715Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QpvwBD5AtmmFDTC3T</td>\n",
       "      <td>leogao</td>\n",
       "      <td>leogao</td>\n",
       "      <td>7176</td>\n",
       "      <td>890</td>\n",
       "      <td>[Mesa-Optimization]</td>\n",
       "      <td>1</td>\n",
       "      <td>QpvwBD5AtmmFDTC3T</td>\n",
       "      <td>leogao</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>499</td>\n",
       "      <td>2020-04-19T18:50:05.381Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x5S2Kuj6TfQTGuo63</td>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>Thomas Kwa</td>\n",
       "      <td>7018</td>\n",
       "      <td>566</td>\n",
       "      <td>[MIRI]</td>\n",
       "      <td>1</td>\n",
       "      <td>x5S2Kuj6TfQTGuo63</td>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>Member of technical staff at [METR](https://me...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>800</td>\n",
       "      <td>2019-12-09T06:28:45.933Z</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId            username        displayName   karma  afKarma  \\\n",
       "0   nmk3nLpQE89dMRzzN   Eliezer_Yudkowsky  Eliezer Yudkowsky  153177     1907   \n",
       "1   r38pkCm7wF4M44MDQ              Raemon             Raemon   59085      731   \n",
       "2   N9zj5qpTfqmbn9dro                 Zvi                Zvi   53718      146   \n",
       "3   2aoRX3ookcCozcb3m              RobbBB      Rob Bensinger   22702     1384   \n",
       "4   dfZAq9eZxs4BB4Ji5     ryan_greenblatt    ryan_greenblatt   19977     4823   \n",
       "5   BCmzFRdQhqLPREvat              ricraz        Richard_Ngo   19906     2854   \n",
       "6   n6LYNw2uGfYnD4pX2               lsusr              lsusr   18664       25   \n",
       "7   4fh2AAe3n7oBviyxx         orthonormal        orthonormal   17953      288   \n",
       "8   AThTtkDufXp3rmMDa               evhub              evhub   14730     4677   \n",
       "9   rx7xLaHCh3m7Po385                Buck               Buck   14669     3100   \n",
       "10  gSKzrqGFdS7DkXhuE  jessica.liu.taylor          jessicata   10263      824   \n",
       "11  fjERoRhgjipqw3z2b     Mitchell_Porter    Mitchell_Porter    9273        6   \n",
       "12  g8JkZfL8PTqAefpvx          JenniferRM         JenniferRM    8978       18   \n",
       "13  DgsGzjyBXN8XSK22q         DanielFilan        DanielFilan    8942     1868   \n",
       "14  nDpieb7g8huozpx9j      Thane Ruthenis     Thane Ruthenis    8911      852   \n",
       "15  mfgrYb4LMk7NWXsSB          tailcalled         tailcalled    7887       77   \n",
       "16  XLwKyCK7JmC292ZCC         Chris_Leong        Chris_Leong    7708      458   \n",
       "17  TCjNiBLBPyhZq5BuM           Seth Herd          Seth Herd    7411      239   \n",
       "18  QpvwBD5AtmmFDTC3T              leogao             leogao    7176      890   \n",
       "19  x5S2Kuj6TfQTGuo63          thomas-kwa         Thomas Kwa    7018      566   \n",
       "\n",
       "                                       ai_safety_tags  \\\n",
       "0                                        [MIRI, MIRI]   \n",
       "1                               [MIRI, AI Governance]   \n",
       "2   [AI Governance, AI Governance, Chain-of-Though...   \n",
       "3                      [MIRI, MIRI, MIRI, MIRI, MIRI]   \n",
       "4     [Outer Alignment, AI Governance, AI Governance]   \n",
       "5   [Inner Alignment, Inner Alignment, AI Governance]   \n",
       "6                                 [Mesa-Optimization]   \n",
       "7                                 [Mesa-Optimization]   \n",
       "8                                              [MIRI]   \n",
       "9                                     [AI Governance]   \n",
       "10                                       [MIRI, MIRI]   \n",
       "11                                    [AI Governance]   \n",
       "12                                [Mesa-Optimization]   \n",
       "13  [Inner Alignment, AI Governance, Mesa-Optimiza...   \n",
       "14  [Mesa-Optimization, Mesa-Optimization, Mesa-Op...   \n",
       "15                                             [MIRI]   \n",
       "16                            [MIRI, Inner Alignment]   \n",
       "17  [Inner Alignment, Chain-of-Thought Alignment, ...   \n",
       "18                                [Mesa-Optimization]   \n",
       "19                                             [MIRI]   \n",
       "\n",
       "    post_count_in_ai_safety                _id                slug  \\\n",
       "0                         2  nmk3nLpQE89dMRzzN   eliezer_yudkowsky   \n",
       "1                         2  r38pkCm7wF4M44MDQ              raemon   \n",
       "2                         3  N9zj5qpTfqmbn9dro                 zvi   \n",
       "3                         5  2aoRX3ookcCozcb3m              robbbb   \n",
       "4                         3  dfZAq9eZxs4BB4Ji5     ryan_greenblatt   \n",
       "5                         3  BCmzFRdQhqLPREvat              ricraz   \n",
       "6                         1  n6LYNw2uGfYnD4pX2               lsusr   \n",
       "7                         1  4fh2AAe3n7oBviyxx         orthonormal   \n",
       "8                         1  AThTtkDufXp3rmMDa               evhub   \n",
       "9                         1  rx7xLaHCh3m7Po385                buck   \n",
       "10                        2  gSKzrqGFdS7DkXhuE  jessica-liu-taylor   \n",
       "11                        1  fjERoRhgjipqw3z2b     mitchell_porter   \n",
       "12                        1  g8JkZfL8PTqAefpvx          jenniferrm   \n",
       "13                        3  DgsGzjyBXN8XSK22q         danielfilan   \n",
       "14                        5  nDpieb7g8huozpx9j      thane-ruthenis   \n",
       "15                        1  mfgrYb4LMk7NWXsSB          tailcalled   \n",
       "16                        2  XLwKyCK7JmC292ZCC         chris_leong   \n",
       "17                        5  TCjNiBLBPyhZq5BuM           seth-herd   \n",
       "18                        1  QpvwBD5AtmmFDTC3T              leogao   \n",
       "19                        1  x5S2Kuj6TfQTGuo63          thomas-kwa   \n",
       "\n",
       "                                                  bio  ...  organization  \\\n",
       "0                                                      ...           NaN   \n",
       "1   LessWrong team member / moderator. I've been a...  ...           NaN   \n",
       "2                                                      ...           NaN   \n",
       "3   Communications @ MIRI. Unless otherwise indica...  ...           NaN   \n",
       "4        I'm the chief scientist at Redwood Research.  ...           NaN   \n",
       "5   Formerly alignment and governance researcher a...  ...           NaN   \n",
       "6   Here is a [list of all my public writings and ...  ...           NaN   \n",
       "7                                                      ...           NaN   \n",
       "8   Evan Hubinger (he/him/his) ([evanjhub@gmail.co...  ...           NaN   \n",
       "9   CEO at Redwood Research.\\n\\nAI safety is a hig...  ...           NaN   \n",
       "10  Jessica Taylor. CS undergrad and Master's at S...  ...           NaN   \n",
       "11                                                     ...           NaN   \n",
       "12                                                     ...           NaN   \n",
       "13                                                     ...           NaN   \n",
       "14  Agent-foundations researcher. Working on [Synt...  ...           NaN   \n",
       "15                                                     ...           NaN   \n",
       "16                                                     ...           NaN   \n",
       "17  Message me here or at seth dot herd at gmail d...  ...           NaN   \n",
       "18                                                     ...           NaN   \n",
       "19  Member of technical staff at [METR](https://me...  ...           NaN   \n",
       "\n",
       "    careerStage                 website linkedinProfileURL  githubProfileURL  \\\n",
       "0           NaN                    None                NaN               NaN   \n",
       "1           NaN                    None                NaN               NaN   \n",
       "2           NaN    thezvi.wordpress.com                NaN               NaN   \n",
       "3           NaN                    None                NaN               NaN   \n",
       "4           NaN                    None                NaN               NaN   \n",
       "5           NaN                    None                NaN               NaN   \n",
       "6           NaN                    None                NaN               NaN   \n",
       "7           NaN                    None                NaN               NaN   \n",
       "8           NaN                    None                NaN               NaN   \n",
       "9           NaN                    None                NaN               NaN   \n",
       "10          NaN                    None                NaN               NaN   \n",
       "11          NaN                    None                NaN               NaN   \n",
       "12          NaN                    None                NaN               NaN   \n",
       "13          NaN  http://danielfilan.com                NaN               NaN   \n",
       "14          NaN                    None                NaN               NaN   \n",
       "15          NaN                    None                NaN               NaN   \n",
       "16          NaN                    None                NaN               NaN   \n",
       "17          NaN                    None                NaN               NaN   \n",
       "18          NaN                    None                NaN               NaN   \n",
       "19          NaN                    None                NaN               NaN   \n",
       "\n",
       "    twitterProfileURL  postCount  commentCount                 createdAt  \\\n",
       "0                 NaN        952          7699  2009-02-23T21:58:56.739Z   \n",
       "1                 NaN        491          8582  2010-09-09T02:09:20.629Z   \n",
       "2                 NaN       1000          1476  2009-03-31T20:54:54.077Z   \n",
       "3                 NaN        125          2232  2012-08-10T00:50:11.669Z   \n",
       "4                 NaN         50          1893  2021-06-08T20:21:15.520Z   \n",
       "5                 NaN        169          1114  2013-07-14T15:42:06.397Z   \n",
       "6                 NaN        290          1735  2019-08-03T22:27:09.960Z   \n",
       "7                 NaN         70          2824  2009-03-22T16:06:51.665Z   \n",
       "8                 NaN         72           805  2017-01-17T06:05:22.405Z   \n",
       "9                 NaN         47           569  2018-04-20T18:36:03.024Z   \n",
       "10                NaN         70           966  2017-06-18T22:55:04.584Z   \n",
       "11                NaN         48          2412  2009-05-28T02:36:19.394Z   \n",
       "12                NaN         34          1377  2009-03-06T17:16:50.600Z   \n",
       "13                NaN        152          1396  2014-01-30T11:04:39.341Z   \n",
       "14                NaN         46          1000  2022-03-20T15:21:33.973Z   \n",
       "15                NaN        107          2411  2015-01-27T20:50:11.327Z   \n",
       "16                NaN        229          2181  2009-05-28T03:08:43.251Z   \n",
       "17                NaN         43          1817  2022-09-05T00:45:45.715Z   \n",
       "18                NaN         32           499  2020-04-19T18:50:05.381Z   \n",
       "19                NaN         26           800  2019-12-09T06:28:45.933Z   \n",
       "\n",
       "   profileTagIds  \n",
       "0             []  \n",
       "1             []  \n",
       "2             []  \n",
       "3             []  \n",
       "4             []  \n",
       "5             []  \n",
       "6             []  \n",
       "7             []  \n",
       "8             []  \n",
       "9             []  \n",
       "10            []  \n",
       "11            []  \n",
       "12            []  \n",
       "13            []  \n",
       "14            []  \n",
       "15            []  \n",
       "16            []  \n",
       "17            []  \n",
       "18            []  \n",
       "19            []  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesswrong_df = pd.read_json('raw-data/lesswrong/2025-09-27/users_top20.json')\n",
    "lesswrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "09d2555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   userId                   20 non-null     object \n",
      " 1   username                 20 non-null     object \n",
      " 2   displayName              20 non-null     object \n",
      " 3   karma                    20 non-null     int64  \n",
      " 4   afKarma                  20 non-null     int64  \n",
      " 5   ai_safety_tags           20 non-null     object \n",
      " 6   post_count_in_ai_safety  20 non-null     int64  \n",
      " 7   _id                      20 non-null     object \n",
      " 8   slug                     20 non-null     object \n",
      " 9   bio                      20 non-null     object \n",
      " 10  jobTitle                 0 non-null      float64\n",
      " 11  organization             0 non-null      float64\n",
      " 12  careerStage              0 non-null      float64\n",
      " 13  website                  2 non-null      object \n",
      " 14  linkedinProfileURL       0 non-null      float64\n",
      " 15  githubProfileURL         0 non-null      float64\n",
      " 16  twitterProfileURL        0 non-null      float64\n",
      " 17  postCount                20 non-null     int64  \n",
      " 18  commentCount             20 non-null     int64  \n",
      " 19  createdAt                20 non-null     object \n",
      " 20  profileTagIds            20 non-null     object \n",
      "dtypes: float64(6), int64(5), object(10)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "lesswrong_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f408b",
   "metadata": {},
   "source": [
    "## Semantic Scholar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7fb7492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "54feaa85-ea48-4382-9cec-945366069b17",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Meskó, E. Topol",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "10",
         "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Sam Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilė Lukošiūtė, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, C. McKinnon, Chris Olah, D. Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, John Kernion, Jamie Kerr, J. Mueller, Jeffrey Ladish, J. Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noem'i Mercado, Nova Dassarma, Robin Larson, Sam McCandlish, S. Kundu, Scott Johnston, Shauna Kravec, S. E. Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom B. Brown, T. Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Benjamin Mann, Jared Kaplan",
         "2022",
         "Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks.",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "https://arxiv.org/pdf/2211.03540",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "arXiv.org",
         "Computer Science, Computer Science, Linguistics",
         "149",
         "bd891ffa97410f74480c289f6510913c",
         "10.48550/arXiv.2211.03540",
         "2211.0354",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Linguistics'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "11",
         "f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "An Incentive-Compatible Energy Trading Framework for Neighborhood Area Networks With Shared Energy Storage",
         "C. Mediwaththe, M. Shaw, S. Halgamuge, David B. Smith, P. Scott",
         "2020",
         "Here, a novel energy trading system is proposed for demand-side management of a neighborhood area network (NAN) consisting of a shared energy storage (SES) provider, users with non-dispatchable energy generation, and an electricity retailer. In a leader–follower Stackelberg game, the SES provider first maximizes their revenue by setting a price signal and trading energy with the grid. Then, by following the SES provider's actions, the retailer minimizes social cost for the users, i.e., the sum of the total users’ cost when they interact with the SES and the total cost for supplying grid energy to the users. A pricing strategy, which incorporates mechanism design, is proposed to make the system incentive-compatible by rewarding users who disclose true energy usage information. A unique Stackelberg equilibrium is achieved where the SES provider's revenue is maximized and the user-level social cost is minimized, which also rewards the retailer. A case study with realistic energy demand and generation data demonstrates 28–45% peak demand reduction of the NAN, depending on the number of participating users, compared to a system without SES. Simulation results confirm that the retailer can also benefit financially, in addition to the SES provider and the users.",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "https://arxiv.org/pdf/2008.10384",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "IEEE Transactions on Sustainable Energy",
         "Engineering, Computer Science, Engineering, Economics, Environmental Science",
         "114",
         "203c35336c8ae692de21ba24e812a8e8",
         "10.1109/TSTE.2019.2895387",
         "2008.10384",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "12",
         "dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
         "Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",
         "2024",
         "As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in mathematical reasoning. It consists of 3,400 test cases, primarily focused on competition- and Olympiad-level math problems. Each test case contains a step-by-step solution with error location annotated by human experts. Models are required to identify the earliest step that contains an error, or conclude that all steps are correct. We conduct extensive evaluation on ProcessBench, involving two types of models: process reward models (PRMs) and critic models, where for the latter we prompt general language models to critique each solution step by step. We draw two main observations: (1) Existing PRMs typically fail to generalize to more challenging math problems beyond GSM8K and MATH. They underperform both critic models (i.e., prompted general language models) and our own trained PRM that is straightforwardly fine-tuned on the PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has demonstrated the critique capability competitive with the proprietary model GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We hope ProcessBench can foster future research in reasoning process assessment, paving the way toward scalable oversight of language models.",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "https://arxiv.org/pdf/2412.06559.pdf",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Mathematics, Computer Science",
         "104",
         "171b07e013043a4f09b897d234418135",
         "10.48550/arXiv.2412.06559",
         "2412.06559",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "13",
         "41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "A new science of emotion: implications for functional neurological disorder.",
         "Johannes Jungilligens, Sara Paredes-Echeverri, S. Popkirov, L. F. Barrett, D. Perez",
         "2022",
         "Functional neurological disorder (FND) reflects impairments in brain networks leading to distressing motor, sensory, and/or cognitive symptoms that demonstrate positive clinical signs on examination incongruent with other conditions. A central issue in historical and contemporary formulations of FND has been the mechanistic and etiological role of emotions. However, the debate has mostly omitted fundamental questions about the nature of emotions in the first place. In this perspective article, we first outline a set of relevant working principles of the brain (e.g., allostasis, predictive processing, interoception, and affect), followed by a focused review of the theory of constructed emotion to introduce a new understanding of what emotions are. Building on this theoretical framework, we formulate how altered emotion category construction can be an integral component of the pathophysiology of FND and related functional somatic symptoms. In doing so, we address several themes for the FND field including: 1) how energy regulation and the process of emotion category construction relate to symptom generation, including revisiting alexithymia, \"panic attack without panic\", dissociation, insecure attachment, and the influential role of life experiences; 2) re-interpret select neurobiological research findings in FND cohorts through the lens of the theory of constructed emotion to illustrate its potential mechanistic relevance; and 3) discuss therapeutic implications. While we continue to support that FND is mechanistically and etiologically heterogenous, consideration of how the theory of constructed emotion relates to the generation and maintenance of functional neurological and functional somatic symptoms offers an integrated viewpoint that cuts across neurology, psychiatry, psychology, and cognitive-affective neuroscience.",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "https://academic.oup.com/brain/article-pdf/145/8/2648/49120115/awac204.pdf",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "Brain : a journal of neurology",
         "Medicine, Psychology",
         "101",
         "a22d0fe84e5c1374d4c95b8a6396a8d9",
         "10.1093/brain/awac204",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "14",
         "1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "Targeting High Ability Entrepreneurs Using Community Information: Mechanism Design in the Field",
         "Reshmaan N. Hussam, Natalia Rigol, Benjamin N. Roth",
         "2022",
         "Identifying high-growth microentrepreneurs in low-income countries remains a challenge due to a scarcity of verifiable information. With a cash grant experiment in India we demonstrate that community knowledge can help target high-growth microentrepreneurs; while the average marginal return to capital in our sample is 9.4 percent per month, microentrepreneurs reported in the top third of the community are estimated to have marginal returns to capital between 24 percent and 30 percent per month. Further we find evidence that community members distort their predictions when they can influence the distribution of resources. Finally, we demonstrate that simple mechanisms can realign incentives for truthful reporting. (JEL D82, G21, I38, L25, L26, O12, O16)",
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         null,
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "The American Economic Review",
         "Business, Economics, Business",
         "97",
         "5643d31ff930134acee2c1071dac09b5",
         "10.1257/aer.20200751",
         null,
         "[{'source': 'external', 'category': 'Business'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Business'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "15",
         "1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "AI-Generated Incentive Mechanism and Full-Duplex Semantic Communications for Information Sharing",
         "Hongyang Du, Jiacheng Wang, Dusist Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim",
         "2023",
         "The next generation of Internet services, such as Metaverse, rely on mixed reality (MR) technology to provide immersive user experiences. However, limited computation power of MR headset-mounted devices (HMDs) hinders the deployment of such services. Therefore, we propose an efficient information-sharing scheme based on full-duplex device-to-device (D2D) semantic communications to address this issue. Our approach enables users to avoid heavy and repetitive computational tasks, such as artificial intelligence-generated content (AIGC) in the view images of all MR users. Specifically, a user can transmit the generated content and semantic information extracted from their view image to nearby users, who can then use this information to obtain the spatial matching of computation results under their view images. We analyze the performance of full-duplex D2D communications, including the achievable rate and bit error probability, by using generalized small-scale fading models. To facilitate semantic information sharing among users, we design a contract theoretic AI-generated incentive mechanism. The proposed diffusion model generates the optimal contract design, outperforming two deep reinforcement learning algorithms, i.e., proximal policy optimization and soft actor-critic algorithms. Our numerical analysis experiment proves the effectiveness of our proposed methods. The code for this paper is available at https://github.com/HongyangDu/SemSharing.",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "https://www.techrxiv.org/articles/preprint/AI-Generated_Incentive_Mechanism_and_Full-Duplex_Semantic_Communications_for_Information_Sharing/22209178/1/files/39468979.pdf",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "IEEE Journal on Selected Areas in Communications",
         "Engineering, Computer Science, Computer Science",
         "96",
         "4265596316b0f66567d76928f99a27fd",
         "10.1109/JSAC.2023.3287547",
         "2303.01896",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "16",
         "8efaf945b1b649bf905e0b9624d23760335aa614",
         "Uncertainty in Mechanism Design",
         "Giuseppe Lopomo, Luca Rigotti, Chris Shannon",
         "2021",
         "We consider mechanism design problems with Knightian uncertainty formalized using incomplete preferences, as in Bewley (1986). Without completeness, decision making depends on a set of beliefs, and an action is preferred to another if and only if it has larger expected utility for all beliefs in this set. We consider two natural notions of incentive compatibility in this setting: maximal incentive compatibility requires that no strategy has larger expected utility than reporting truthfully for all beliefs, while optimal incentive compatibility requires that reporting truthfully has larger expected utility than all other strategies for all beliefs. In a model with a continuum of types, we show that optimal incentive compatibility is equivalent to ex-post incentive compatibility under fairly general conditions on beliefs. In a model with a discrete type space, we characterize full extraction of rents generated from private information. We show that full extraction is generically possible with maximal incentive compatible mechanisms, but requires sufficient disagreement across types, which neither holds nor fails generically, with optimal incentive compatible mechanisms.",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         "https://arxiv.org/pdf/2108.12633",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         null,
         "Economics, Economics",
         "90",
         "36c493c55efcd610b95cacde98fab544",
         "10.2139/ssrn.3774581",
         "2108.12633",
         "[{'source': 'external', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "17",
         "6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
         "Atticus Geiger, D. Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah D. Goodman, Christopher Potts, Thomas F. Icard",
         "2023",
         "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "https://arxiv.org/pdf/2301.04709.pdf",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         null,
         "Computer Science, Computer Science, Philosophy",
         "80",
         "b3611594ff729546b6130e75d7322abd",
         null,
         "2301.04709",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:15.857258+00:00",
         "2025-09-29 20:01:45.343601+00:00"
        ],
        [
         "18",
         "0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Rationally Design a Sulfur Cathode with Solid‐Phase Conversion Mechanism for High Cycle‐Stable Li–S Batteries",
         "Bin He, Zhixiang Rao, Zexiao Cheng, Dongdong Liu, Danqi He, Jie Chen, Ziyun Miao, Lixia Yuan, Zhen Li, Yunhui Huang",
         "2021",
         "Solid–solid reactions are very effective for solving the main challenges of lithium–sulfur (Li–S) batteries, such as the shuttle effect of polysulfides and the high dependence of electrolyte consumption. However, the low sulfur content and sluggish redox kinetics of such cathodes dramatically limit the practical energy density of Li–S batteries. Here a rationally designed hierarchical cathode to simultaneously solve above‐mentioned challenges is reported. With nanoscale sulfur as the core, selenium‐doped sulfurized polyacrylonitrile (PAN/S7Se) as the shell and micron‐scale secondary particle morphology, the proposed cathode realizes excellent solid–solid reaction kinetics in a commercial carbonate electrolyte under high active species loading and a relatively low electrolyte/sulfur ratio. Such an approach provides a promising solution toward practical lithium sulfur batteries.",
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         null,
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Advanced Energy Materials",
         "Materials Science, Materials Science, Chemistry, Engineering",
         "78",
         "55c45ab4d8c970aeb6f70267874c70d1",
         "10.1002/aenm.202003690",
         null,
         "[{'source': 'external', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "19",
         "1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nonnegative spatial factorization applied to spatial genomics",
         "F. W. Townes, B. Engelhardt",
         "2022",
         "This paper presents nonnegative spatial factorization, a general framework for spatially aware and interpretable dimension reduction for high-dimensional spatial data, and its application to spatial transcriptomics analysis. Nonnegative matrix factorization (NMF) is widely used to analyze high-dimensional count data because, in contrast to real-valued alternatives such as factor analysis, it produces an interpretable parts-based representation. However, in applications such as spatial transcriptomics, NMF fails to incorporate known structure between observations. Here, we present nonnegative spatial factorization (NSF), a spatially-aware probabilistic dimension reduction model based on transformed Gaussian processes that naturally encourages sparsity and scales to tens of thousands of observations. NSF recovers ground truth factors more accurately than real-valued alternatives such as MEFISTO in simulations, and has lower out-of-sample prediction error than probabilistic NMF on three spatial transcriptomics datasets from mouse brain and liver. Since not all patterns of gene expression have spatial correlations, we also propose a hybrid extension of NSF that combines spatial and nonspatial components, enabling quantification of spatial importance for both observations and features. A TensorFlow implementation of NSF is available from https://github.com/willtownes/nsf-paper .",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "https://www.nature.com/articles/s41592-022-01687-w.pdf",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nature Methods",
         "Medicine, Computer Science, Biology",
         "72",
         "86d4a32c9b25afc8510904668935d1b6",
         "10.1038/s41592-022-01687-w",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "20",
         "7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration",
         "T. Bodrito, Alexandre Zouaoui, J. Chanussot, J. Mairal",
         "2021",
         "Hyperspectral imaging offers new perspectives for diverse applications, ranging from the monitoring of the environment using airborne or satellite remote sensing, precision farming, food safety, planetary exploration, or astrophysics. Unfortunately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth\"clean\"hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difficult, in contrast to traditional RGB imaging problems where deep models tend to shine. In this paper, we advocate instead for a hybrid approach based on sparse coding principles that retains the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data. We show on various denoising benchmarks that our method is computationally efficient and significantly outperforms the state of the art.",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "https://arxiv.org/pdf/2111.09708.pdf",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "Neural Information Processing Systems",
         "Computer Science, Engineering, Environmental Science, Computer Science, Engineering",
         "70",
         "043f0c78b6d43bf864f00572f1fa44be",
         null,
         "2111.09708",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "21",
         "70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Parcels and particles: Markov blankets in the brain",
         "Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr, Ines Hip'olito, L. Magrou, Adeel Razi",
         "2020",
         "At the inception of human brain mapping, two principles of functional anatomy underwrote most conceptions—and analyses—of distributed brain responses: namely, functional segregation and integration. There are currently two main approaches to characterizing functional integration. The first is a mechanistic modeling of connectomics in terms of directed effective connectivity that mediates neuronal message passing and dynamics on neuronal circuits. The second phenomenological approach usually characterizes undirected functional connectivity (i.e., measurable correlations), in terms of intrinsic brain networks, self-organized criticality, dynamical instability, and so on. This paper describes a treatment of effective connectivity that speaks to the emergence of intrinsic brain networks and critical dynamics. It is predicated on the notion of Markov blankets that play a fundamental role in the self-organization of far from equilibrium systems. Using the apparatus of the renormalization group, we show that much of the phenomenology found in network neuroscience is an emergent property of a particular partition of neuronal states, over progressively coarser scales. As such, it offers a way of linking dynamics on directed graphs to the phenomenology of intrinsic brain networks.",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "https://direct.mit.edu/netn/article-pdf/5/1/211/1889785/netn_a_00175.pdf",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Network Neuroscience",
         "Biology, Medicine, Computer Science, Physics",
         "70",
         "a28f67baf975f5d1bee41d5db29f602d",
         "10.1162/netn_a_00175",
         "2007.09704",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Physics'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "22",
         "980255db598dc210d6a784db247d159d3ea1cf3f",
         "Interpretable Multi-Modal Image Registration Network Based on Disentangled Convolutional Sparse Coding",
         "Xin Deng, Enpeng Liu, Shengxi Li, Yiping Duan, Mai Xu",
         "2023",
         "Multi-modal image registration aims to spatially align two images from different modalities to make their feature points match with each other. Captured by different sensors, the images from different modalities often contain many distinct features, which makes it challenging to find their accurate correspondences. With the success of deep learning, many deep networks have been proposed to align multi-modal images, however, they are mostly lack of interpretability. In this paper, we first model the multi-modal image registration problem as a disentangled convolutional sparse coding (DCSC) model. In this model, the multi-modal features that are responsible for alignment (RA features) are well separated from the features that are not responsible for alignment (nRA features). By only allowing the RA features to participate in the deformation field prediction, we can eliminate the interference of the nRA features to improve the registration accuracy and efficiency. The optimization process of the DCSC model to separate the RA and nRA features is then turned into a deep network, namely Interpretable Multi-modal Image Registration Network (InMIR-Net). To ensure the accurate separation of RA and nRA features, we further design an accompanying guidance network (AG-Net) to supervise the extraction of RA features in InMIR-Net. The advantage of InMIR-Net is that it provides a universal framework to tackle both rigid and non-rigid multi-modal image registration tasks. Extensive experimental results verify the effectiveness of our method on both rigid and non-rigid registrations on various multi-modal image datasets, including RGB/depth images, RGB/near-infrared (NIR) images, RGB/multi-spectral images, T1/T2 weighted magnetic resonance (MR) images and computed tomography (CT)/MR images. The codes are available at https://github.com/lep990816/Interpretable-Multi-modal-Image-Registration.",
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         null,
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         "IEEE Transactions on Image Processing",
         "Medicine, Computer Science, Computer Science, Engineering",
         "66",
         "540673f1f88c28586b4306e40b8d041f",
         "10.1109/TIP.2023.3240024",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "23",
         "41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Evolution of central neural circuits: state of the art and perspectives",
         "Ruairí J. V. Roberts, S. Pop, L. Prieto-Godino",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Nature Reviews Neuroscience",
         "Medicine, Biology",
         "62",
         "a1837ac9580622b09b74da0595b69e74",
         "10.1038/s41583-022-00644-y",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "24",
         "79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Reducing the Cognitive Footprint of Brain Tumor Surgery",
         "N. Dadario, Bledi C. Brahimaj, J. Yeung, M. Sughrue",
         "2021",
         "The surgical management of brain tumors is based on the principle that the extent of resection improves patient outcomes. Traditionally, neurosurgeons have considered that lesions in “non-eloquent” cerebrum can be more aggressively surgically managed compared to lesions in “eloquent” regions with more known functional relevance. Furthermore, advancements in multimodal imaging technologies have improved our ability to extend the rate of resection while minimizing the risk of inducing new neurologic deficits, together referred to as the “onco-functional balance.” However, despite the common utilization of invasive techniques such as cortical mapping to identify eloquent tissue responsible for language and motor functions, glioma patients continue to present post-operatively with poor cognitive morbidity in higher-order functions. Such observations are likely related to the difficulty in interpreting the highly-dimensional information these technologies present to us regarding cognition in addition to our classically poor understanding of the functional and structural neuroanatomy underlying complex higher-order cognitive functions. Furthermore, reduction of the brain into isolated cortical regions without consideration of the complex, interacting brain networks which these regions function within to subserve higher-order cognition inherently prevents our successful navigation of true eloquent and non-eloquent cerebrum. Fortunately, recent large-scale movements in the neuroscience community, such as the Human Connectome Project (HCP), have provided updated neural data detailing the many intricate macroscopic connections between cortical regions which integrate and process the information underlying complex human behavior within a brain “connectome.” Connectomic data can provide us better maps on how to understand convoluted cortical and subcortical relationships between tumor and human cerebrum such that neurosurgeons can begin to make more informed decisions during surgery to maximize the onco-functional balance. However, connectome-based neurosurgery and related applications for neurorehabilitation are relatively nascent and require further work moving forward to optimize our ability to add highly valuable connectomic data to our surgical armamentarium. In this manuscript, we review four concepts with detailed examples which will help us better understand post-operative cognitive outcomes and provide a guide for how to utilize connectomics to reduce cognitive morbidity following cerebral surgery.",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "https://www.frontiersin.org/articles/10.3389/fneur.2021.711646/pdf",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Frontiers in Neurology",
         "Medicine, Medicine, Psychology",
         "61",
         "e26c187369f3f43944783d2070633188",
         "10.3389/fneur.2021.711646",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "25",
         "9854f38388b01991f461a25fefd1f67fecb9731f",
         "The Architecture of Human Memory: Insights from Human Single-Neuron Recordings",
         "Ueli Rutishauser, L. Reddy, F. Mormann, J. Sarnthein",
         "2020",
         "Deciphering the mechanisms of human memory is a central goal of neuroscience, both from the point of view of the fundamental biology of memory and for its translational relevance. Here, we review some contributions that recordings from neurons in humans implanted with electrodes for clinical purposes have made toward this goal. Recordings from the medial temporal lobe, including the hippocampus, reveal the existence of two classes of cells: those encoding highly selective and invariant representations of abstract concepts, and memory-selective cells whose activity is related to familiarity and episodic retrieval. Insights derived from observing these cells in behaving humans include that semantic representations are activated before episodic representations, that memory content and memory strength are segregated, and that the activity of both types of cells is related to subjective awareness as expected from a substrate for declarative memory. Visually selective cells can remain persistently active for several seconds, thereby revealing a cellular substrate for working memory in humans. An overarching insight is that the neural code of human memory is interpretable at the single-neuron level. Jointly, intracranial recording studies are starting to reveal aspects of the building blocks of human memory at the single-cell level. This work establishes a bridge to cellular-level work in animals on the one hand, and the extensive literature on noninvasive imaging in humans on the other hand. More broadly, this work is a step toward a detailed mechanistic understanding of human memory that is needed to develop therapies for human memory disorders.",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "https://www.jneurosci.org/content/jneuro/41/5/883.full.pdf",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "Journal of Neuroscience",
         "Medicine, Biology",
         "57",
         "ffce458267bc401455e35aa57197a0e9",
         "10.1523/JNEUROSCI.1648-20.2020",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "26",
         "85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "Mechanisms and mathematical modelling of ROS production by the mitochondrial electron transport chain.",
         "Sandeep Chenna, W. Koopman, J. Prehn, N. Connolly",
         "2022",
         "Reactive oxygen species (ROS) are recognised both as damaging molecules and intracellular signalling entities. In addition to its role in ATP generation, the mitochondrial electron transport chain (ETC) constitutes a relevant source of mitochondrial ROS, in particular during pathological conditions. Mitochondrial ROS homeostasis depends on species- and site-dependent ROS production, their bioreactivity, diffusion, and scavenging. However, our quantitative understanding of mitochondrial ROS homeostasis has thus far been hampered by technical limitations, including lack of truly site- and/or ROS-specific reporter molecules. In this context, the use of computational models is of great value to complement and interpret empirical data, as well as to predict variables that are difficult to assess experimentally. During the last decades, various mechanistic models of ETC-mediated ROS production have been developed. Although these often-complex models have generated novel insights, their parameterisation, analysis, and integration with other computational models is not straightforward. In contrast, phenomenological (sometimes termed \"minimal\") models use a relatively small set of equations to describe empirical relationship(s) between ROS-related and other parameters, and generally aim to explore system behaviour and generate hypotheses for experimental validation. In this review, we first discuss ETC-linked ROS homeostasis and introduce various detailed mechanistic models. Next, we present how bioenergetic parameters (e.g. NADH/NAD+ ratio, mitochondrial membrane potential) relate to site-specific ROS production within the ETC and how these relationships can be used to design minimal models of ROS homeostasis. Finally, we illustrate how minimal models have been applied to explore pathophysiological aspects of ROS.",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "https://figshare.com/articles/journal_contribution/Mechanisms_and_mathematical_modeling_of_ROS_production_by_the_mitochondrial_electron_transport_chain/20308254/1/files/36272712.pdf",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "American Journal of Physiology - Cell Physiology",
         "Medicine, Mathematics, Medicine",
         "56",
         "1a1ddb8e840f90dc765583768b6ce610",
         "10.1152/ajpcell.00455.2021",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Medicine'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "27",
         "8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "Open Problems in Mechanistic Interpretability",
         "Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, Stella Biderman, Adrià Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, Eric Todd, Atticus Geiger, Mor Geva, Jesse Hoogland, Daniel Murfet, Thomas McGrath",
         "2025",
         "Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "https://arxiv.org/pdf/2501.16496.pdf",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "arXiv.org",
         "Computer Science, Computer Science, Philosophy",
         "52",
         "91df2ef4eadf077383bb23722f77664f",
         "10.48550/arXiv.2501.16496",
         "2501.16496",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:20.370015+00:00",
         "2025-09-29 20:01:51.158008+00:00"
        ],
        [
         "28",
         "1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "High-throughput genetic clustering of type 2 diabetes loci reveals heterogeneous mechanistic pathways of metabolic disease",
         "Hyunkyung Kim, K. Westerman, Kirk Smith, Joshua Chiou, J. Cole, T. Majarian, Marcin von Grotthuss, S. Kwak, Jaegil Kim, J. Mercader, J. Florez, K. Gaulton, A. Manning, M. Udler",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "https://link.springer.com/content/pdf/10.1007/s00125-022-05848-6.pdf",
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "Diabetologia",
         "Medicine, Medicine, Biology",
         "50",
         "6177f0d87f15e961d672e7d0629df25d",
         "10.1007/s00125-022-05848-6",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "29",
         "9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Non-negative Matrix Factorization: A Survey",
         "Jiangzhang Gan, Tong Liu, Li Li, Jilian Zhang",
         "2021",
         "\n Non-negative matrix factorization (NMF) is a powerful tool for data science researchers, and it has been successfully applied to data mining and machine learning community, due to its advantages such as simple form, good interpretability and less storage space. In this paper, we give a detailed survey on existing NMF methods, including a comprehensive analysis of their design principles, characteristics and drawbacks. In addition, we also discuss various variants of NMF methods and analyse properties and applications of these variants. Finally, we evaluate the performance of nine NMF methods through numerical experiments, and the results show that NMF methods perform well in clustering tasks.",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "https://mro.massey.ac.nz/bitstreams/7dbd6b5e-4d71-490a-b1b6-654e40181693/download",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Computer/law journal",
         "Computer Science, Mathematics, Computer Science, Mathematics",
         "50",
         "59e53699c3921eb318bb078214c055c5",
         "10.1093/COMJNL/BXAB103",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "30",
         "2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
         "Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, Ziyu Yao",
         "2024",
         "Mechanistic interpretability (MI) is an emerging sub-field of interpretability that seeks to understand a neural network model by reverse-engineering its internal computations. Recently, MI has garnered significant attention for interpreting transformer-based language models (LMs), resulting in many novel insights yet introducing new challenges. However, there has not been work that comprehensively reviews these insights and challenges, particularly as a guide for newcomers to this field. To fill this gap, we provide a comprehensive survey from a task-centric perspective, organizing the taxonomy of MI research around specific research questions or tasks. We outline the fundamental objects of study in MI, along with the techniques, evaluation methods, and key findings for each task in the taxonomy. In particular, we present a task-centric taxonomy as a roadmap for beginners to navigate the field by helping them quickly identify impactful problems in which they are most interested and leverage MI for their benefit. Finally, we discuss the current gaps in the field and suggest potential future directions for MI research.",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "https://arxiv.org/pdf/2407.02646.pdf",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "arXiv.org",
         "Computer Science, Computer Science",
         "50",
         "315f88620b6902745a1f3b994fd0e831",
         "10.48550/arXiv.2407.02646",
         "2407.02646",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.481838+00:00",
         "2025-09-29 20:01:43.961857+00:00"
        ],
        [
         "31",
         "7748391c938dc6f6a5bae6ac56f33faf37686714",
         "The rotational and divergent components of atmospheric circulation on tidally locked planets",
         "M. Hammond, N. Lewis",
         "2021",
         "Significance Tidally locked exoplanets have a permanent day side and night side. Understanding the atmospheric circulation on these planets is crucial for interpreting telescope observations and assessing their habitability. We show that the main components of the circulation—a jet going around the planet, stationary atmospheric waves, and direct flow from the day side to the night side—can be separated using a simple mathematical decomposition. This decomposition will significantly aid future study of tidally locked atmospheres. As an illustration, we use it to quantify heat transport due to different components of the circulation. This analysis reveals that the direct day–night component can dominate heat transport from the day side to the night side, even when the jet is strong. Tidally locked exoplanets likely host global atmospheric circulations with a superrotating equatorial jet, planetary-scale stationary waves, and thermally driven overturning circulation. In this work, we show that each of these features can be separated from the total circulation by using a Helmholtz decomposition, which splits the circulation into rotational (divergence-free) and divergent (vorticity-free) components. This technique is applied to the simulated circulation of a terrestrial planet and a gaseous hot Jupiter. For both planets, the rotational component comprises the equatorial jet and stationary waves, and the divergent component contains the overturning circulation. Separating out each component allows us to evaluate their spatial structure and relative contribution to the total flow. In contrast with previous work, we show that divergent velocities are not negligible when compared with rotational velocities and that divergent, overturning circulation takes the form of a single, roughly isotropic cell that ascends on the day side and descends on the night side. These conclusions are drawn for both the terrestrial case and the hot Jupiter. To illustrate the utility of the Helmholtz decomposition for studying atmospheric processes, we compute the contribution of each of the circulation components to heat transport from day side to night side. Surprisingly, we find that the divergent circulation dominates day–night heat transport in the terrestrial case and accounts for around half of the heat transport for the hot Jupiter. The relative contributions of the rotational and divergent components to day–night heat transport are likely sensitive to multiple planetary parameters and atmospheric processes and merit further study.",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "https://www.pnas.org/doi/pdf/10.1073/pnas.2022705118",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "Proceedings of the National Academy of Sciences of the United States of America",
         "Medicine, Physics, Physics, Environmental Science",
         "48",
         "abff31af6dcd5fe122dec99d8ade4088",
         "10.1073/pnas.2022705118",
         "2102.1176",
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "32",
         "02ad427b0d20fb976741e332f69c2fd00c751164",
         "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
         "Dan Braun, Jordan K. Taylor, Nicholas Goldowsky-Dill, Lee Sharkey",
         "2024",
         "Identifying the features learned by neural networks is a core challenge in mechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse, overcomplete dictionary that reconstructs a network's internal activations, have been used to identify these features. However, SAEs may learn more about the structure of the datatset than the computational structure of the network. There is therefore only indirect reason to believe that the directions found in these dictionaries are functionally important to the network. We propose end-to-end (e2e) sparse dictionary learning, a method for training SAEs that ensures the features learned are functionally important by minimizing the KL divergence between the output distributions of the original model and the model with SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a Pareto improvement: They explain more network performance, require fewer total features, and require fewer simultaneously active features per datapoint, all with no cost to interpretability. We explore geometric and qualitative differences between e2e SAE features and standard SAE features. E2e dictionary learning brings us closer to methods that can explain network behavior concisely and accurately. We release our library for training e2e SAEs and reproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "https://arxiv.org/pdf/2405.12241.pdf",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "46",
         "5dc8cc7891318ba16ac9c75ba5693d16",
         "10.48550/arXiv.2405.12241",
         "2405.12241",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "33",
         "f8029060e91209f048b3f9882f2cdd3607785ccd",
         "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability",
         "Ziming Liu, Eric Gan, Max Tegmark",
         "2023",
         "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that BIMT discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "http://arxiv.org/pdf/2305.08746",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "arXiv.org",
         "Computer Science, Physics, Mathematics, Biology, Computer Science",
         "46",
         "e067eaaff103d512e5af5296af1cdb46",
         "10.48550/arXiv.2305.08746",
         "2305.08746",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Physics'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.083803+00:00",
         "2025-09-29 20:01:45.576156+00:00"
        ],
        [
         "34",
         "e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "On scalable oversight with weak LLMs judging strong LLMs",
         "Zachary Kenton, Noah Y. Siegel, J'anos Kram'ar, Jonah Brown-Cohen, Samuel Albanie, Jannis Bulian, Rishabh Agarwal, David Lindner, Yunhao Tang, Noah D. Goodman, Rohin Shah",
         "2024",
         "Scalable oversight protocols aim to enable humans to accurately supervise superhuman AI. In this paper we study debate, where two AI's compete to convince a judge; consultancy, where a single AI tries to convince a judge that asks questions; and compare to a baseline of direct question-answering, where the judge just answers outright without the AI. We use large language models (LLMs) as both AI agents and as stand-ins for human judges, taking the judge models to be weaker than agent models. We benchmark on a diverse range of asymmetries between judges and agents, extending previous work on a single extractive QA task with information asymmetry, to also include mathematics, coding, logic and multimodal reasoning asymmetries. We find that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer. Comparing debate to direct question answering, the results depend on the type of task: in extractive QA tasks with information asymmetry debate outperforms direct question answering, but in other tasks without information asymmetry the results are mixed. Previous work assigned debaters/consultants an answer to argue for. When we allow them to instead choose which answer to argue for, we find judges are less frequently convinced by the wrong answer in debate than in consultancy. Further, we find that stronger debater models increase judge accuracy, though more modestly than in previous studies.",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "https://arxiv.org/pdf/2407.04622.pdf",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "44",
         "9c1fb35a2858675c73be477fb0ece0b3",
         "10.48550/arXiv.2407.04622",
         "2407.04622",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "35",
         "0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "PVC-SLP: Perceptual Vibrotactile-Signal Compression Based-on Sparse Linear Prediction",
         "Rania Hassen, Başak Güleçyüz, E. Steinbach",
         "2021",
         "Developing a signal compression technique that is able to achieve a low bit rate while maintaining high perceptual signal quality is a classical signal processing problem vigorously studied for audio, speech, image, and video type of signals. Yet, until recently, there has been limited effort directed toward the compression of vibrotactile signals, which represent a crucial element of rich touch (haptic) information. A vibrotactile signal; produced when stroking a textured surface with a tool-tip or bare-finger; like other signals contains a great deal of redundant and imperceptible information that can be exploited for efficient compression. This paper presents PVC-SLP, a vibrotactile perceptual coding approach. PVC-SLP employs a model of tactile sensitivity; called ASF (Acceleration Sensitivity Function); for perceptual coding. The ASF is inspired by the four channels model that mediate the perception of vibrotactile stimuli in the glabrous skin. The compression algorithm introduces sparsity constraints in a linear prediction scheme both on the residual and the predictor coefficients. The perceptual quantization of the residual is developed through the use of ASF. The quantization parameters of the residual and the predictor coefficients were jointly optimized; by means of both squared error and perceptual quality measures; to find the sweet spot of the rate-distortion curve. PVC-SLP coding performance is evaluated using two publicly available databases that collectively comprise 1281 vibrotactile signals covering 193 material classes. Furthermore, we compare PVC-SLP with a recent vibrotactile compression method and show that PVC-SLP perceptually outperforms existing method by a sizable margin. Most recently, PVC-SLP has been selected to become part of the haptic codec standard currently under preparation by IEEE P1918.1.1, aka Haptic Codecs for the Tactile Internet.",
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         null,
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "IEEE transactions on multimedia",
         "Computer Science, Computer Science",
         "44",
         "99db78f4eb2492099f409ede6822e163",
         "10.1109/tmm.2020.3042674",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "36",
         "ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Hybrid modelling of water resource recovery facilities: status and opportunities.",
         "M. Y. Schneider, Ward Quaghebeur, Sina Borzooei, A. Froemelt, Feiyi Li, R. Saagi, Matthew John Wade, Jun‐Jie Zhu, E. Torfs",
         "2022",
         "Mathematical modelling is an indispensable tool to support water resource recovery facility (WRRF) operators and engineers with the ambition of creating a truly circular economy and assuring a sustainable future. Despite the successful application of mechanistic models in the water sector, they show some important limitations and do not fully profit from the increasing digitalisation of systems and processes. Recent advances in data-driven methods have provided options for harnessing the power of Industry 4.0, but they are often limited by the lack of interpretability and extrapolation capabilities. Hybrid modelling (HM) combines these two modelling paradigms and aims to leverage both the rapidly increasing volumes of data collected, as well as the continued pursuit of greater process understanding. Despite the potential of HM in a sector that is undergoing a significant digital and cultural transformation, the application of hybrid models remains vague. This article presents an overview of HM methodologies applied to WRRFs and aims to stimulate the wider adoption and development of HM. We also highlight challenges and research needs for HM design and architecture, good modelling practice, data assurance, and software compatibility. HM is a paradigm for WRRF modelling to transition towards a more resource-efficient, resilient, and sustainable future.",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "https://iwaponline.com/wst/article-pdf/85/9/2503/1064960/wst085092503.pdf",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Water Science and Technology",
         "Medicine, Environmental Science, Engineering",
         "42",
         "46d3af83fe7d76740b0f84253214e6c5",
         "10.2166/wst.2022.115",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "37",
         "63a87feede94433b44b2c2b194e5902c3c5158f2",
         "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation",
         "Aaditya K. Singh, Ted Moskovitz, Felix Hill, S. C. Chan, Andrew M. Saxe",
         "2024",
         "In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning -- the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By clamping subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to\"go right\"for an induction head.",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "https://arxiv.org/pdf/2404.07129.pdf",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "International Conference on Machine Learning",
         "Computer Science",
         "41",
         "160d0353f52a1dccf893bdae96e30380",
         "10.48550/arXiv.2404.07129",
         "2404.07129",
         "[{'source': 'external', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.524693+00:00",
         "2025-09-29 20:02:01.691828+00:00"
        ],
        [
         "38",
         "680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
         "Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe",
         "2024",
         "How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate this kind of easy-to-hard generalization using simple finetuning methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect easy data rather than hard data for finetuning, since hard data is generally noisier and costlier to collect. Our experiments use open models up to 70b in size and four publicly available question-answering datasets with questions ranging in difficulty from 3rd grade science questions to college level STEM questions and general-knowledge trivia. We conclude that easy-to-hard generalization in LMs is surprisingly strong for the tasks studied. Our code is available at: https://github.com/allenai/easy-to-hard-generalization",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "https://arxiv.org/pdf/2401.06751.pdf",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "39",
         "fd9c2650583db7080c93fe4ad97bc16a",
         "10.48550/arXiv.2401.06751",
         "2401.06751",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "39",
         "d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "Multi-Modal Convolutional Dictionary Learning",
         "Fangyuan Gao, Xin Deng, Mai Xu, Jingyi Xu, P. Dragotti",
         "2022",
         "Convolutional dictionary learning has become increasingly popular in signal and image processing for its ability to overcome the limitations of traditional patch-based dictionary learning. Although most studies on convolutional dictionary learning mainly focus on the unimodal case, real-world image processing tasks usually involve images from multiple modalities, e.g., visible and near-infrared (NIR) images. Thus, it is necessary to explore convolutional dictionary learning across different modalities. In this paper, we propose a novel multi-modal convolutional dictionary learning algorithm, which efficiently correlates different image modalities and fully considers neighborhood information at the image level. In this model, each modality is represented by two convolutional dictionaries, in which one dictionary is for common feature representation and the other is for unique feature representation. The model is constrained by the requirement that the convolutional sparse representations (CSRs) for the common features should be the same across different modalities, considering that these images are captured from the same scene. We propose a new training method based on the alternating direction method of multipliers (ADMM) to alternatively learn the common and unique dictionaries in the discrete Fourier transform (DFT) domain. We show that our model converges in less than 20 iterations between the convolutional dictionary updating and the CSRs calculation. The effectiveness of the proposed dictionary learning algorithm is demonstrated on various multimodal image processing tasks, achieves better performance than both dictionary learning methods and deep learning based methods with limited training data.",
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         null,
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "IEEE Transactions on Image Processing",
         "Computer Science, Medicine, Computer Science, Environmental Science",
         "39",
         "e087496c780892e3207eb83d96645f87",
         "10.1109/TIP.2022.3141251",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "40",
         "2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "Diffusion Models for Audio Restoration: A review [Special Issue On Model-Based and Data-Driven Audio Signal Processing]",
         "Jean-Marie Lemercier, Julius Richter, Simon Welker, Eloi Moliner, V. Välimäki, Timo Gerkmann",
         "2024",
         "With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift toward data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged as powerful techniques for learning complex data distributions. However, relying solely on DNN-based learning approaches carries the risk of reducing interpretability, particularly when employing end-to-end models. Nonetheless, data-driven approaches allow more flexibility in comparison to statistical model-based frameworks, whose performance depends on distributional and statistical assumptions that can be difficult to guarantee. Here, we aim to show that diffusion models can combine the best of both worlds and offer the opportunity to design audio restoration algorithms with a good degree of interpretability and a remarkable performance in terms of sound quality. In this article, we review the use of diffusion models for audio restoration. We explain the diffusion formalism and its application to the conditional generation of clean audio signals. We believe that diffusion models open an exciting field of research with the potential to spawn new audio restoration algorithms that are natural-sounding and remain robust in difficult acoustic situations.",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "https://arxiv.org/pdf/2402.09821.pdf",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Computer Science, Engineering",
         "37",
         "e188cd7a5af5364280ca4c2fd54355b5",
         "10.1109/MSP.2024.3445871",
         "2402.09821",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "41",
         "5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Interpretability of artificial neural network models in artificial intelligence versus neuroscience",
         "Kohitij Kar, Simon Kornblith, Evelina Fedorenko",
         "2022",
         "Computationally explicit hypotheses of brain function derived from machine learning (ML)-based models have recently revolutionized neuroscience. Despite the unprecedented ability of these artificial neural networks (ANNs) to capture responses in biological neural networks (brains), and our full access to all internal model components (unlike the brain), ANNs are often referred to as black-boxes with limited interpretability. Interpretability, however, is a multi-faceted construct that is used differently across fields. In particular, interpretability, or explainability, efforts in Artificial Intelligence (AI) focus on understanding how different model components contribute to its output (i.e., decision making). In contrast, the neuroscientific interpretability of ANNs requires explicit alignment between model components and neuroscientific constructs (e.g., different brain areas or phenomena, like recurrence or top-down feedback). Given the widespread calls to improve the interpretability of AI systems, we here highlight these different notions of interpretability and argue that the neuroscientific interpretability of ANNs can be pursued in parallel with, but independently from, the ongoing efforts in AI. Certain ML techniques (e.g., deep dream) can be leveraged in both fields, to ask what stimulus optimally activates the specific model features (feature visualization by optimization), or how different features contribute to the model's output (feature attribution). However, without appropriate brain alignment, certain features will remain uninterpretable to neuroscientists.",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "https://arxiv.org/pdf/2206.03951",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Nat. Mac. Intell.",
         "Computer Science, Biology, Computer Science, Philosophy",
         "36",
         "7387e8bb067dd5c477ba0c3fe39df6a4",
         "10.1038/s42256-022-00592-3",
         "2206.03951",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:59.476166+00:00",
         "2025-09-29 20:01:59.476166+00:00"
        ],
        [
         "42",
         "c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Application of non-negative matrix factorization in oncology: one approach for establishing precision medicine",
         "Ryuji Hamamoto, Ken Takasawa, Hidenori Machino, Kazuma Kobayashi, Satoshi Takahashi, Amina Bolatkan, Norio Shinkai, Akira Sakai, R. Aoyama, Masayoshi Yamada, Ken Asada, M. Komatsu, Koji Okamoto, H. Kameoka, S. Kaneko",
         "2022",
         "Abstract The increase in the expectations of artificial intelligence (AI) technology has led to machine learning technology being actively used in the medical field. Non-negative matrix factorization (NMF) is a machine learning technique used for image analysis, speech recognition, and language processing; recently, it is being applied to medical research. Precision medicine, wherein important information is extracted from large-scale medical data to provide optimal medical care for every individual, is considered important in medical policies globally, and the application of machine learning techniques to this end is being handled in several ways. NMF is also introduced differently because of the characteristics of its algorithms. In this review, the importance of NMF in the field of medicine, with a focus on the field of oncology, is described by explaining the mathematical science of NMF and the characteristics of the algorithm, providing examples of how NMF can be used to establish precision medicine, and presenting the challenges of NMF. Finally, the direction regarding the effective use of NMF in the field of oncology is also discussed.",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "https://academic.oup.com/bib/article-pdf/23/4/bbac246/45017265/bbac246.pdf",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Briefings Bioinform.",
         "Medicine, Computer Science, Medicine, Computer Science",
         "35",
         "cea76d54281f58364f2cdbd89a30795c",
         "10.1093/bib/bbac246",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "43",
         "59b988fda9c1737465921a9bade731d511500718",
         "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
         "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
         "2024",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         "arXiv.org",
         "Computer Science, Psychology",
         "35",
         "ba9e6b607a4904c9b0fa98dd7fb06b26",
         "10.48550/arXiv.2408.01416",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:40.147869+00:00",
         "2025-09-30 00:45:40.147869+00:00"
        ],
        [
         "44",
         "b437d4398b443234aa253156404e12326ba899a5",
         "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
         "Mitchell Ostrow, Adam Eisen, L. Kozachkov, I. Fiete",
         "2023",
         "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "https://arxiv.org/pdf/2306.10168",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "Neural Information Processing Systems",
         "Biology, Computer Science, Computer Science",
         "35",
         "fada21b27d9df8d40aef2026b27654ac",
         "10.48550/arXiv.2306.10168",
         "2306.10168",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:41.941797+00:00",
         "2025-09-29 20:01:41.941797+00:00"
        ],
        [
         "45",
         "557dce8787129ca623fcb2cca2e76e9920347b69",
         "Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms",
         "Alireza Fallah, A. Makhdoumi, Azarakhsh Malekian, A. Ozdaglar",
         "2022",
         "We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "https://arxiv.org/pdf/2201.03968.pdf",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "ACM Conference on Economics and Computation",
         "Computer Science, Computer Science, Economics",
         "34",
         "6f74ae4cba716c1607ae234c9694a38e",
         "10.1145/3490486.3538329",
         "2201.03968",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "46",
         "d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP",
         "Vedant Palit, Rohan Pandey, Aryaman Arora, Paul Pu Liang",
         "2023",
         "Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have identified neural circuits that copy spans of text, capture factual knowledge, and more, they remain unusable for multimodal models since adapting these tools to the vision-language domain requires considerable architectural changes. In this work, we adapt a unimodal causal tracing tool to BLIP to enable the study of the neural mechanisms underlying image-conditioned text generation. We demonstrate our approach on a visual question answering dataset, highlighting the causal relevance of later layer representations for all tokens. Furthermore, we release our BLIP causal tracing tool as open source to enable further experimentation in vision-language mechanistic interpretability by the community. Our code is available at this URL.",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "https://arxiv.org/pdf/2308.14179",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
         "Computer Science, Computer Science",
         "34",
         "9cf5a58ea2e4185711ce7b8677794afc",
         "10.1109/ICCVW60793.2023.00307",
         "2308.14179",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.758641+00:00",
         "2025-09-29 20:01:46.494319+00:00"
        ],
        [
         "47",
         "6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning",
         "Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang",
         "2023",
         "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "https://arxiv.org/pdf/2311.07954.pdf",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "North American Chapter of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "32",
         "c392393c2dc5c78e3dc51c1d7ab07def",
         "10.48550/arXiv.2311.07954",
         "2311.07954",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "48",
         "f3658afcd181e4078e1e96ff86eac224fd92faab",
         "ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability",
         "ZhongXiang Sun, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu, Xiao Zhang, Weijie Yu, Han Li",
         "2024",
         "Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric (internal) knowledge. However, even with accurate and relevant retrieved content, RAG models can still produce hallucinations by generating outputs that conflict with the retrieved information. Detecting such hallucinations requires disentangling how Large Language Models (LLMs) utilize external and parametric knowledge. Current detection methods often focus on one of these mechanisms or without decoupling their intertwined effects, making accurate detection difficult. In this paper, we investigate the internal mechanisms behind hallucinations in RAG scenarios. We discover hallucinations occur when the Knowledge FFNs in LLMs overemphasize parametric knowledge in the residual stream, while Copying Heads fail to effectively retain or integrate external knowledge from retrieved content. Based on these findings, we propose ReDeEP, a novel method that detects hallucinations by decoupling LLM's utilization of external context and parametric knowledge. Our experiments show that ReDeEP significantly improves RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by modulating the contributions of Knowledge FFNs and Copying Heads.",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "https://arxiv.org/pdf/2410.11414.pdf",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "32",
         "ac30ae75b45154f43567d24b201cee78",
         "10.48550/arXiv.2410.11414",
         "2410.11414",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.714672+00:00",
         "2025-09-29 20:01:43.739899+00:00"
        ],
        [
         "49",
         "7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Orthogonal Non-negative Tensor Factorization based Multi-view Clustering",
         "Jing Li, Quanxue Gao, Qianqian Wang, Ming Yang, Wei Xia",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Mathematics",
         "31",
         "20a966da2d81a77230eb9bf78d244a46",
         null,
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 759
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edd112383ad494f5f2eba72b6f4ffae122ce61f</td>\n",
       "      <td>Interpretability in the Wild: a Circuit for In...</td>\n",
       "      <td>Kevin Wang, Alexandre Variengien, Arthur Conmy...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Research in mechanistic interpretability seeks...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>https://arxiv.org/pdf/2211.00593</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>644</td>\n",
       "      <td>1ff47a5be9a68e64e23ad2359d220370</td>\n",
       "      <td>10.48550/arXiv.2211.00593</td>\n",
       "      <td>2211.00593</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:28.298552+00:00</td>\n",
       "      <td>2025-09-29 20:02:03.480569+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0893549771094fac547432cb4f84e9605c911a86</td>\n",
       "      <td>The imperative for regulatory oversight of lar...</td>\n",
       "      <td>B. Meskó, E. Topol</td>\n",
       "      <td>2023</td>\n",
       "      <td>The rapid advancements in artificial intellige...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>https://www.nature.com/articles/s41746-023-008...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>npj Digit. Medicine</td>\n",
       "      <td>Computer Science, Medicine, Medicine, Computer...</td>\n",
       "      <td>627</td>\n",
       "      <td>920cc7dbbd6a0bb608e11b65097d69ef</td>\n",
       "      <td>10.1038/s41746-023-00873-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f680d47a51a0e470fcb228bf0110c026535ead1b</td>\n",
       "      <td>Progress measures for grokking via mechanistic...</td>\n",
       "      <td>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neural networks often exhibit emergent behavio...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05217</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>517</td>\n",
       "      <td>953089e9556a8e0b37293683f8ff8807</td>\n",
       "      <td>10.48550/arXiv.2301.05217</td>\n",
       "      <td>2301.05217</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:13.784216+00:00</td>\n",
       "      <td>2025-09-29 20:01:43.521903+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefbd8b384a58f464827b19e30a6920ba976def9</td>\n",
       "      <td>Towards Automated Circuit Discovery for Mechan...</td>\n",
       "      <td>Arthur Conmy, Augustine N. Mavor-Parker, Aengu...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Through considerable effort and intuition, sev...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>https://arxiv.org/pdf/2304.14997</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>Neural Information Processing Systems</td>\n",
       "      <td>Computer Science, Computer Science, Engineering</td>\n",
       "      <td>356</td>\n",
       "      <td>a97a69c6234d51eeafeb50c9077b71ba</td>\n",
       "      <td>10.48550/arXiv.2304.14997</td>\n",
       "      <td>2304.14997</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:14.252982+00:00</td>\n",
       "      <td>2025-09-29 20:01:44.864490+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2</td>\n",
       "      <td>Mechanistic Interpretability of GPT-like Model...</td>\n",
       "      <td>Anurag Mishra</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability research seeks to...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.17073.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>3771d70ffd60f9c3f692d0e8f989f74d</td>\n",
       "      <td>10.48550/arXiv.2505.17073</td>\n",
       "      <td>2505.17073</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.786419+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.195754+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>663292eaef24c22c0692f1b4a9120d24662d7fc7</td>\n",
       "      <td>Causal Intervention Framework for Variational ...</td>\n",
       "      <td>Dip Roy</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability of deep learning ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.03530.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>2f8d578153eefbc0b11361f9e71a0194</td>\n",
       "      <td>10.48550/arXiv.2505.03530</td>\n",
       "      <td>2505.03530</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.332786+00:00</td>\n",
       "      <td>2025-09-29 20:01:57.450585+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>49072764553763f1686121fd03e3dadda259f273</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>2024</td>\n",
       "      <td>Recent research (arXiv:2310.11453, arXiv:2402....</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>https://arxiv.org/pdf/2405.17703.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>81612dabd9dc5de68fc08c32d1ed9a14</td>\n",
       "      <td>10.48550/arXiv.2405.17703</td>\n",
       "      <td>2405.17703</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.685040+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.957507+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_id  \\\n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "1    6edd112383ad494f5f2eba72b6f4ffae122ce61f   \n",
       "2    0893549771094fac547432cb4f84e9605c911a86   \n",
       "3    f680d47a51a0e470fcb228bf0110c026535ead1b   \n",
       "4    eefbd8b384a58f464827b19e30a6920ba976def9   \n",
       "..                                        ...   \n",
       "754  f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2   \n",
       "755  663292eaef24c22c0692f1b4a9120d24662d7fc7   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "757  49072764553763f1686121fd03e3dadda259f273   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "1    Interpretability in the Wild: a Circuit for In...   \n",
       "2    The imperative for regulatory oversight of lar...   \n",
       "3    Progress measures for grokking via mechanistic...   \n",
       "4    Towards Automated Circuit Discovery for Mechan...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic Interpretability of GPT-like Model...   \n",
       "755  Causal Intervention Framework for Variational ...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "757  Mechanistic Interpretability of Binary and Ter...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                               authors  year  \\\n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...  2023   \n",
       "1    Kevin Wang, Alexandre Variengien, Arthur Conmy...  2022   \n",
       "2                                   B. Meskó, E. Topol  2023   \n",
       "3    Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...  2023   \n",
       "4    Arthur Conmy, Augustine N. Mavor-Parker, Aengu...  2023   \n",
       "..                                                 ...   ...   \n",
       "754                                      Anurag Mishra  2025   \n",
       "755                                            Dip Roy  2025   \n",
       "756                    Marcos Florencio, Thomas Barton  2025   \n",
       "757                                           Jason Li  2024   \n",
       "758                     Tristan Trim, Triston Grayston  2024   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    We present GPQA, a challenging dataset of 448 ...   \n",
       "1    Research in mechanistic interpretability seeks...   \n",
       "2    The rapid advancements in artificial intellige...   \n",
       "3    Neural networks often exhibit emergent behavio...   \n",
       "4    Through considerable effort and intuition, sev...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic interpretability research seeks to...   \n",
       "755  Mechanistic interpretability of deep learning ...   \n",
       "756  Architectural obfuscation - e.g., permuting hi...   \n",
       "757  Recent research (arXiv:2310.11453, arXiv:2402....   \n",
       "758  This paper explores the mechanistic interpreta...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                               pdf_url  \\\n",
       "0                 https://arxiv.org/pdf/2311.12022.pdf   \n",
       "1                     https://arxiv.org/pdf/2211.00593   \n",
       "2    https://www.nature.com/articles/s41746-023-008...   \n",
       "3                      http://arxiv.org/pdf/2301.05217   \n",
       "4                     https://arxiv.org/pdf/2304.14997   \n",
       "..                                                 ...   \n",
       "754               https://arxiv.org/pdf/2505.17073.pdf   \n",
       "755               https://arxiv.org/pdf/2505.03530.pdf   \n",
       "756               https://arxiv.org/pdf/2506.18053.pdf   \n",
       "757               https://arxiv.org/pdf/2405.17703.pdf   \n",
       "758               https://arxiv.org/pdf/2411.00867.pdf   \n",
       "\n",
       "                                           scholar_url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                                 venue  \\\n",
       "0                                            arXiv.org   \n",
       "1    International Conference on Learning Represent...   \n",
       "2                                  npj Digit. Medicine   \n",
       "3    International Conference on Learning Represent...   \n",
       "4                Neural Information Processing Systems   \n",
       "..                                                 ...   \n",
       "754                                          arXiv.org   \n",
       "755                                          arXiv.org   \n",
       "756                                          arXiv.org   \n",
       "757                                          arXiv.org   \n",
       "758                                          arXiv.org   \n",
       "\n",
       "                                              keywords  citations  \\\n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "1                   Computer Science, Computer Science        644   \n",
       "2    Computer Science, Medicine, Medicine, Computer...        627   \n",
       "3                   Computer Science, Computer Science        517   \n",
       "4      Computer Science, Computer Science, Engineering        356   \n",
       "..                                                 ...        ...   \n",
       "754                 Computer Science, Computer Science          0   \n",
       "755                 Computer Science, Computer Science          0   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "757                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "\n",
       "                           title_hash                         doi    arxiv_id  \\\n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                         NaN  2311.12022   \n",
       "1    1ff47a5be9a68e64e23ad2359d220370   10.48550/arXiv.2211.00593  2211.00593   \n",
       "2    920cc7dbbd6a0bb608e11b65097d69ef  10.1038/s41746-023-00873-0         NaN   \n",
       "3    953089e9556a8e0b37293683f8ff8807   10.48550/arXiv.2301.05217  2301.05217   \n",
       "4    a97a69c6234d51eeafeb50c9077b71ba   10.48550/arXiv.2304.14997  2304.14997   \n",
       "..                                ...                         ...         ...   \n",
       "754  3771d70ffd60f9c3f692d0e8f989f74d   10.48550/arXiv.2505.17073  2505.17073   \n",
       "755  2f8d578153eefbc0b11361f9e71a0194   10.48550/arXiv.2505.03530  2505.03530   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34   10.48550/arXiv.2506.18053  2506.18053   \n",
       "757  81612dabd9dc5de68fc08c32d1ed9a14   10.48550/arXiv.2405.17703  2405.17703   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82   10.48550/arXiv.2411.00867  2411.00867   \n",
       "\n",
       "                                             s2_fields  \\\n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "1    [{'source': 'external', 'category': 'Computer ...   \n",
       "2    [{'source': 'external', 'category': 'Computer ...   \n",
       "3    [{'source': 'external', 'category': 'Computer ...   \n",
       "4    [{'source': 'external', 'category': 'Computer ...   \n",
       "..                                                 ...   \n",
       "754  [{'source': 'external', 'category': 'Computer ...   \n",
       "755  [{'source': 'external', 'category': 'Computer ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "757  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                           created_at                        updated_at  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "1    2025-09-29 20:01:28.298552+00:00  2025-09-29 20:02:03.480569+00:00  \n",
       "2    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "3    2025-09-29 20:01:13.784216+00:00  2025-09-29 20:01:43.521903+00:00  \n",
       "4    2025-09-29 20:01:14.252982+00:00  2025-09-29 20:01:44.864490+00:00  \n",
       "..                                ...                               ...  \n",
       "754  2025-09-29 20:01:25.786419+00:00  2025-09-29 20:01:55.195754+00:00  \n",
       "755  2025-09-29 20:01:25.332786+00:00  2025-09-29 20:01:57.450585+00:00  \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00  \n",
       "757  2025-09-29 20:01:19.685040+00:00  2025-09-29 20:01:48.957507+00:00  \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00  \n",
       "\n",
       "[759 rows x 17 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df = pd.read_csv('data/ai_safety_papers.csv')\n",
    "semantic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "740c3d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 759 entries, 0 to 758\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   paper_id     759 non-null    object \n",
      " 1   title        759 non-null    object \n",
      " 2   authors      758 non-null    object \n",
      " 3   year         759 non-null    int64  \n",
      " 4   abstract     681 non-null    object \n",
      " 5   url          759 non-null    object \n",
      " 6   pdf_url      468 non-null    object \n",
      " 7   scholar_url  759 non-null    object \n",
      " 8   venue        704 non-null    object \n",
      " 9   keywords     759 non-null    object \n",
      " 10  citations    759 non-null    int64  \n",
      " 11  title_hash   759 non-null    object \n",
      " 12  doi          688 non-null    object \n",
      " 13  arxiv_id     283 non-null    float64\n",
      " 14  s2_fields    759 non-null    object \n",
      " 15  created_at   759 non-null    object \n",
      " 16  updated_at   759 non-null    object \n",
      "dtypes: float64(1), int64(2), object(14)\n",
      "memory usage: 100.9+ KB\n"
     ]
    }
   ],
   "source": [
    "semantic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c983f87",
   "metadata": {},
   "source": [
    "Adding the authors for each work as a python list so I can split into indiviual records later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8da40efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e1f6cf57-5f4c-49da-86f9-18d283f799c6",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['David Rein', ' Betty Li Hou', ' Asa Cooper Stickland', ' Jackson Petty', ' Richard Yuanzhe Pang', ' Julien Dirani', ' Julian Michael', ' Samuel R. Bowman']"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00",
         "['Kevin Wang', ' Alexandre Variengien', ' Arthur Conmy', ' Buck Shlegeris', ' J. Steinhardt']"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Meskó, E. Topol",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['B. Meskó', ' E. Topol']"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00",
         "['Neel Nanda', ' Lawrence Chan', ' Tom Lieberum', ' Jess Smith', ' J. Steinhardt']"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00",
         "['Arthur Conmy', ' Augustine N. Mavor-Parker', ' Aengus Lynch', ' Stefan Heimersheim', ' Adrià Garriga-Alonso']"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00",
         "['X. Fang', ' C. Lloyd', ' B. Palsson']"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00",
         "['Leonard Bereska', ' E. Gavves']"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00",
         "['Xiaowen Dong', ' D. Thanou', ' L. Toni', ' M. Bronstein', ' P. Frossard']"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['Caio Seguin', ' O. Sporns', ' A. Zalesky']"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['S. Loomba', ' Jakob Straehle', ' V. Gangadharan', ' Natalie Heike', ' Abdelrahman Khalifa', ' Alessandro Motta', ' Niansheng Ju', ' Meike Sievers', ' J. Gempt', ' H. S. Meyer', ' M. Helmstaedter']"
        ],
        [
         "10",
         "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Sam Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilė Lukošiūtė, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, C. McKinnon, Chris Olah, D. Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, John Kernion, Jamie Kerr, J. Mueller, Jeffrey Ladish, J. Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noem'i Mercado, Nova Dassarma, Robin Larson, Sam McCandlish, S. Kundu, Scott Johnston, Shauna Kravec, S. E. Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom B. Brown, T. Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Benjamin Mann, Jared Kaplan",
         "2022",
         "Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks.",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "https://arxiv.org/pdf/2211.03540",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "arXiv.org",
         "Computer Science, Computer Science, Linguistics",
         "149",
         "bd891ffa97410f74480c289f6510913c",
         "10.48550/arXiv.2211.03540",
         "2211.0354",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Linguistics'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['Sam Bowman', ' Jeeyoon Hyun', ' Ethan Perez', ' Edwin Chen', ' Craig Pettit', ' Scott Heiner', ' Kamilė Lukošiūtė', ' Amanda Askell', ' Andy Jones', ' Anna Chen', ' Anna Goldie', ' Azalia Mirhoseini', ' C. McKinnon', ' Chris Olah', ' D. Amodei', ' Dario Amodei', ' Dawn Drain', ' Dustin Li', ' Eli Tran-Johnson', ' John Kernion', ' Jamie Kerr', ' J. Mueller', ' Jeffrey Ladish', ' J. Landau', ' Kamal Ndousse', ' Liane Lovitt', ' Nelson Elhage', ' Nicholas Schiefer', ' Nicholas Joseph', \" Noem'i Mercado\", ' Nova Dassarma', ' Robin Larson', ' Sam McCandlish', ' S. Kundu', ' Scott Johnston', ' Shauna Kravec', ' S. E. Showk', ' Stanislav Fort', ' Timothy Telleen-Lawton', ' Tom B. Brown', ' T. Henighan', ' Tristan Hume', ' Yuntao Bai', ' Zac Hatfield-Dodds', ' Benjamin Mann', ' Jared Kaplan']"
        ],
        [
         "11",
         "f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "An Incentive-Compatible Energy Trading Framework for Neighborhood Area Networks With Shared Energy Storage",
         "C. Mediwaththe, M. Shaw, S. Halgamuge, David B. Smith, P. Scott",
         "2020",
         "Here, a novel energy trading system is proposed for demand-side management of a neighborhood area network (NAN) consisting of a shared energy storage (SES) provider, users with non-dispatchable energy generation, and an electricity retailer. In a leader–follower Stackelberg game, the SES provider first maximizes their revenue by setting a price signal and trading energy with the grid. Then, by following the SES provider's actions, the retailer minimizes social cost for the users, i.e., the sum of the total users’ cost when they interact with the SES and the total cost for supplying grid energy to the users. A pricing strategy, which incorporates mechanism design, is proposed to make the system incentive-compatible by rewarding users who disclose true energy usage information. A unique Stackelberg equilibrium is achieved where the SES provider's revenue is maximized and the user-level social cost is minimized, which also rewards the retailer. A case study with realistic energy demand and generation data demonstrates 28–45% peak demand reduction of the NAN, depending on the number of participating users, compared to a system without SES. Simulation results confirm that the retailer can also benefit financially, in addition to the SES provider and the users.",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "https://arxiv.org/pdf/2008.10384",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "IEEE Transactions on Sustainable Energy",
         "Engineering, Computer Science, Engineering, Economics, Environmental Science",
         "114",
         "203c35336c8ae692de21ba24e812a8e8",
         "10.1109/TSTE.2019.2895387",
         "2008.10384",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00",
         "['C. Mediwaththe', ' M. Shaw', ' S. Halgamuge', ' David B. Smith', ' P. Scott']"
        ],
        [
         "12",
         "dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
         "Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",
         "2024",
         "As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in mathematical reasoning. It consists of 3,400 test cases, primarily focused on competition- and Olympiad-level math problems. Each test case contains a step-by-step solution with error location annotated by human experts. Models are required to identify the earliest step that contains an error, or conclude that all steps are correct. We conduct extensive evaluation on ProcessBench, involving two types of models: process reward models (PRMs) and critic models, where for the latter we prompt general language models to critique each solution step by step. We draw two main observations: (1) Existing PRMs typically fail to generalize to more challenging math problems beyond GSM8K and MATH. They underperform both critic models (i.e., prompted general language models) and our own trained PRM that is straightforwardly fine-tuned on the PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has demonstrated the critique capability competitive with the proprietary model GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We hope ProcessBench can foster future research in reasoning process assessment, paving the way toward scalable oversight of language models.",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "https://arxiv.org/pdf/2412.06559.pdf",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Mathematics, Computer Science",
         "104",
         "171b07e013043a4f09b897d234418135",
         "10.48550/arXiv.2412.06559",
         "2412.06559",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['Chujie Zheng', ' Zhenru Zhang', ' Beichen Zhang', ' Runji Lin', ' Keming Lu', ' Bowen Yu', ' Dayiheng Liu', ' Jingren Zhou', ' Junyang Lin']"
        ],
        [
         "13",
         "41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "A new science of emotion: implications for functional neurological disorder.",
         "Johannes Jungilligens, Sara Paredes-Echeverri, S. Popkirov, L. F. Barrett, D. Perez",
         "2022",
         "Functional neurological disorder (FND) reflects impairments in brain networks leading to distressing motor, sensory, and/or cognitive symptoms that demonstrate positive clinical signs on examination incongruent with other conditions. A central issue in historical and contemporary formulations of FND has been the mechanistic and etiological role of emotions. However, the debate has mostly omitted fundamental questions about the nature of emotions in the first place. In this perspective article, we first outline a set of relevant working principles of the brain (e.g., allostasis, predictive processing, interoception, and affect), followed by a focused review of the theory of constructed emotion to introduce a new understanding of what emotions are. Building on this theoretical framework, we formulate how altered emotion category construction can be an integral component of the pathophysiology of FND and related functional somatic symptoms. In doing so, we address several themes for the FND field including: 1) how energy regulation and the process of emotion category construction relate to symptom generation, including revisiting alexithymia, \"panic attack without panic\", dissociation, insecure attachment, and the influential role of life experiences; 2) re-interpret select neurobiological research findings in FND cohorts through the lens of the theory of constructed emotion to illustrate its potential mechanistic relevance; and 3) discuss therapeutic implications. While we continue to support that FND is mechanistically and etiologically heterogenous, consideration of how the theory of constructed emotion relates to the generation and maintenance of functional neurological and functional somatic symptoms offers an integrated viewpoint that cuts across neurology, psychiatry, psychology, and cognitive-affective neuroscience.",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "https://academic.oup.com/brain/article-pdf/145/8/2648/49120115/awac204.pdf",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "Brain : a journal of neurology",
         "Medicine, Psychology",
         "101",
         "a22d0fe84e5c1374d4c95b8a6396a8d9",
         "10.1093/brain/awac204",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['Johannes Jungilligens', ' Sara Paredes-Echeverri', ' S. Popkirov', ' L. F. Barrett', ' D. Perez']"
        ],
        [
         "14",
         "1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "Targeting High Ability Entrepreneurs Using Community Information: Mechanism Design in the Field",
         "Reshmaan N. Hussam, Natalia Rigol, Benjamin N. Roth",
         "2022",
         "Identifying high-growth microentrepreneurs in low-income countries remains a challenge due to a scarcity of verifiable information. With a cash grant experiment in India we demonstrate that community knowledge can help target high-growth microentrepreneurs; while the average marginal return to capital in our sample is 9.4 percent per month, microentrepreneurs reported in the top third of the community are estimated to have marginal returns to capital between 24 percent and 30 percent per month. Further we find evidence that community members distort their predictions when they can influence the distribution of resources. Finally, we demonstrate that simple mechanisms can realign incentives for truthful reporting. (JEL D82, G21, I38, L25, L26, O12, O16)",
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         null,
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "The American Economic Review",
         "Business, Economics, Business",
         "97",
         "5643d31ff930134acee2c1071dac09b5",
         "10.1257/aer.20200751",
         null,
         "[{'source': 'external', 'category': 'Business'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Business'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00",
         "['Reshmaan N. Hussam', ' Natalia Rigol', ' Benjamin N. Roth']"
        ],
        [
         "15",
         "1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "AI-Generated Incentive Mechanism and Full-Duplex Semantic Communications for Information Sharing",
         "Hongyang Du, Jiacheng Wang, Dusist Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim",
         "2023",
         "The next generation of Internet services, such as Metaverse, rely on mixed reality (MR) technology to provide immersive user experiences. However, limited computation power of MR headset-mounted devices (HMDs) hinders the deployment of such services. Therefore, we propose an efficient information-sharing scheme based on full-duplex device-to-device (D2D) semantic communications to address this issue. Our approach enables users to avoid heavy and repetitive computational tasks, such as artificial intelligence-generated content (AIGC) in the view images of all MR users. Specifically, a user can transmit the generated content and semantic information extracted from their view image to nearby users, who can then use this information to obtain the spatial matching of computation results under their view images. We analyze the performance of full-duplex D2D communications, including the achievable rate and bit error probability, by using generalized small-scale fading models. To facilitate semantic information sharing among users, we design a contract theoretic AI-generated incentive mechanism. The proposed diffusion model generates the optimal contract design, outperforming two deep reinforcement learning algorithms, i.e., proximal policy optimization and soft actor-critic algorithms. Our numerical analysis experiment proves the effectiveness of our proposed methods. The code for this paper is available at https://github.com/HongyangDu/SemSharing.",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "https://www.techrxiv.org/articles/preprint/AI-Generated_Incentive_Mechanism_and_Full-Duplex_Semantic_Communications_for_Information_Sharing/22209178/1/files/39468979.pdf",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "IEEE Journal on Selected Areas in Communications",
         "Engineering, Computer Science, Computer Science",
         "96",
         "4265596316b0f66567d76928f99a27fd",
         "10.1109/JSAC.2023.3287547",
         "2303.01896",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00",
         "['Hongyang Du', ' Jiacheng Wang', ' Dusist Niyato', ' Jiawen Kang', ' Zehui Xiong', ' Dong In Kim']"
        ],
        [
         "16",
         "8efaf945b1b649bf905e0b9624d23760335aa614",
         "Uncertainty in Mechanism Design",
         "Giuseppe Lopomo, Luca Rigotti, Chris Shannon",
         "2021",
         "We consider mechanism design problems with Knightian uncertainty formalized using incomplete preferences, as in Bewley (1986). Without completeness, decision making depends on a set of beliefs, and an action is preferred to another if and only if it has larger expected utility for all beliefs in this set. We consider two natural notions of incentive compatibility in this setting: maximal incentive compatibility requires that no strategy has larger expected utility than reporting truthfully for all beliefs, while optimal incentive compatibility requires that reporting truthfully has larger expected utility than all other strategies for all beliefs. In a model with a continuum of types, we show that optimal incentive compatibility is equivalent to ex-post incentive compatibility under fairly general conditions on beliefs. In a model with a discrete type space, we characterize full extraction of rents generated from private information. We show that full extraction is generically possible with maximal incentive compatible mechanisms, but requires sufficient disagreement across types, which neither holds nor fails generically, with optimal incentive compatible mechanisms.",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         "https://arxiv.org/pdf/2108.12633",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         null,
         "Economics, Economics",
         "90",
         "36c493c55efcd610b95cacde98fab544",
         "10.2139/ssrn.3774581",
         "2108.12633",
         "[{'source': 'external', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00",
         "['Giuseppe Lopomo', ' Luca Rigotti', ' Chris Shannon']"
        ],
        [
         "17",
         "6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
         "Atticus Geiger, D. Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah D. Goodman, Christopher Potts, Thomas F. Icard",
         "2023",
         "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "https://arxiv.org/pdf/2301.04709.pdf",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         null,
         "Computer Science, Computer Science, Philosophy",
         "80",
         "b3611594ff729546b6130e75d7322abd",
         null,
         "2301.04709",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:15.857258+00:00",
         "2025-09-29 20:01:45.343601+00:00",
         "['Atticus Geiger', ' D. Ibeling', ' Amir Zur', ' Maheep Chaudhary', ' Sonakshi Chauhan', ' Jing Huang', ' Aryaman Arora', ' Zhengxuan Wu', ' Noah D. Goodman', ' Christopher Potts', ' Thomas F. Icard']"
        ],
        [
         "18",
         "0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Rationally Design a Sulfur Cathode with Solid‐Phase Conversion Mechanism for High Cycle‐Stable Li–S Batteries",
         "Bin He, Zhixiang Rao, Zexiao Cheng, Dongdong Liu, Danqi He, Jie Chen, Ziyun Miao, Lixia Yuan, Zhen Li, Yunhui Huang",
         "2021",
         "Solid–solid reactions are very effective for solving the main challenges of lithium–sulfur (Li–S) batteries, such as the shuttle effect of polysulfides and the high dependence of electrolyte consumption. However, the low sulfur content and sluggish redox kinetics of such cathodes dramatically limit the practical energy density of Li–S batteries. Here a rationally designed hierarchical cathode to simultaneously solve above‐mentioned challenges is reported. With nanoscale sulfur as the core, selenium‐doped sulfurized polyacrylonitrile (PAN/S7Se) as the shell and micron‐scale secondary particle morphology, the proposed cathode realizes excellent solid–solid reaction kinetics in a commercial carbonate electrolyte under high active species loading and a relatively low electrolyte/sulfur ratio. Such an approach provides a promising solution toward practical lithium sulfur batteries.",
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         null,
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Advanced Energy Materials",
         "Materials Science, Materials Science, Chemistry, Engineering",
         "78",
         "55c45ab4d8c970aeb6f70267874c70d1",
         "10.1002/aenm.202003690",
         null,
         "[{'source': 'external', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00",
         "['Bin He', ' Zhixiang Rao', ' Zexiao Cheng', ' Dongdong Liu', ' Danqi He', ' Jie Chen', ' Ziyun Miao', ' Lixia Yuan', ' Zhen Li', ' Yunhui Huang']"
        ],
        [
         "19",
         "1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nonnegative spatial factorization applied to spatial genomics",
         "F. W. Townes, B. Engelhardt",
         "2022",
         "This paper presents nonnegative spatial factorization, a general framework for spatially aware and interpretable dimension reduction for high-dimensional spatial data, and its application to spatial transcriptomics analysis. Nonnegative matrix factorization (NMF) is widely used to analyze high-dimensional count data because, in contrast to real-valued alternatives such as factor analysis, it produces an interpretable parts-based representation. However, in applications such as spatial transcriptomics, NMF fails to incorporate known structure between observations. Here, we present nonnegative spatial factorization (NSF), a spatially-aware probabilistic dimension reduction model based on transformed Gaussian processes that naturally encourages sparsity and scales to tens of thousands of observations. NSF recovers ground truth factors more accurately than real-valued alternatives such as MEFISTO in simulations, and has lower out-of-sample prediction error than probabilistic NMF on three spatial transcriptomics datasets from mouse brain and liver. Since not all patterns of gene expression have spatial correlations, we also propose a hybrid extension of NSF that combines spatial and nonspatial components, enabling quantification of spatial importance for both observations and features. A TensorFlow implementation of NSF is available from https://github.com/willtownes/nsf-paper .",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "https://www.nature.com/articles/s41592-022-01687-w.pdf",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nature Methods",
         "Medicine, Computer Science, Biology",
         "72",
         "86d4a32c9b25afc8510904668935d1b6",
         "10.1038/s41592-022-01687-w",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00",
         "['F. W. Townes', ' B. Engelhardt']"
        ],
        [
         "20",
         "7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration",
         "T. Bodrito, Alexandre Zouaoui, J. Chanussot, J. Mairal",
         "2021",
         "Hyperspectral imaging offers new perspectives for diverse applications, ranging from the monitoring of the environment using airborne or satellite remote sensing, precision farming, food safety, planetary exploration, or astrophysics. Unfortunately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth\"clean\"hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difficult, in contrast to traditional RGB imaging problems where deep models tend to shine. In this paper, we advocate instead for a hybrid approach based on sparse coding principles that retains the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data. We show on various denoising benchmarks that our method is computationally efficient and significantly outperforms the state of the art.",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "https://arxiv.org/pdf/2111.09708.pdf",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "Neural Information Processing Systems",
         "Computer Science, Engineering, Environmental Science, Computer Science, Engineering",
         "70",
         "043f0c78b6d43bf864f00572f1fa44be",
         null,
         "2111.09708",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00",
         "['T. Bodrito', ' Alexandre Zouaoui', ' J. Chanussot', ' J. Mairal']"
        ],
        [
         "21",
         "70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Parcels and particles: Markov blankets in the brain",
         "Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr, Ines Hip'olito, L. Magrou, Adeel Razi",
         "2020",
         "At the inception of human brain mapping, two principles of functional anatomy underwrote most conceptions—and analyses—of distributed brain responses: namely, functional segregation and integration. There are currently two main approaches to characterizing functional integration. The first is a mechanistic modeling of connectomics in terms of directed effective connectivity that mediates neuronal message passing and dynamics on neuronal circuits. The second phenomenological approach usually characterizes undirected functional connectivity (i.e., measurable correlations), in terms of intrinsic brain networks, self-organized criticality, dynamical instability, and so on. This paper describes a treatment of effective connectivity that speaks to the emergence of intrinsic brain networks and critical dynamics. It is predicated on the notion of Markov blankets that play a fundamental role in the self-organization of far from equilibrium systems. Using the apparatus of the renormalization group, we show that much of the phenomenology found in network neuroscience is an emergent property of a particular partition of neuronal states, over progressively coarser scales. As such, it offers a way of linking dynamics on directed graphs to the phenomenology of intrinsic brain networks.",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "https://direct.mit.edu/netn/article-pdf/5/1/211/1889785/netn_a_00175.pdf",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Network Neuroscience",
         "Biology, Medicine, Computer Science, Physics",
         "70",
         "a28f67baf975f5d1bee41d5db29f602d",
         "10.1162/netn_a_00175",
         "2007.09704",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Physics'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['Karl J. Friston', ' Erik D. Fagerholm', ' Tahereh S. Zarghami', ' Thomas Parr', \" Ines Hip'olito\", ' L. Magrou', ' Adeel Razi']"
        ],
        [
         "22",
         "980255db598dc210d6a784db247d159d3ea1cf3f",
         "Interpretable Multi-Modal Image Registration Network Based on Disentangled Convolutional Sparse Coding",
         "Xin Deng, Enpeng Liu, Shengxi Li, Yiping Duan, Mai Xu",
         "2023",
         "Multi-modal image registration aims to spatially align two images from different modalities to make their feature points match with each other. Captured by different sensors, the images from different modalities often contain many distinct features, which makes it challenging to find their accurate correspondences. With the success of deep learning, many deep networks have been proposed to align multi-modal images, however, they are mostly lack of interpretability. In this paper, we first model the multi-modal image registration problem as a disentangled convolutional sparse coding (DCSC) model. In this model, the multi-modal features that are responsible for alignment (RA features) are well separated from the features that are not responsible for alignment (nRA features). By only allowing the RA features to participate in the deformation field prediction, we can eliminate the interference of the nRA features to improve the registration accuracy and efficiency. The optimization process of the DCSC model to separate the RA and nRA features is then turned into a deep network, namely Interpretable Multi-modal Image Registration Network (InMIR-Net). To ensure the accurate separation of RA and nRA features, we further design an accompanying guidance network (AG-Net) to supervise the extraction of RA features in InMIR-Net. The advantage of InMIR-Net is that it provides a universal framework to tackle both rigid and non-rigid multi-modal image registration tasks. Extensive experimental results verify the effectiveness of our method on both rigid and non-rigid registrations on various multi-modal image datasets, including RGB/depth images, RGB/near-infrared (NIR) images, RGB/multi-spectral images, T1/T2 weighted magnetic resonance (MR) images and computed tomography (CT)/MR images. The codes are available at https://github.com/lep990816/Interpretable-Multi-modal-Image-Registration.",
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         null,
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         "IEEE Transactions on Image Processing",
         "Medicine, Computer Science, Computer Science, Engineering",
         "66",
         "540673f1f88c28586b4306e40b8d041f",
         "10.1109/TIP.2023.3240024",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00",
         "['Xin Deng', ' Enpeng Liu', ' Shengxi Li', ' Yiping Duan', ' Mai Xu']"
        ],
        [
         "23",
         "41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Evolution of central neural circuits: state of the art and perspectives",
         "Ruairí J. V. Roberts, S. Pop, L. Prieto-Godino",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Nature Reviews Neuroscience",
         "Medicine, Biology",
         "62",
         "a1837ac9580622b09b74da0595b69e74",
         "10.1038/s41583-022-00644-y",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['Ruairí J. V. Roberts', ' S. Pop', ' L. Prieto-Godino']"
        ],
        [
         "24",
         "79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Reducing the Cognitive Footprint of Brain Tumor Surgery",
         "N. Dadario, Bledi C. Brahimaj, J. Yeung, M. Sughrue",
         "2021",
         "The surgical management of brain tumors is based on the principle that the extent of resection improves patient outcomes. Traditionally, neurosurgeons have considered that lesions in “non-eloquent” cerebrum can be more aggressively surgically managed compared to lesions in “eloquent” regions with more known functional relevance. Furthermore, advancements in multimodal imaging technologies have improved our ability to extend the rate of resection while minimizing the risk of inducing new neurologic deficits, together referred to as the “onco-functional balance.” However, despite the common utilization of invasive techniques such as cortical mapping to identify eloquent tissue responsible for language and motor functions, glioma patients continue to present post-operatively with poor cognitive morbidity in higher-order functions. Such observations are likely related to the difficulty in interpreting the highly-dimensional information these technologies present to us regarding cognition in addition to our classically poor understanding of the functional and structural neuroanatomy underlying complex higher-order cognitive functions. Furthermore, reduction of the brain into isolated cortical regions without consideration of the complex, interacting brain networks which these regions function within to subserve higher-order cognition inherently prevents our successful navigation of true eloquent and non-eloquent cerebrum. Fortunately, recent large-scale movements in the neuroscience community, such as the Human Connectome Project (HCP), have provided updated neural data detailing the many intricate macroscopic connections between cortical regions which integrate and process the information underlying complex human behavior within a brain “connectome.” Connectomic data can provide us better maps on how to understand convoluted cortical and subcortical relationships between tumor and human cerebrum such that neurosurgeons can begin to make more informed decisions during surgery to maximize the onco-functional balance. However, connectome-based neurosurgery and related applications for neurorehabilitation are relatively nascent and require further work moving forward to optimize our ability to add highly valuable connectomic data to our surgical armamentarium. In this manuscript, we review four concepts with detailed examples which will help us better understand post-operative cognitive outcomes and provide a guide for how to utilize connectomics to reduce cognitive morbidity following cerebral surgery.",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "https://www.frontiersin.org/articles/10.3389/fneur.2021.711646/pdf",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Frontiers in Neurology",
         "Medicine, Medicine, Psychology",
         "61",
         "e26c187369f3f43944783d2070633188",
         "10.3389/fneur.2021.711646",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['N. Dadario', ' Bledi C. Brahimaj', ' J. Yeung', ' M. Sughrue']"
        ],
        [
         "25",
         "9854f38388b01991f461a25fefd1f67fecb9731f",
         "The Architecture of Human Memory: Insights from Human Single-Neuron Recordings",
         "Ueli Rutishauser, L. Reddy, F. Mormann, J. Sarnthein",
         "2020",
         "Deciphering the mechanisms of human memory is a central goal of neuroscience, both from the point of view of the fundamental biology of memory and for its translational relevance. Here, we review some contributions that recordings from neurons in humans implanted with electrodes for clinical purposes have made toward this goal. Recordings from the medial temporal lobe, including the hippocampus, reveal the existence of two classes of cells: those encoding highly selective and invariant representations of abstract concepts, and memory-selective cells whose activity is related to familiarity and episodic retrieval. Insights derived from observing these cells in behaving humans include that semantic representations are activated before episodic representations, that memory content and memory strength are segregated, and that the activity of both types of cells is related to subjective awareness as expected from a substrate for declarative memory. Visually selective cells can remain persistently active for several seconds, thereby revealing a cellular substrate for working memory in humans. An overarching insight is that the neural code of human memory is interpretable at the single-neuron level. Jointly, intracranial recording studies are starting to reveal aspects of the building blocks of human memory at the single-cell level. This work establishes a bridge to cellular-level work in animals on the one hand, and the extensive literature on noninvasive imaging in humans on the other hand. More broadly, this work is a step toward a detailed mechanistic understanding of human memory that is needed to develop therapies for human memory disorders.",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "https://www.jneurosci.org/content/jneuro/41/5/883.full.pdf",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "Journal of Neuroscience",
         "Medicine, Biology",
         "57",
         "ffce458267bc401455e35aa57197a0e9",
         "10.1523/JNEUROSCI.1648-20.2020",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00",
         "['Ueli Rutishauser', ' L. Reddy', ' F. Mormann', ' J. Sarnthein']"
        ],
        [
         "26",
         "85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "Mechanisms and mathematical modelling of ROS production by the mitochondrial electron transport chain.",
         "Sandeep Chenna, W. Koopman, J. Prehn, N. Connolly",
         "2022",
         "Reactive oxygen species (ROS) are recognised both as damaging molecules and intracellular signalling entities. In addition to its role in ATP generation, the mitochondrial electron transport chain (ETC) constitutes a relevant source of mitochondrial ROS, in particular during pathological conditions. Mitochondrial ROS homeostasis depends on species- and site-dependent ROS production, their bioreactivity, diffusion, and scavenging. However, our quantitative understanding of mitochondrial ROS homeostasis has thus far been hampered by technical limitations, including lack of truly site- and/or ROS-specific reporter molecules. In this context, the use of computational models is of great value to complement and interpret empirical data, as well as to predict variables that are difficult to assess experimentally. During the last decades, various mechanistic models of ETC-mediated ROS production have been developed. Although these often-complex models have generated novel insights, their parameterisation, analysis, and integration with other computational models is not straightforward. In contrast, phenomenological (sometimes termed \"minimal\") models use a relatively small set of equations to describe empirical relationship(s) between ROS-related and other parameters, and generally aim to explore system behaviour and generate hypotheses for experimental validation. In this review, we first discuss ETC-linked ROS homeostasis and introduce various detailed mechanistic models. Next, we present how bioenergetic parameters (e.g. NADH/NAD+ ratio, mitochondrial membrane potential) relate to site-specific ROS production within the ETC and how these relationships can be used to design minimal models of ROS homeostasis. Finally, we illustrate how minimal models have been applied to explore pathophysiological aspects of ROS.",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "https://figshare.com/articles/journal_contribution/Mechanisms_and_mathematical_modeling_of_ROS_production_by_the_mitochondrial_electron_transport_chain/20308254/1/files/36272712.pdf",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "American Journal of Physiology - Cell Physiology",
         "Medicine, Mathematics, Medicine",
         "56",
         "1a1ddb8e840f90dc765583768b6ce610",
         "10.1152/ajpcell.00455.2021",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Medicine'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00",
         "['Sandeep Chenna', ' W. Koopman', ' J. Prehn', ' N. Connolly']"
        ],
        [
         "27",
         "8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "Open Problems in Mechanistic Interpretability",
         "Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, Stella Biderman, Adrià Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, Eric Todd, Atticus Geiger, Mor Geva, Jesse Hoogland, Daniel Murfet, Thomas McGrath",
         "2025",
         "Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "https://arxiv.org/pdf/2501.16496.pdf",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "arXiv.org",
         "Computer Science, Computer Science, Philosophy",
         "52",
         "91df2ef4eadf077383bb23722f77664f",
         "10.48550/arXiv.2501.16496",
         "2501.16496",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:20.370015+00:00",
         "2025-09-29 20:01:51.158008+00:00",
         "['Lee Sharkey', ' Bilal Chughtai', ' Joshua Batson', ' Jack Lindsey', ' Jeff Wu', ' Lucius Bushnaq', ' Nicholas Goldowsky-Dill', ' Stefan Heimersheim', ' Alejandro Ortega', ' Joseph Bloom', ' Stella Biderman', ' Adrià Garriga-Alonso', ' Arthur Conmy', ' Neel Nanda', ' Jessica Rumbelow', ' Martin Wattenberg', ' Nandi Schoots', ' Joseph Miller', ' Eric J. Michaud', ' Stephen Casper', ' Max Tegmark', ' William Saunders', ' David Bau', ' Eric Todd', ' Atticus Geiger', ' Mor Geva', ' Jesse Hoogland', ' Daniel Murfet', ' Thomas McGrath']"
        ],
        [
         "28",
         "1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "High-throughput genetic clustering of type 2 diabetes loci reveals heterogeneous mechanistic pathways of metabolic disease",
         "Hyunkyung Kim, K. Westerman, Kirk Smith, Joshua Chiou, J. Cole, T. Majarian, Marcin von Grotthuss, S. Kwak, Jaegil Kim, J. Mercader, J. Florez, K. Gaulton, A. Manning, M. Udler",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "https://link.springer.com/content/pdf/10.1007/s00125-022-05848-6.pdf",
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "Diabetologia",
         "Medicine, Medicine, Biology",
         "50",
         "6177f0d87f15e961d672e7d0629df25d",
         "10.1007/s00125-022-05848-6",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00",
         "['Hyunkyung Kim', ' K. Westerman', ' Kirk Smith', ' Joshua Chiou', ' J. Cole', ' T. Majarian', ' Marcin von Grotthuss', ' S. Kwak', ' Jaegil Kim', ' J. Mercader', ' J. Florez', ' K. Gaulton', ' A. Manning', ' M. Udler']"
        ],
        [
         "29",
         "9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Non-negative Matrix Factorization: A Survey",
         "Jiangzhang Gan, Tong Liu, Li Li, Jilian Zhang",
         "2021",
         "\n Non-negative matrix factorization (NMF) is a powerful tool for data science researchers, and it has been successfully applied to data mining and machine learning community, due to its advantages such as simple form, good interpretability and less storage space. In this paper, we give a detailed survey on existing NMF methods, including a comprehensive analysis of their design principles, characteristics and drawbacks. In addition, we also discuss various variants of NMF methods and analyse properties and applications of these variants. Finally, we evaluate the performance of nine NMF methods through numerical experiments, and the results show that NMF methods perform well in clustering tasks.",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "https://mro.massey.ac.nz/bitstreams/7dbd6b5e-4d71-490a-b1b6-654e40181693/download",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Computer/law journal",
         "Computer Science, Mathematics, Computer Science, Mathematics",
         "50",
         "59e53699c3921eb318bb078214c055c5",
         "10.1093/COMJNL/BXAB103",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00",
         "['Jiangzhang Gan', ' Tong Liu', ' Li Li', ' Jilian Zhang']"
        ],
        [
         "30",
         "2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
         "Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, Ziyu Yao",
         "2024",
         "Mechanistic interpretability (MI) is an emerging sub-field of interpretability that seeks to understand a neural network model by reverse-engineering its internal computations. Recently, MI has garnered significant attention for interpreting transformer-based language models (LMs), resulting in many novel insights yet introducing new challenges. However, there has not been work that comprehensively reviews these insights and challenges, particularly as a guide for newcomers to this field. To fill this gap, we provide a comprehensive survey from a task-centric perspective, organizing the taxonomy of MI research around specific research questions or tasks. We outline the fundamental objects of study in MI, along with the techniques, evaluation methods, and key findings for each task in the taxonomy. In particular, we present a task-centric taxonomy as a roadmap for beginners to navigate the field by helping them quickly identify impactful problems in which they are most interested and leverage MI for their benefit. Finally, we discuss the current gaps in the field and suggest potential future directions for MI research.",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "https://arxiv.org/pdf/2407.02646.pdf",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "arXiv.org",
         "Computer Science, Computer Science",
         "50",
         "315f88620b6902745a1f3b994fd0e831",
         "10.48550/arXiv.2407.02646",
         "2407.02646",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.481838+00:00",
         "2025-09-29 20:01:43.961857+00:00",
         "['Daking Rai', ' Yilun Zhou', ' Shi Feng', ' Abulhair Saparov', ' Ziyu Yao']"
        ],
        [
         "31",
         "7748391c938dc6f6a5bae6ac56f33faf37686714",
         "The rotational and divergent components of atmospheric circulation on tidally locked planets",
         "M. Hammond, N. Lewis",
         "2021",
         "Significance Tidally locked exoplanets have a permanent day side and night side. Understanding the atmospheric circulation on these planets is crucial for interpreting telescope observations and assessing their habitability. We show that the main components of the circulation—a jet going around the planet, stationary atmospheric waves, and direct flow from the day side to the night side—can be separated using a simple mathematical decomposition. This decomposition will significantly aid future study of tidally locked atmospheres. As an illustration, we use it to quantify heat transport due to different components of the circulation. This analysis reveals that the direct day–night component can dominate heat transport from the day side to the night side, even when the jet is strong. Tidally locked exoplanets likely host global atmospheric circulations with a superrotating equatorial jet, planetary-scale stationary waves, and thermally driven overturning circulation. In this work, we show that each of these features can be separated from the total circulation by using a Helmholtz decomposition, which splits the circulation into rotational (divergence-free) and divergent (vorticity-free) components. This technique is applied to the simulated circulation of a terrestrial planet and a gaseous hot Jupiter. For both planets, the rotational component comprises the equatorial jet and stationary waves, and the divergent component contains the overturning circulation. Separating out each component allows us to evaluate their spatial structure and relative contribution to the total flow. In contrast with previous work, we show that divergent velocities are not negligible when compared with rotational velocities and that divergent, overturning circulation takes the form of a single, roughly isotropic cell that ascends on the day side and descends on the night side. These conclusions are drawn for both the terrestrial case and the hot Jupiter. To illustrate the utility of the Helmholtz decomposition for studying atmospheric processes, we compute the contribution of each of the circulation components to heat transport from day side to night side. Surprisingly, we find that the divergent circulation dominates day–night heat transport in the terrestrial case and accounts for around half of the heat transport for the hot Jupiter. The relative contributions of the rotational and divergent components to day–night heat transport are likely sensitive to multiple planetary parameters and atmospheric processes and merit further study.",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "https://www.pnas.org/doi/pdf/10.1073/pnas.2022705118",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "Proceedings of the National Academy of Sciences of the United States of America",
         "Medicine, Physics, Physics, Environmental Science",
         "48",
         "abff31af6dcd5fe122dec99d8ade4088",
         "10.1073/pnas.2022705118",
         "2102.1176",
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00",
         "['M. Hammond', ' N. Lewis']"
        ],
        [
         "32",
         "02ad427b0d20fb976741e332f69c2fd00c751164",
         "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
         "Dan Braun, Jordan K. Taylor, Nicholas Goldowsky-Dill, Lee Sharkey",
         "2024",
         "Identifying the features learned by neural networks is a core challenge in mechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse, overcomplete dictionary that reconstructs a network's internal activations, have been used to identify these features. However, SAEs may learn more about the structure of the datatset than the computational structure of the network. There is therefore only indirect reason to believe that the directions found in these dictionaries are functionally important to the network. We propose end-to-end (e2e) sparse dictionary learning, a method for training SAEs that ensures the features learned are functionally important by minimizing the KL divergence between the output distributions of the original model and the model with SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a Pareto improvement: They explain more network performance, require fewer total features, and require fewer simultaneously active features per datapoint, all with no cost to interpretability. We explore geometric and qualitative differences between e2e SAE features and standard SAE features. E2e dictionary learning brings us closer to methods that can explain network behavior concisely and accurately. We release our library for training e2e SAEs and reproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "https://arxiv.org/pdf/2405.12241.pdf",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "46",
         "5dc8cc7891318ba16ac9c75ba5693d16",
         "10.48550/arXiv.2405.12241",
         "2405.12241",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00",
         "['Dan Braun', ' Jordan K. Taylor', ' Nicholas Goldowsky-Dill', ' Lee Sharkey']"
        ],
        [
         "33",
         "f8029060e91209f048b3f9882f2cdd3607785ccd",
         "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability",
         "Ziming Liu, Eric Gan, Max Tegmark",
         "2023",
         "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that BIMT discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "http://arxiv.org/pdf/2305.08746",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "arXiv.org",
         "Computer Science, Physics, Mathematics, Biology, Computer Science",
         "46",
         "e067eaaff103d512e5af5296af1cdb46",
         "10.48550/arXiv.2305.08746",
         "2305.08746",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Physics'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.083803+00:00",
         "2025-09-29 20:01:45.576156+00:00",
         "['Ziming Liu', ' Eric Gan', ' Max Tegmark']"
        ],
        [
         "34",
         "e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "On scalable oversight with weak LLMs judging strong LLMs",
         "Zachary Kenton, Noah Y. Siegel, J'anos Kram'ar, Jonah Brown-Cohen, Samuel Albanie, Jannis Bulian, Rishabh Agarwal, David Lindner, Yunhao Tang, Noah D. Goodman, Rohin Shah",
         "2024",
         "Scalable oversight protocols aim to enable humans to accurately supervise superhuman AI. In this paper we study debate, where two AI's compete to convince a judge; consultancy, where a single AI tries to convince a judge that asks questions; and compare to a baseline of direct question-answering, where the judge just answers outright without the AI. We use large language models (LLMs) as both AI agents and as stand-ins for human judges, taking the judge models to be weaker than agent models. We benchmark on a diverse range of asymmetries between judges and agents, extending previous work on a single extractive QA task with information asymmetry, to also include mathematics, coding, logic and multimodal reasoning asymmetries. We find that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer. Comparing debate to direct question answering, the results depend on the type of task: in extractive QA tasks with information asymmetry debate outperforms direct question answering, but in other tasks without information asymmetry the results are mixed. Previous work assigned debaters/consultants an answer to argue for. When we allow them to instead choose which answer to argue for, we find judges are less frequently convinced by the wrong answer in debate than in consultancy. Further, we find that stronger debater models increase judge accuracy, though more modestly than in previous studies.",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "https://arxiv.org/pdf/2407.04622.pdf",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "44",
         "9c1fb35a2858675c73be477fb0ece0b3",
         "10.48550/arXiv.2407.04622",
         "2407.04622",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['Zachary Kenton', ' Noah Y. Siegel', \" J'anos Kram'ar\", ' Jonah Brown-Cohen', ' Samuel Albanie', ' Jannis Bulian', ' Rishabh Agarwal', ' David Lindner', ' Yunhao Tang', ' Noah D. Goodman', ' Rohin Shah']"
        ],
        [
         "35",
         "0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "PVC-SLP: Perceptual Vibrotactile-Signal Compression Based-on Sparse Linear Prediction",
         "Rania Hassen, Başak Güleçyüz, E. Steinbach",
         "2021",
         "Developing a signal compression technique that is able to achieve a low bit rate while maintaining high perceptual signal quality is a classical signal processing problem vigorously studied for audio, speech, image, and video type of signals. Yet, until recently, there has been limited effort directed toward the compression of vibrotactile signals, which represent a crucial element of rich touch (haptic) information. A vibrotactile signal; produced when stroking a textured surface with a tool-tip or bare-finger; like other signals contains a great deal of redundant and imperceptible information that can be exploited for efficient compression. This paper presents PVC-SLP, a vibrotactile perceptual coding approach. PVC-SLP employs a model of tactile sensitivity; called ASF (Acceleration Sensitivity Function); for perceptual coding. The ASF is inspired by the four channels model that mediate the perception of vibrotactile stimuli in the glabrous skin. The compression algorithm introduces sparsity constraints in a linear prediction scheme both on the residual and the predictor coefficients. The perceptual quantization of the residual is developed through the use of ASF. The quantization parameters of the residual and the predictor coefficients were jointly optimized; by means of both squared error and perceptual quality measures; to find the sweet spot of the rate-distortion curve. PVC-SLP coding performance is evaluated using two publicly available databases that collectively comprise 1281 vibrotactile signals covering 193 material classes. Furthermore, we compare PVC-SLP with a recent vibrotactile compression method and show that PVC-SLP perceptually outperforms existing method by a sizable margin. Most recently, PVC-SLP has been selected to become part of the haptic codec standard currently under preparation by IEEE P1918.1.1, aka Haptic Codecs for the Tactile Internet.",
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         null,
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "IEEE transactions on multimedia",
         "Computer Science, Computer Science",
         "44",
         "99db78f4eb2492099f409ede6822e163",
         "10.1109/tmm.2020.3042674",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00",
         "['Rania Hassen', ' Başak Güleçyüz', ' E. Steinbach']"
        ],
        [
         "36",
         "ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Hybrid modelling of water resource recovery facilities: status and opportunities.",
         "M. Y. Schneider, Ward Quaghebeur, Sina Borzooei, A. Froemelt, Feiyi Li, R. Saagi, Matthew John Wade, Jun‐Jie Zhu, E. Torfs",
         "2022",
         "Mathematical modelling is an indispensable tool to support water resource recovery facility (WRRF) operators and engineers with the ambition of creating a truly circular economy and assuring a sustainable future. Despite the successful application of mechanistic models in the water sector, they show some important limitations and do not fully profit from the increasing digitalisation of systems and processes. Recent advances in data-driven methods have provided options for harnessing the power of Industry 4.0, but they are often limited by the lack of interpretability and extrapolation capabilities. Hybrid modelling (HM) combines these two modelling paradigms and aims to leverage both the rapidly increasing volumes of data collected, as well as the continued pursuit of greater process understanding. Despite the potential of HM in a sector that is undergoing a significant digital and cultural transformation, the application of hybrid models remains vague. This article presents an overview of HM methodologies applied to WRRFs and aims to stimulate the wider adoption and development of HM. We also highlight challenges and research needs for HM design and architecture, good modelling practice, data assurance, and software compatibility. HM is a paradigm for WRRF modelling to transition towards a more resource-efficient, resilient, and sustainable future.",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "https://iwaponline.com/wst/article-pdf/85/9/2503/1064960/wst085092503.pdf",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Water Science and Technology",
         "Medicine, Environmental Science, Engineering",
         "42",
         "46d3af83fe7d76740b0f84253214e6c5",
         "10.2166/wst.2022.115",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00",
         "['M. Y. Schneider', ' Ward Quaghebeur', ' Sina Borzooei', ' A. Froemelt', ' Feiyi Li', ' R. Saagi', ' Matthew John Wade', ' Jun‐Jie Zhu', ' E. Torfs']"
        ],
        [
         "37",
         "63a87feede94433b44b2c2b194e5902c3c5158f2",
         "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation",
         "Aaditya K. Singh, Ted Moskovitz, Felix Hill, S. C. Chan, Andrew M. Saxe",
         "2024",
         "In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning -- the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By clamping subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to\"go right\"for an induction head.",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "https://arxiv.org/pdf/2404.07129.pdf",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "International Conference on Machine Learning",
         "Computer Science",
         "41",
         "160d0353f52a1dccf893bdae96e30380",
         "10.48550/arXiv.2404.07129",
         "2404.07129",
         "[{'source': 'external', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.524693+00:00",
         "2025-09-29 20:02:01.691828+00:00",
         "['Aaditya K. Singh', ' Ted Moskovitz', ' Felix Hill', ' S. C. Chan', ' Andrew M. Saxe']"
        ],
        [
         "38",
         "680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
         "Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe",
         "2024",
         "How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate this kind of easy-to-hard generalization using simple finetuning methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect easy data rather than hard data for finetuning, since hard data is generally noisier and costlier to collect. Our experiments use open models up to 70b in size and four publicly available question-answering datasets with questions ranging in difficulty from 3rd grade science questions to college level STEM questions and general-knowledge trivia. We conclude that easy-to-hard generalization in LMs is surprisingly strong for the tasks studied. Our code is available at: https://github.com/allenai/easy-to-hard-generalization",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "https://arxiv.org/pdf/2401.06751.pdf",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "39",
         "fd9c2650583db7080c93fe4ad97bc16a",
         "10.48550/arXiv.2401.06751",
         "2401.06751",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['Peter Hase', ' Mohit Bansal', ' Peter Clark', ' Sarah Wiegreffe']"
        ],
        [
         "39",
         "d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "Multi-Modal Convolutional Dictionary Learning",
         "Fangyuan Gao, Xin Deng, Mai Xu, Jingyi Xu, P. Dragotti",
         "2022",
         "Convolutional dictionary learning has become increasingly popular in signal and image processing for its ability to overcome the limitations of traditional patch-based dictionary learning. Although most studies on convolutional dictionary learning mainly focus on the unimodal case, real-world image processing tasks usually involve images from multiple modalities, e.g., visible and near-infrared (NIR) images. Thus, it is necessary to explore convolutional dictionary learning across different modalities. In this paper, we propose a novel multi-modal convolutional dictionary learning algorithm, which efficiently correlates different image modalities and fully considers neighborhood information at the image level. In this model, each modality is represented by two convolutional dictionaries, in which one dictionary is for common feature representation and the other is for unique feature representation. The model is constrained by the requirement that the convolutional sparse representations (CSRs) for the common features should be the same across different modalities, considering that these images are captured from the same scene. We propose a new training method based on the alternating direction method of multipliers (ADMM) to alternatively learn the common and unique dictionaries in the discrete Fourier transform (DFT) domain. We show that our model converges in less than 20 iterations between the convolutional dictionary updating and the CSRs calculation. The effectiveness of the proposed dictionary learning algorithm is demonstrated on various multimodal image processing tasks, achieves better performance than both dictionary learning methods and deep learning based methods with limited training data.",
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         null,
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "IEEE Transactions on Image Processing",
         "Computer Science, Medicine, Computer Science, Environmental Science",
         "39",
         "e087496c780892e3207eb83d96645f87",
         "10.1109/TIP.2022.3141251",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00",
         "['Fangyuan Gao', ' Xin Deng', ' Mai Xu', ' Jingyi Xu', ' P. Dragotti']"
        ],
        [
         "40",
         "2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "Diffusion Models for Audio Restoration: A review [Special Issue On Model-Based and Data-Driven Audio Signal Processing]",
         "Jean-Marie Lemercier, Julius Richter, Simon Welker, Eloi Moliner, V. Välimäki, Timo Gerkmann",
         "2024",
         "With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift toward data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged as powerful techniques for learning complex data distributions. However, relying solely on DNN-based learning approaches carries the risk of reducing interpretability, particularly when employing end-to-end models. Nonetheless, data-driven approaches allow more flexibility in comparison to statistical model-based frameworks, whose performance depends on distributional and statistical assumptions that can be difficult to guarantee. Here, we aim to show that diffusion models can combine the best of both worlds and offer the opportunity to design audio restoration algorithms with a good degree of interpretability and a remarkable performance in terms of sound quality. In this article, we review the use of diffusion models for audio restoration. We explain the diffusion formalism and its application to the conditional generation of clean audio signals. We believe that diffusion models open an exciting field of research with the potential to spawn new audio restoration algorithms that are natural-sounding and remain robust in difficult acoustic situations.",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "https://arxiv.org/pdf/2402.09821.pdf",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Computer Science, Engineering",
         "37",
         "e188cd7a5af5364280ca4c2fd54355b5",
         "10.1109/MSP.2024.3445871",
         "2402.09821",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00",
         "['Jean-Marie Lemercier', ' Julius Richter', ' Simon Welker', ' Eloi Moliner', ' V. Välimäki', ' Timo Gerkmann']"
        ],
        [
         "41",
         "5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Interpretability of artificial neural network models in artificial intelligence versus neuroscience",
         "Kohitij Kar, Simon Kornblith, Evelina Fedorenko",
         "2022",
         "Computationally explicit hypotheses of brain function derived from machine learning (ML)-based models have recently revolutionized neuroscience. Despite the unprecedented ability of these artificial neural networks (ANNs) to capture responses in biological neural networks (brains), and our full access to all internal model components (unlike the brain), ANNs are often referred to as black-boxes with limited interpretability. Interpretability, however, is a multi-faceted construct that is used differently across fields. In particular, interpretability, or explainability, efforts in Artificial Intelligence (AI) focus on understanding how different model components contribute to its output (i.e., decision making). In contrast, the neuroscientific interpretability of ANNs requires explicit alignment between model components and neuroscientific constructs (e.g., different brain areas or phenomena, like recurrence or top-down feedback). Given the widespread calls to improve the interpretability of AI systems, we here highlight these different notions of interpretability and argue that the neuroscientific interpretability of ANNs can be pursued in parallel with, but independently from, the ongoing efforts in AI. Certain ML techniques (e.g., deep dream) can be leveraged in both fields, to ask what stimulus optimally activates the specific model features (feature visualization by optimization), or how different features contribute to the model's output (feature attribution). However, without appropriate brain alignment, certain features will remain uninterpretable to neuroscientists.",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "https://arxiv.org/pdf/2206.03951",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Nat. Mac. Intell.",
         "Computer Science, Biology, Computer Science, Philosophy",
         "36",
         "7387e8bb067dd5c477ba0c3fe39df6a4",
         "10.1038/s42256-022-00592-3",
         "2206.03951",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:59.476166+00:00",
         "2025-09-29 20:01:59.476166+00:00",
         "['Kohitij Kar', ' Simon Kornblith', ' Evelina Fedorenko']"
        ],
        [
         "42",
         "c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Application of non-negative matrix factorization in oncology: one approach for establishing precision medicine",
         "Ryuji Hamamoto, Ken Takasawa, Hidenori Machino, Kazuma Kobayashi, Satoshi Takahashi, Amina Bolatkan, Norio Shinkai, Akira Sakai, R. Aoyama, Masayoshi Yamada, Ken Asada, M. Komatsu, Koji Okamoto, H. Kameoka, S. Kaneko",
         "2022",
         "Abstract The increase in the expectations of artificial intelligence (AI) technology has led to machine learning technology being actively used in the medical field. Non-negative matrix factorization (NMF) is a machine learning technique used for image analysis, speech recognition, and language processing; recently, it is being applied to medical research. Precision medicine, wherein important information is extracted from large-scale medical data to provide optimal medical care for every individual, is considered important in medical policies globally, and the application of machine learning techniques to this end is being handled in several ways. NMF is also introduced differently because of the characteristics of its algorithms. In this review, the importance of NMF in the field of medicine, with a focus on the field of oncology, is described by explaining the mathematical science of NMF and the characteristics of the algorithm, providing examples of how NMF can be used to establish precision medicine, and presenting the challenges of NMF. Finally, the direction regarding the effective use of NMF in the field of oncology is also discussed.",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "https://academic.oup.com/bib/article-pdf/23/4/bbac246/45017265/bbac246.pdf",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Briefings Bioinform.",
         "Medicine, Computer Science, Medicine, Computer Science",
         "35",
         "cea76d54281f58364f2cdbd89a30795c",
         "10.1093/bib/bbac246",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00",
         "['Ryuji Hamamoto', ' Ken Takasawa', ' Hidenori Machino', ' Kazuma Kobayashi', ' Satoshi Takahashi', ' Amina Bolatkan', ' Norio Shinkai', ' Akira Sakai', ' R. Aoyama', ' Masayoshi Yamada', ' Ken Asada', ' M. Komatsu', ' Koji Okamoto', ' H. Kameoka', ' S. Kaneko']"
        ],
        [
         "43",
         "59b988fda9c1737465921a9bade731d511500718",
         "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
         "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
         "2024",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         "arXiv.org",
         "Computer Science, Psychology",
         "35",
         "ba9e6b607a4904c9b0fa98dd7fb06b26",
         "10.48550/arXiv.2408.01416",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:40.147869+00:00",
         "2025-09-30 00:45:40.147869+00:00",
         "['Aaron Mueller', ' Jannik Brinkmann', ' Millicent Li', ' Samuel Marks', ' Koyena Pal', ' Nikhil Prakash', ' Can Rager', ' Aruna Sankaranarayanan', ' Arnab Sen Sharma', ' Jiuding Sun', ' Eric Todd', ' David Bau', ' Yonatan Belinkov']"
        ],
        [
         "44",
         "b437d4398b443234aa253156404e12326ba899a5",
         "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
         "Mitchell Ostrow, Adam Eisen, L. Kozachkov, I. Fiete",
         "2023",
         "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "https://arxiv.org/pdf/2306.10168",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "Neural Information Processing Systems",
         "Biology, Computer Science, Computer Science",
         "35",
         "fada21b27d9df8d40aef2026b27654ac",
         "10.48550/arXiv.2306.10168",
         "2306.10168",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:41.941797+00:00",
         "2025-09-29 20:01:41.941797+00:00",
         "['Mitchell Ostrow', ' Adam Eisen', ' L. Kozachkov', ' I. Fiete']"
        ],
        [
         "45",
         "557dce8787129ca623fcb2cca2e76e9920347b69",
         "Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms",
         "Alireza Fallah, A. Makhdoumi, Azarakhsh Malekian, A. Ozdaglar",
         "2022",
         "We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "https://arxiv.org/pdf/2201.03968.pdf",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "ACM Conference on Economics and Computation",
         "Computer Science, Computer Science, Economics",
         "34",
         "6f74ae4cba716c1607ae234c9694a38e",
         "10.1145/3490486.3538329",
         "2201.03968",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00",
         "['Alireza Fallah', ' A. Makhdoumi', ' Azarakhsh Malekian', ' A. Ozdaglar']"
        ],
        [
         "46",
         "d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP",
         "Vedant Palit, Rohan Pandey, Aryaman Arora, Paul Pu Liang",
         "2023",
         "Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have identified neural circuits that copy spans of text, capture factual knowledge, and more, they remain unusable for multimodal models since adapting these tools to the vision-language domain requires considerable architectural changes. In this work, we adapt a unimodal causal tracing tool to BLIP to enable the study of the neural mechanisms underlying image-conditioned text generation. We demonstrate our approach on a visual question answering dataset, highlighting the causal relevance of later layer representations for all tokens. Furthermore, we release our BLIP causal tracing tool as open source to enable further experimentation in vision-language mechanistic interpretability by the community. Our code is available at this URL.",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "https://arxiv.org/pdf/2308.14179",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
         "Computer Science, Computer Science",
         "34",
         "9cf5a58ea2e4185711ce7b8677794afc",
         "10.1109/ICCVW60793.2023.00307",
         "2308.14179",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.758641+00:00",
         "2025-09-29 20:01:46.494319+00:00",
         "['Vedant Palit', ' Rohan Pandey', ' Aryaman Arora', ' Paul Pu Liang']"
        ],
        [
         "47",
         "6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning",
         "Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang",
         "2023",
         "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "https://arxiv.org/pdf/2311.07954.pdf",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "North American Chapter of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "32",
         "c392393c2dc5c78e3dc51c1d7ab07def",
         "10.48550/arXiv.2311.07954",
         "2311.07954",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00",
         "['Ruixin Hong', ' Hongming Zhang', ' Xinyu Pang', ' Dong Yu', ' Changshui Zhang']"
        ],
        [
         "48",
         "f3658afcd181e4078e1e96ff86eac224fd92faab",
         "ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability",
         "ZhongXiang Sun, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu, Xiao Zhang, Weijie Yu, Han Li",
         "2024",
         "Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric (internal) knowledge. However, even with accurate and relevant retrieved content, RAG models can still produce hallucinations by generating outputs that conflict with the retrieved information. Detecting such hallucinations requires disentangling how Large Language Models (LLMs) utilize external and parametric knowledge. Current detection methods often focus on one of these mechanisms or without decoupling their intertwined effects, making accurate detection difficult. In this paper, we investigate the internal mechanisms behind hallucinations in RAG scenarios. We discover hallucinations occur when the Knowledge FFNs in LLMs overemphasize parametric knowledge in the residual stream, while Copying Heads fail to effectively retain or integrate external knowledge from retrieved content. Based on these findings, we propose ReDeEP, a novel method that detects hallucinations by decoupling LLM's utilization of external context and parametric knowledge. Our experiments show that ReDeEP significantly improves RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by modulating the contributions of Knowledge FFNs and Copying Heads.",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "https://arxiv.org/pdf/2410.11414.pdf",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "32",
         "ac30ae75b45154f43567d24b201cee78",
         "10.48550/arXiv.2410.11414",
         "2410.11414",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.714672+00:00",
         "2025-09-29 20:01:43.739899+00:00",
         "['ZhongXiang Sun', ' Xiaoxue Zang', ' Kai Zheng', ' Yang Song', ' Jun Xu', ' Xiao Zhang', ' Weijie Yu', ' Han Li']"
        ],
        [
         "49",
         "7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Orthogonal Non-negative Tensor Factorization based Multi-view Clustering",
         "Jing Li, Quanxue Gao, Qianqian Wang, Ming Yang, Wei Xia",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Mathematics",
         "31",
         "20a966da2d81a77230eb9bf78d244a46",
         null,
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00",
         "['Jing Li', ' Quanxue Gao', ' Qianqian Wang', ' Ming Yang', ' Wei Xia']"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 759
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>authors_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>[David Rein,  Betty Li Hou,  Asa Cooper Stickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edd112383ad494f5f2eba72b6f4ffae122ce61f</td>\n",
       "      <td>Interpretability in the Wild: a Circuit for In...</td>\n",
       "      <td>Kevin Wang, Alexandre Variengien, Arthur Conmy...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Research in mechanistic interpretability seeks...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>https://arxiv.org/pdf/2211.00593</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>644</td>\n",
       "      <td>1ff47a5be9a68e64e23ad2359d220370</td>\n",
       "      <td>10.48550/arXiv.2211.00593</td>\n",
       "      <td>2211.00593</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:28.298552+00:00</td>\n",
       "      <td>2025-09-29 20:02:03.480569+00:00</td>\n",
       "      <td>[Kevin Wang,  Alexandre Variengien,  Arthur Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0893549771094fac547432cb4f84e9605c911a86</td>\n",
       "      <td>The imperative for regulatory oversight of lar...</td>\n",
       "      <td>B. Meskó, E. Topol</td>\n",
       "      <td>2023</td>\n",
       "      <td>The rapid advancements in artificial intellige...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>https://www.nature.com/articles/s41746-023-008...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>npj Digit. Medicine</td>\n",
       "      <td>Computer Science, Medicine, Medicine, Computer...</td>\n",
       "      <td>627</td>\n",
       "      <td>920cc7dbbd6a0bb608e11b65097d69ef</td>\n",
       "      <td>10.1038/s41746-023-00873-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>[B. Meskó,  E. Topol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f680d47a51a0e470fcb228bf0110c026535ead1b</td>\n",
       "      <td>Progress measures for grokking via mechanistic...</td>\n",
       "      <td>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neural networks often exhibit emergent behavio...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05217</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>517</td>\n",
       "      <td>953089e9556a8e0b37293683f8ff8807</td>\n",
       "      <td>10.48550/arXiv.2301.05217</td>\n",
       "      <td>2301.05217</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:13.784216+00:00</td>\n",
       "      <td>2025-09-29 20:01:43.521903+00:00</td>\n",
       "      <td>[Neel Nanda,  Lawrence Chan,  Tom Lieberum,  J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefbd8b384a58f464827b19e30a6920ba976def9</td>\n",
       "      <td>Towards Automated Circuit Discovery for Mechan...</td>\n",
       "      <td>Arthur Conmy, Augustine N. Mavor-Parker, Aengu...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Through considerable effort and intuition, sev...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>https://arxiv.org/pdf/2304.14997</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>Neural Information Processing Systems</td>\n",
       "      <td>Computer Science, Computer Science, Engineering</td>\n",
       "      <td>356</td>\n",
       "      <td>a97a69c6234d51eeafeb50c9077b71ba</td>\n",
       "      <td>10.48550/arXiv.2304.14997</td>\n",
       "      <td>2304.14997</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:14.252982+00:00</td>\n",
       "      <td>2025-09-29 20:01:44.864490+00:00</td>\n",
       "      <td>[Arthur Conmy,  Augustine N. Mavor-Parker,  Ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2</td>\n",
       "      <td>Mechanistic Interpretability of GPT-like Model...</td>\n",
       "      <td>Anurag Mishra</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability research seeks to...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.17073.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>3771d70ffd60f9c3f692d0e8f989f74d</td>\n",
       "      <td>10.48550/arXiv.2505.17073</td>\n",
       "      <td>2505.17073</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.786419+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.195754+00:00</td>\n",
       "      <td>[Anurag Mishra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>663292eaef24c22c0692f1b4a9120d24662d7fc7</td>\n",
       "      <td>Causal Intervention Framework for Variational ...</td>\n",
       "      <td>Dip Roy</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability of deep learning ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.03530.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>2f8d578153eefbc0b11361f9e71a0194</td>\n",
       "      <td>10.48550/arXiv.2505.03530</td>\n",
       "      <td>2505.03530</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.332786+00:00</td>\n",
       "      <td>2025-09-29 20:01:57.450585+00:00</td>\n",
       "      <td>[Dip Roy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "      <td>[Marcos Florencio,  Thomas Barton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>49072764553763f1686121fd03e3dadda259f273</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>2024</td>\n",
       "      <td>Recent research (arXiv:2310.11453, arXiv:2402....</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>https://arxiv.org/pdf/2405.17703.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>81612dabd9dc5de68fc08c32d1ed9a14</td>\n",
       "      <td>10.48550/arXiv.2405.17703</td>\n",
       "      <td>2405.17703</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.685040+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.957507+00:00</td>\n",
       "      <td>[Jason Li]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "      <td>[Tristan Trim,  Triston Grayston]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_id  \\\n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "1    6edd112383ad494f5f2eba72b6f4ffae122ce61f   \n",
       "2    0893549771094fac547432cb4f84e9605c911a86   \n",
       "3    f680d47a51a0e470fcb228bf0110c026535ead1b   \n",
       "4    eefbd8b384a58f464827b19e30a6920ba976def9   \n",
       "..                                        ...   \n",
       "754  f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2   \n",
       "755  663292eaef24c22c0692f1b4a9120d24662d7fc7   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "757  49072764553763f1686121fd03e3dadda259f273   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "1    Interpretability in the Wild: a Circuit for In...   \n",
       "2    The imperative for regulatory oversight of lar...   \n",
       "3    Progress measures for grokking via mechanistic...   \n",
       "4    Towards Automated Circuit Discovery for Mechan...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic Interpretability of GPT-like Model...   \n",
       "755  Causal Intervention Framework for Variational ...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "757  Mechanistic Interpretability of Binary and Ter...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                               authors  year  \\\n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...  2023   \n",
       "1    Kevin Wang, Alexandre Variengien, Arthur Conmy...  2022   \n",
       "2                                   B. Meskó, E. Topol  2023   \n",
       "3    Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...  2023   \n",
       "4    Arthur Conmy, Augustine N. Mavor-Parker, Aengu...  2023   \n",
       "..                                                 ...   ...   \n",
       "754                                      Anurag Mishra  2025   \n",
       "755                                            Dip Roy  2025   \n",
       "756                    Marcos Florencio, Thomas Barton  2025   \n",
       "757                                           Jason Li  2024   \n",
       "758                     Tristan Trim, Triston Grayston  2024   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    We present GPQA, a challenging dataset of 448 ...   \n",
       "1    Research in mechanistic interpretability seeks...   \n",
       "2    The rapid advancements in artificial intellige...   \n",
       "3    Neural networks often exhibit emergent behavio...   \n",
       "4    Through considerable effort and intuition, sev...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic interpretability research seeks to...   \n",
       "755  Mechanistic interpretability of deep learning ...   \n",
       "756  Architectural obfuscation - e.g., permuting hi...   \n",
       "757  Recent research (arXiv:2310.11453, arXiv:2402....   \n",
       "758  This paper explores the mechanistic interpreta...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                               pdf_url  \\\n",
       "0                 https://arxiv.org/pdf/2311.12022.pdf   \n",
       "1                     https://arxiv.org/pdf/2211.00593   \n",
       "2    https://www.nature.com/articles/s41746-023-008...   \n",
       "3                      http://arxiv.org/pdf/2301.05217   \n",
       "4                     https://arxiv.org/pdf/2304.14997   \n",
       "..                                                 ...   \n",
       "754               https://arxiv.org/pdf/2505.17073.pdf   \n",
       "755               https://arxiv.org/pdf/2505.03530.pdf   \n",
       "756               https://arxiv.org/pdf/2506.18053.pdf   \n",
       "757               https://arxiv.org/pdf/2405.17703.pdf   \n",
       "758               https://arxiv.org/pdf/2411.00867.pdf   \n",
       "\n",
       "                                           scholar_url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                                 venue  \\\n",
       "0                                            arXiv.org   \n",
       "1    International Conference on Learning Represent...   \n",
       "2                                  npj Digit. Medicine   \n",
       "3    International Conference on Learning Represent...   \n",
       "4                Neural Information Processing Systems   \n",
       "..                                                 ...   \n",
       "754                                          arXiv.org   \n",
       "755                                          arXiv.org   \n",
       "756                                          arXiv.org   \n",
       "757                                          arXiv.org   \n",
       "758                                          arXiv.org   \n",
       "\n",
       "                                              keywords  citations  \\\n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "1                   Computer Science, Computer Science        644   \n",
       "2    Computer Science, Medicine, Medicine, Computer...        627   \n",
       "3                   Computer Science, Computer Science        517   \n",
       "4      Computer Science, Computer Science, Engineering        356   \n",
       "..                                                 ...        ...   \n",
       "754                 Computer Science, Computer Science          0   \n",
       "755                 Computer Science, Computer Science          0   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "757                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "\n",
       "                           title_hash                         doi    arxiv_id  \\\n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                         NaN  2311.12022   \n",
       "1    1ff47a5be9a68e64e23ad2359d220370   10.48550/arXiv.2211.00593  2211.00593   \n",
       "2    920cc7dbbd6a0bb608e11b65097d69ef  10.1038/s41746-023-00873-0         NaN   \n",
       "3    953089e9556a8e0b37293683f8ff8807   10.48550/arXiv.2301.05217  2301.05217   \n",
       "4    a97a69c6234d51eeafeb50c9077b71ba   10.48550/arXiv.2304.14997  2304.14997   \n",
       "..                                ...                         ...         ...   \n",
       "754  3771d70ffd60f9c3f692d0e8f989f74d   10.48550/arXiv.2505.17073  2505.17073   \n",
       "755  2f8d578153eefbc0b11361f9e71a0194   10.48550/arXiv.2505.03530  2505.03530   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34   10.48550/arXiv.2506.18053  2506.18053   \n",
       "757  81612dabd9dc5de68fc08c32d1ed9a14   10.48550/arXiv.2405.17703  2405.17703   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82   10.48550/arXiv.2411.00867  2411.00867   \n",
       "\n",
       "                                             s2_fields  \\\n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "1    [{'source': 'external', 'category': 'Computer ...   \n",
       "2    [{'source': 'external', 'category': 'Computer ...   \n",
       "3    [{'source': 'external', 'category': 'Computer ...   \n",
       "4    [{'source': 'external', 'category': 'Computer ...   \n",
       "..                                                 ...   \n",
       "754  [{'source': 'external', 'category': 'Computer ...   \n",
       "755  [{'source': 'external', 'category': 'Computer ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "757  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                           created_at                        updated_at  \\\n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00   \n",
       "1    2025-09-29 20:01:28.298552+00:00  2025-09-29 20:02:03.480569+00:00   \n",
       "2    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00   \n",
       "3    2025-09-29 20:01:13.784216+00:00  2025-09-29 20:01:43.521903+00:00   \n",
       "4    2025-09-29 20:01:14.252982+00:00  2025-09-29 20:01:44.864490+00:00   \n",
       "..                                ...                               ...   \n",
       "754  2025-09-29 20:01:25.786419+00:00  2025-09-29 20:01:55.195754+00:00   \n",
       "755  2025-09-29 20:01:25.332786+00:00  2025-09-29 20:01:57.450585+00:00   \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00   \n",
       "757  2025-09-29 20:01:19.685040+00:00  2025-09-29 20:01:48.957507+00:00   \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00   \n",
       "\n",
       "                                          authors_list  \n",
       "0    [David Rein,  Betty Li Hou,  Asa Cooper Stickl...  \n",
       "1    [Kevin Wang,  Alexandre Variengien,  Arthur Co...  \n",
       "2                                [B. Meskó,  E. Topol]  \n",
       "3    [Neel Nanda,  Lawrence Chan,  Tom Lieberum,  J...  \n",
       "4    [Arthur Conmy,  Augustine N. Mavor-Parker,  Ae...  \n",
       "..                                                 ...  \n",
       "754                                    [Anurag Mishra]  \n",
       "755                                          [Dip Roy]  \n",
       "756                 [Marcos Florencio,  Thomas Barton]  \n",
       "757                                         [Jason Li]  \n",
       "758                  [Tristan Trim,  Triston Grayston]  \n",
       "\n",
       "[759 rows x 18 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df['authors_list'] = semantic_df.apply(\n",
    "    lambda x: list(str(x['authors']).split(',')),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "semantic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "faaf6693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'title', 'authors', 'year', 'abstract', 'url', 'pdf_url',\n",
       "       'scholar_url', 'venue', 'keywords', 'citations', 'title_hash', 'doi',\n",
       "       'arxiv_id', 's2_fields', 'created_at', 'updated_at', 'authors_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5c0ca45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "24229c85-2814-4182-987a-d7618b06c034",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "['David Rein', ' Betty Li Hou', ' Asa Cooper Stickland', ' Jackson Petty', ' Richard Yuanzhe Pang', ' Julien Dirani', ' Julian Michael', ' Samuel R. Bowman']",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "['Kevin Wang', ' Alexandre Variengien', ' Arthur Conmy', ' Buck Shlegeris', ' J. Steinhardt']",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Meskó, E. Topol",
         "['B. Meskó', ' E. Topol']",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "['Neel Nanda', ' Lawrence Chan', ' Tom Lieberum', ' Jess Smith', ' J. Steinhardt']",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         "['Arthur Conmy', ' Augustine N. Mavor-Parker', ' Aengus Lynch', ' Stefan Heimersheim', ' Adrià Garriga-Alonso']",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         "['X. Fang', ' C. Lloyd', ' B. Palsson']",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         "['Leonard Bereska', ' E. Gavves']",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         "['Xiaowen Dong', ' D. Thanou', ' L. Toni', ' M. Bronstein', ' P. Frossard']",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         "['Caio Seguin', ' O. Sporns', ' A. Zalesky']",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         "['S. Loomba', ' Jakob Straehle', ' V. Gangadharan', ' Natalie Heike', ' Abdelrahman Khalifa', ' Alessandro Motta', ' Niansheng Ju', ' Meike Sievers', ' J. Gempt', ' H. S. Meyer', ' M. Helmstaedter']",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "10",
         "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Sam Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilė Lukošiūtė, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, C. McKinnon, Chris Olah, D. Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, John Kernion, Jamie Kerr, J. Mueller, Jeffrey Ladish, J. Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noem'i Mercado, Nova Dassarma, Robin Larson, Sam McCandlish, S. Kundu, Scott Johnston, Shauna Kravec, S. E. Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom B. Brown, T. Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Benjamin Mann, Jared Kaplan",
         "['Sam Bowman', ' Jeeyoon Hyun', ' Ethan Perez', ' Edwin Chen', ' Craig Pettit', ' Scott Heiner', ' Kamilė Lukošiūtė', ' Amanda Askell', ' Andy Jones', ' Anna Chen', ' Anna Goldie', ' Azalia Mirhoseini', ' C. McKinnon', ' Chris Olah', ' D. Amodei', ' Dario Amodei', ' Dawn Drain', ' Dustin Li', ' Eli Tran-Johnson', ' John Kernion', ' Jamie Kerr', ' J. Mueller', ' Jeffrey Ladish', ' J. Landau', ' Kamal Ndousse', ' Liane Lovitt', ' Nelson Elhage', ' Nicholas Schiefer', ' Nicholas Joseph', \" Noem'i Mercado\", ' Nova Dassarma', ' Robin Larson', ' Sam McCandlish', ' S. Kundu', ' Scott Johnston', ' Shauna Kravec', ' S. E. Showk', ' Stanislav Fort', ' Timothy Telleen-Lawton', ' Tom B. Brown', ' T. Henighan', ' Tristan Hume', ' Yuntao Bai', ' Zac Hatfield-Dodds', ' Benjamin Mann', ' Jared Kaplan']",
         "2022",
         "Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks.",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "https://arxiv.org/pdf/2211.03540",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "arXiv.org",
         "Computer Science, Computer Science, Linguistics",
         "149",
         "bd891ffa97410f74480c289f6510913c",
         "10.48550/arXiv.2211.03540",
         "2211.0354",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Linguistics'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "11",
         "f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "An Incentive-Compatible Energy Trading Framework for Neighborhood Area Networks With Shared Energy Storage",
         "C. Mediwaththe, M. Shaw, S. Halgamuge, David B. Smith, P. Scott",
         "['C. Mediwaththe', ' M. Shaw', ' S. Halgamuge', ' David B. Smith', ' P. Scott']",
         "2020",
         "Here, a novel energy trading system is proposed for demand-side management of a neighborhood area network (NAN) consisting of a shared energy storage (SES) provider, users with non-dispatchable energy generation, and an electricity retailer. In a leader–follower Stackelberg game, the SES provider first maximizes their revenue by setting a price signal and trading energy with the grid. Then, by following the SES provider's actions, the retailer minimizes social cost for the users, i.e., the sum of the total users’ cost when they interact with the SES and the total cost for supplying grid energy to the users. A pricing strategy, which incorporates mechanism design, is proposed to make the system incentive-compatible by rewarding users who disclose true energy usage information. A unique Stackelberg equilibrium is achieved where the SES provider's revenue is maximized and the user-level social cost is minimized, which also rewards the retailer. A case study with realistic energy demand and generation data demonstrates 28–45% peak demand reduction of the NAN, depending on the number of participating users, compared to a system without SES. Simulation results confirm that the retailer can also benefit financially, in addition to the SES provider and the users.",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "https://arxiv.org/pdf/2008.10384",
         "https://www.semanticscholar.org/paper/f45f61e5d0df0b09cc453eb7a1ea3efbd97ecdd4",
         "IEEE Transactions on Sustainable Energy",
         "Engineering, Computer Science, Engineering, Economics, Environmental Science",
         "114",
         "203c35336c8ae692de21ba24e812a8e8",
         "10.1109/TSTE.2019.2895387",
         "2008.10384",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "12",
         "dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
         "Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",
         "['Chujie Zheng', ' Zhenru Zhang', ' Beichen Zhang', ' Runji Lin', ' Keming Lu', ' Bowen Yu', ' Dayiheng Liu', ' Jingren Zhou', ' Junyang Lin']",
         "2024",
         "As language models regularly make mistakes when solving math problems, automated identification of errors in the reasoning process becomes increasingly significant for their scalable oversight. In this paper, we introduce ProcessBench for measuring the ability to identify erroneous steps in mathematical reasoning. It consists of 3,400 test cases, primarily focused on competition- and Olympiad-level math problems. Each test case contains a step-by-step solution with error location annotated by human experts. Models are required to identify the earliest step that contains an error, or conclude that all steps are correct. We conduct extensive evaluation on ProcessBench, involving two types of models: process reward models (PRMs) and critic models, where for the latter we prompt general language models to critique each solution step by step. We draw two main observations: (1) Existing PRMs typically fail to generalize to more challenging math problems beyond GSM8K and MATH. They underperform both critic models (i.e., prompted general language models) and our own trained PRM that is straightforwardly fine-tuned on the PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has demonstrated the critique capability competitive with the proprietary model GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We hope ProcessBench can foster future research in reasoning process assessment, paving the way toward scalable oversight of language models.",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "https://arxiv.org/pdf/2412.06559.pdf",
         "https://www.semanticscholar.org/paper/dccd3899dd16beec8adcc97b65f6e24e7927d19b",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Mathematics, Computer Science",
         "104",
         "171b07e013043a4f09b897d234418135",
         "10.48550/arXiv.2412.06559",
         "2412.06559",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "13",
         "41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "A new science of emotion: implications for functional neurological disorder.",
         "Johannes Jungilligens, Sara Paredes-Echeverri, S. Popkirov, L. F. Barrett, D. Perez",
         "['Johannes Jungilligens', ' Sara Paredes-Echeverri', ' S. Popkirov', ' L. F. Barrett', ' D. Perez']",
         "2022",
         "Functional neurological disorder (FND) reflects impairments in brain networks leading to distressing motor, sensory, and/or cognitive symptoms that demonstrate positive clinical signs on examination incongruent with other conditions. A central issue in historical and contemporary formulations of FND has been the mechanistic and etiological role of emotions. However, the debate has mostly omitted fundamental questions about the nature of emotions in the first place. In this perspective article, we first outline a set of relevant working principles of the brain (e.g., allostasis, predictive processing, interoception, and affect), followed by a focused review of the theory of constructed emotion to introduce a new understanding of what emotions are. Building on this theoretical framework, we formulate how altered emotion category construction can be an integral component of the pathophysiology of FND and related functional somatic symptoms. In doing so, we address several themes for the FND field including: 1) how energy regulation and the process of emotion category construction relate to symptom generation, including revisiting alexithymia, \"panic attack without panic\", dissociation, insecure attachment, and the influential role of life experiences; 2) re-interpret select neurobiological research findings in FND cohorts through the lens of the theory of constructed emotion to illustrate its potential mechanistic relevance; and 3) discuss therapeutic implications. While we continue to support that FND is mechanistically and etiologically heterogenous, consideration of how the theory of constructed emotion relates to the generation and maintenance of functional neurological and functional somatic symptoms offers an integrated viewpoint that cuts across neurology, psychiatry, psychology, and cognitive-affective neuroscience.",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "https://academic.oup.com/brain/article-pdf/145/8/2648/49120115/awac204.pdf",
         "https://www.semanticscholar.org/paper/41d9b3eb97695ef2b4218573bddb66e0f27877f4",
         "Brain : a journal of neurology",
         "Medicine, Psychology",
         "101",
         "a22d0fe84e5c1374d4c95b8a6396a8d9",
         "10.1093/brain/awac204",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "14",
         "1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "Targeting High Ability Entrepreneurs Using Community Information: Mechanism Design in the Field",
         "Reshmaan N. Hussam, Natalia Rigol, Benjamin N. Roth",
         "['Reshmaan N. Hussam', ' Natalia Rigol', ' Benjamin N. Roth']",
         "2022",
         "Identifying high-growth microentrepreneurs in low-income countries remains a challenge due to a scarcity of verifiable information. With a cash grant experiment in India we demonstrate that community knowledge can help target high-growth microentrepreneurs; while the average marginal return to capital in our sample is 9.4 percent per month, microentrepreneurs reported in the top third of the community are estimated to have marginal returns to capital between 24 percent and 30 percent per month. Further we find evidence that community members distort their predictions when they can influence the distribution of resources. Finally, we demonstrate that simple mechanisms can realign incentives for truthful reporting. (JEL D82, G21, I38, L25, L26, O12, O16)",
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         null,
         "https://www.semanticscholar.org/paper/1f16cf174139b0e2ba3be49b29ef45790f2b0624",
         "The American Economic Review",
         "Business, Economics, Business",
         "97",
         "5643d31ff930134acee2c1071dac09b5",
         "10.1257/aer.20200751",
         null,
         "[{'source': 'external', 'category': 'Business'}, {'source': 's2-fos-model', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Business'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "15",
         "1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "AI-Generated Incentive Mechanism and Full-Duplex Semantic Communications for Information Sharing",
         "Hongyang Du, Jiacheng Wang, Dusist Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim",
         "['Hongyang Du', ' Jiacheng Wang', ' Dusist Niyato', ' Jiawen Kang', ' Zehui Xiong', ' Dong In Kim']",
         "2023",
         "The next generation of Internet services, such as Metaverse, rely on mixed reality (MR) technology to provide immersive user experiences. However, limited computation power of MR headset-mounted devices (HMDs) hinders the deployment of such services. Therefore, we propose an efficient information-sharing scheme based on full-duplex device-to-device (D2D) semantic communications to address this issue. Our approach enables users to avoid heavy and repetitive computational tasks, such as artificial intelligence-generated content (AIGC) in the view images of all MR users. Specifically, a user can transmit the generated content and semantic information extracted from their view image to nearby users, who can then use this information to obtain the spatial matching of computation results under their view images. We analyze the performance of full-duplex D2D communications, including the achievable rate and bit error probability, by using generalized small-scale fading models. To facilitate semantic information sharing among users, we design a contract theoretic AI-generated incentive mechanism. The proposed diffusion model generates the optimal contract design, outperforming two deep reinforcement learning algorithms, i.e., proximal policy optimization and soft actor-critic algorithms. Our numerical analysis experiment proves the effectiveness of our proposed methods. The code for this paper is available at https://github.com/HongyangDu/SemSharing.",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "https://www.techrxiv.org/articles/preprint/AI-Generated_Incentive_Mechanism_and_Full-Duplex_Semantic_Communications_for_Information_Sharing/22209178/1/files/39468979.pdf",
         "https://www.semanticscholar.org/paper/1b05d266ca3d0becfe52c11d5b3fba58c9df7c48",
         "IEEE Journal on Selected Areas in Communications",
         "Engineering, Computer Science, Computer Science",
         "96",
         "4265596316b0f66567d76928f99a27fd",
         "10.1109/JSAC.2023.3287547",
         "2303.01896",
         "[{'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "16",
         "8efaf945b1b649bf905e0b9624d23760335aa614",
         "Uncertainty in Mechanism Design",
         "Giuseppe Lopomo, Luca Rigotti, Chris Shannon",
         "['Giuseppe Lopomo', ' Luca Rigotti', ' Chris Shannon']",
         "2021",
         "We consider mechanism design problems with Knightian uncertainty formalized using incomplete preferences, as in Bewley (1986). Without completeness, decision making depends on a set of beliefs, and an action is preferred to another if and only if it has larger expected utility for all beliefs in this set. We consider two natural notions of incentive compatibility in this setting: maximal incentive compatibility requires that no strategy has larger expected utility than reporting truthfully for all beliefs, while optimal incentive compatibility requires that reporting truthfully has larger expected utility than all other strategies for all beliefs. In a model with a continuum of types, we show that optimal incentive compatibility is equivalent to ex-post incentive compatibility under fairly general conditions on beliefs. In a model with a discrete type space, we characterize full extraction of rents generated from private information. We show that full extraction is generically possible with maximal incentive compatible mechanisms, but requires sufficient disagreement across types, which neither holds nor fails generically, with optimal incentive compatible mechanisms.",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         "https://arxiv.org/pdf/2108.12633",
         "https://www.semanticscholar.org/paper/8efaf945b1b649bf905e0b9624d23760335aa614",
         null,
         "Economics, Economics",
         "90",
         "36c493c55efcd610b95cacde98fab544",
         "10.2139/ssrn.3774581",
         "2108.12633",
         "[{'source': 'external', 'category': 'Economics'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:47:49.908057+00:00",
         "2025-09-30 00:47:49.908057+00:00"
        ],
        [
         "17",
         "6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
         "Atticus Geiger, D. Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah D. Goodman, Christopher Potts, Thomas F. Icard",
         "['Atticus Geiger', ' D. Ibeling', ' Amir Zur', ' Maheep Chaudhary', ' Sonakshi Chauhan', ' Jing Huang', ' Aryaman Arora', ' Zhengxuan Wu', ' Noah D. Goodman', ' Christopher Potts', ' Thomas F. Icard']",
         "2023",
         "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         "https://arxiv.org/pdf/2301.04709.pdf",
         "https://www.semanticscholar.org/paper/6247d7bb9093b4f6c222c6c224b3df4335d4b8bd",
         null,
         "Computer Science, Computer Science, Philosophy",
         "80",
         "b3611594ff729546b6130e75d7322abd",
         null,
         "2301.04709",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:15.857258+00:00",
         "2025-09-29 20:01:45.343601+00:00"
        ],
        [
         "18",
         "0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Rationally Design a Sulfur Cathode with Solid‐Phase Conversion Mechanism for High Cycle‐Stable Li–S Batteries",
         "Bin He, Zhixiang Rao, Zexiao Cheng, Dongdong Liu, Danqi He, Jie Chen, Ziyun Miao, Lixia Yuan, Zhen Li, Yunhui Huang",
         "['Bin He', ' Zhixiang Rao', ' Zexiao Cheng', ' Dongdong Liu', ' Danqi He', ' Jie Chen', ' Ziyun Miao', ' Lixia Yuan', ' Zhen Li', ' Yunhui Huang']",
         "2021",
         "Solid–solid reactions are very effective for solving the main challenges of lithium–sulfur (Li–S) batteries, such as the shuttle effect of polysulfides and the high dependence of electrolyte consumption. However, the low sulfur content and sluggish redox kinetics of such cathodes dramatically limit the practical energy density of Li–S batteries. Here a rationally designed hierarchical cathode to simultaneously solve above‐mentioned challenges is reported. With nanoscale sulfur as the core, selenium‐doped sulfurized polyacrylonitrile (PAN/S7Se) as the shell and micron‐scale secondary particle morphology, the proposed cathode realizes excellent solid–solid reaction kinetics in a commercial carbonate electrolyte under high active species loading and a relatively low electrolyte/sulfur ratio. Such an approach provides a promising solution toward practical lithium sulfur batteries.",
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         null,
         "https://www.semanticscholar.org/paper/0a73d193635e86a595cdc6e8e4e43c79ac3d33b4",
         "Advanced Energy Materials",
         "Materials Science, Materials Science, Chemistry, Engineering",
         "78",
         "55c45ab4d8c970aeb6f70267874c70d1",
         "10.1002/aenm.202003690",
         null,
         "[{'source': 'external', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Materials Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "19",
         "1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nonnegative spatial factorization applied to spatial genomics",
         "F. W. Townes, B. Engelhardt",
         "['F. W. Townes', ' B. Engelhardt']",
         "2022",
         "This paper presents nonnegative spatial factorization, a general framework for spatially aware and interpretable dimension reduction for high-dimensional spatial data, and its application to spatial transcriptomics analysis. Nonnegative matrix factorization (NMF) is widely used to analyze high-dimensional count data because, in contrast to real-valued alternatives such as factor analysis, it produces an interpretable parts-based representation. However, in applications such as spatial transcriptomics, NMF fails to incorporate known structure between observations. Here, we present nonnegative spatial factorization (NSF), a spatially-aware probabilistic dimension reduction model based on transformed Gaussian processes that naturally encourages sparsity and scales to tens of thousands of observations. NSF recovers ground truth factors more accurately than real-valued alternatives such as MEFISTO in simulations, and has lower out-of-sample prediction error than probabilistic NMF on three spatial transcriptomics datasets from mouse brain and liver. Since not all patterns of gene expression have spatial correlations, we also propose a hybrid extension of NSF that combines spatial and nonspatial components, enabling quantification of spatial importance for both observations and features. A TensorFlow implementation of NSF is available from https://github.com/willtownes/nsf-paper .",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "https://www.nature.com/articles/s41592-022-01687-w.pdf",
         "https://www.semanticscholar.org/paper/1dde3f7dfd675fb4679b85795577eb631ac4b4c7",
         "Nature Methods",
         "Medicine, Computer Science, Biology",
         "72",
         "86d4a32c9b25afc8510904668935d1b6",
         "10.1038/s41592-022-01687-w",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "20",
         "7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration",
         "T. Bodrito, Alexandre Zouaoui, J. Chanussot, J. Mairal",
         "['T. Bodrito', ' Alexandre Zouaoui', ' J. Chanussot', ' J. Mairal']",
         "2021",
         "Hyperspectral imaging offers new perspectives for diverse applications, ranging from the monitoring of the environment using airborne or satellite remote sensing, precision farming, food safety, planetary exploration, or astrophysics. Unfortunately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth\"clean\"hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difficult, in contrast to traditional RGB imaging problems where deep models tend to shine. In this paper, we advocate instead for a hybrid approach based on sparse coding principles that retains the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data. We show on various denoising benchmarks that our method is computationally efficient and significantly outperforms the state of the art.",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "https://arxiv.org/pdf/2111.09708.pdf",
         "https://www.semanticscholar.org/paper/7b86bf1452b21f52d8c714b52c742fcbf6e4645c",
         "Neural Information Processing Systems",
         "Computer Science, Engineering, Environmental Science, Computer Science, Engineering",
         "70",
         "043f0c78b6d43bf864f00572f1fa44be",
         null,
         "2111.09708",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "21",
         "70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Parcels and particles: Markov blankets in the brain",
         "Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr, Ines Hip'olito, L. Magrou, Adeel Razi",
         "['Karl J. Friston', ' Erik D. Fagerholm', ' Tahereh S. Zarghami', ' Thomas Parr', \" Ines Hip'olito\", ' L. Magrou', ' Adeel Razi']",
         "2020",
         "At the inception of human brain mapping, two principles of functional anatomy underwrote most conceptions—and analyses—of distributed brain responses: namely, functional segregation and integration. There are currently two main approaches to characterizing functional integration. The first is a mechanistic modeling of connectomics in terms of directed effective connectivity that mediates neuronal message passing and dynamics on neuronal circuits. The second phenomenological approach usually characterizes undirected functional connectivity (i.e., measurable correlations), in terms of intrinsic brain networks, self-organized criticality, dynamical instability, and so on. This paper describes a treatment of effective connectivity that speaks to the emergence of intrinsic brain networks and critical dynamics. It is predicated on the notion of Markov blankets that play a fundamental role in the self-organization of far from equilibrium systems. Using the apparatus of the renormalization group, we show that much of the phenomenology found in network neuroscience is an emergent property of a particular partition of neuronal states, over progressively coarser scales. As such, it offers a way of linking dynamics on directed graphs to the phenomenology of intrinsic brain networks.",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "https://direct.mit.edu/netn/article-pdf/5/1/211/1889785/netn_a_00175.pdf",
         "https://www.semanticscholar.org/paper/70cd23f3053190ac70cad7107eb06d30ea0aadea",
         "Network Neuroscience",
         "Biology, Medicine, Computer Science, Physics",
         "70",
         "a28f67baf975f5d1bee41d5db29f602d",
         "10.1162/netn_a_00175",
         "2007.09704",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Physics'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "22",
         "980255db598dc210d6a784db247d159d3ea1cf3f",
         "Interpretable Multi-Modal Image Registration Network Based on Disentangled Convolutional Sparse Coding",
         "Xin Deng, Enpeng Liu, Shengxi Li, Yiping Duan, Mai Xu",
         "['Xin Deng', ' Enpeng Liu', ' Shengxi Li', ' Yiping Duan', ' Mai Xu']",
         "2023",
         "Multi-modal image registration aims to spatially align two images from different modalities to make their feature points match with each other. Captured by different sensors, the images from different modalities often contain many distinct features, which makes it challenging to find their accurate correspondences. With the success of deep learning, many deep networks have been proposed to align multi-modal images, however, they are mostly lack of interpretability. In this paper, we first model the multi-modal image registration problem as a disentangled convolutional sparse coding (DCSC) model. In this model, the multi-modal features that are responsible for alignment (RA features) are well separated from the features that are not responsible for alignment (nRA features). By only allowing the RA features to participate in the deformation field prediction, we can eliminate the interference of the nRA features to improve the registration accuracy and efficiency. The optimization process of the DCSC model to separate the RA and nRA features is then turned into a deep network, namely Interpretable Multi-modal Image Registration Network (InMIR-Net). To ensure the accurate separation of RA and nRA features, we further design an accompanying guidance network (AG-Net) to supervise the extraction of RA features in InMIR-Net. The advantage of InMIR-Net is that it provides a universal framework to tackle both rigid and non-rigid multi-modal image registration tasks. Extensive experimental results verify the effectiveness of our method on both rigid and non-rigid registrations on various multi-modal image datasets, including RGB/depth images, RGB/near-infrared (NIR) images, RGB/multi-spectral images, T1/T2 weighted magnetic resonance (MR) images and computed tomography (CT)/MR images. The codes are available at https://github.com/lep990816/Interpretable-Multi-modal-Image-Registration.",
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         null,
         "https://www.semanticscholar.org/paper/980255db598dc210d6a784db247d159d3ea1cf3f",
         "IEEE Transactions on Image Processing",
         "Medicine, Computer Science, Computer Science, Engineering",
         "66",
         "540673f1f88c28586b4306e40b8d041f",
         "10.1109/TIP.2023.3240024",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "23",
         "41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Evolution of central neural circuits: state of the art and perspectives",
         "Ruairí J. V. Roberts, S. Pop, L. Prieto-Godino",
         "['Ruairí J. V. Roberts', ' S. Pop', ' L. Prieto-Godino']",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         null,
         "https://www.semanticscholar.org/paper/41d470a9d84ee9aeb07a40c809e686f11224593b",
         "Nature Reviews Neuroscience",
         "Medicine, Biology",
         "62",
         "a1837ac9580622b09b74da0595b69e74",
         "10.1038/s41583-022-00644-y",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "24",
         "79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Reducing the Cognitive Footprint of Brain Tumor Surgery",
         "N. Dadario, Bledi C. Brahimaj, J. Yeung, M. Sughrue",
         "['N. Dadario', ' Bledi C. Brahimaj', ' J. Yeung', ' M. Sughrue']",
         "2021",
         "The surgical management of brain tumors is based on the principle that the extent of resection improves patient outcomes. Traditionally, neurosurgeons have considered that lesions in “non-eloquent” cerebrum can be more aggressively surgically managed compared to lesions in “eloquent” regions with more known functional relevance. Furthermore, advancements in multimodal imaging technologies have improved our ability to extend the rate of resection while minimizing the risk of inducing new neurologic deficits, together referred to as the “onco-functional balance.” However, despite the common utilization of invasive techniques such as cortical mapping to identify eloquent tissue responsible for language and motor functions, glioma patients continue to present post-operatively with poor cognitive morbidity in higher-order functions. Such observations are likely related to the difficulty in interpreting the highly-dimensional information these technologies present to us regarding cognition in addition to our classically poor understanding of the functional and structural neuroanatomy underlying complex higher-order cognitive functions. Furthermore, reduction of the brain into isolated cortical regions without consideration of the complex, interacting brain networks which these regions function within to subserve higher-order cognition inherently prevents our successful navigation of true eloquent and non-eloquent cerebrum. Fortunately, recent large-scale movements in the neuroscience community, such as the Human Connectome Project (HCP), have provided updated neural data detailing the many intricate macroscopic connections between cortical regions which integrate and process the information underlying complex human behavior within a brain “connectome.” Connectomic data can provide us better maps on how to understand convoluted cortical and subcortical relationships between tumor and human cerebrum such that neurosurgeons can begin to make more informed decisions during surgery to maximize the onco-functional balance. However, connectome-based neurosurgery and related applications for neurorehabilitation are relatively nascent and require further work moving forward to optimize our ability to add highly valuable connectomic data to our surgical armamentarium. In this manuscript, we review four concepts with detailed examples which will help us better understand post-operative cognitive outcomes and provide a guide for how to utilize connectomics to reduce cognitive morbidity following cerebral surgery.",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "https://www.frontiersin.org/articles/10.3389/fneur.2021.711646/pdf",
         "https://www.semanticscholar.org/paper/79aa20aa8cf9546b87e694078581e02d6637f86a",
         "Frontiers in Neurology",
         "Medicine, Medicine, Psychology",
         "61",
         "e26c187369f3f43944783d2070633188",
         "10.3389/fneur.2021.711646",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "25",
         "9854f38388b01991f461a25fefd1f67fecb9731f",
         "The Architecture of Human Memory: Insights from Human Single-Neuron Recordings",
         "Ueli Rutishauser, L. Reddy, F. Mormann, J. Sarnthein",
         "['Ueli Rutishauser', ' L. Reddy', ' F. Mormann', ' J. Sarnthein']",
         "2020",
         "Deciphering the mechanisms of human memory is a central goal of neuroscience, both from the point of view of the fundamental biology of memory and for its translational relevance. Here, we review some contributions that recordings from neurons in humans implanted with electrodes for clinical purposes have made toward this goal. Recordings from the medial temporal lobe, including the hippocampus, reveal the existence of two classes of cells: those encoding highly selective and invariant representations of abstract concepts, and memory-selective cells whose activity is related to familiarity and episodic retrieval. Insights derived from observing these cells in behaving humans include that semantic representations are activated before episodic representations, that memory content and memory strength are segregated, and that the activity of both types of cells is related to subjective awareness as expected from a substrate for declarative memory. Visually selective cells can remain persistently active for several seconds, thereby revealing a cellular substrate for working memory in humans. An overarching insight is that the neural code of human memory is interpretable at the single-neuron level. Jointly, intracranial recording studies are starting to reveal aspects of the building blocks of human memory at the single-cell level. This work establishes a bridge to cellular-level work in animals on the one hand, and the extensive literature on noninvasive imaging in humans on the other hand. More broadly, this work is a step toward a detailed mechanistic understanding of human memory that is needed to develop therapies for human memory disorders.",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "https://www.jneurosci.org/content/jneuro/41/5/883.full.pdf",
         "https://www.semanticscholar.org/paper/9854f38388b01991f461a25fefd1f67fecb9731f",
         "Journal of Neuroscience",
         "Medicine, Biology",
         "57",
         "ffce458267bc401455e35aa57197a0e9",
         "10.1523/JNEUROSCI.1648-20.2020",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "26",
         "85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "Mechanisms and mathematical modelling of ROS production by the mitochondrial electron transport chain.",
         "Sandeep Chenna, W. Koopman, J. Prehn, N. Connolly",
         "['Sandeep Chenna', ' W. Koopman', ' J. Prehn', ' N. Connolly']",
         "2022",
         "Reactive oxygen species (ROS) are recognised both as damaging molecules and intracellular signalling entities. In addition to its role in ATP generation, the mitochondrial electron transport chain (ETC) constitutes a relevant source of mitochondrial ROS, in particular during pathological conditions. Mitochondrial ROS homeostasis depends on species- and site-dependent ROS production, their bioreactivity, diffusion, and scavenging. However, our quantitative understanding of mitochondrial ROS homeostasis has thus far been hampered by technical limitations, including lack of truly site- and/or ROS-specific reporter molecules. In this context, the use of computational models is of great value to complement and interpret empirical data, as well as to predict variables that are difficult to assess experimentally. During the last decades, various mechanistic models of ETC-mediated ROS production have been developed. Although these often-complex models have generated novel insights, their parameterisation, analysis, and integration with other computational models is not straightforward. In contrast, phenomenological (sometimes termed \"minimal\") models use a relatively small set of equations to describe empirical relationship(s) between ROS-related and other parameters, and generally aim to explore system behaviour and generate hypotheses for experimental validation. In this review, we first discuss ETC-linked ROS homeostasis and introduce various detailed mechanistic models. Next, we present how bioenergetic parameters (e.g. NADH/NAD+ ratio, mitochondrial membrane potential) relate to site-specific ROS production within the ETC and how these relationships can be used to design minimal models of ROS homeostasis. Finally, we illustrate how minimal models have been applied to explore pathophysiological aspects of ROS.",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "https://figshare.com/articles/journal_contribution/Mechanisms_and_mathematical_modeling_of_ROS_production_by_the_mitochondrial_electron_transport_chain/20308254/1/files/36272712.pdf",
         "https://www.semanticscholar.org/paper/85245be0c3b0ad078a440ab40da82f1f5edbdca5",
         "American Journal of Physiology - Cell Physiology",
         "Medicine, Mathematics, Medicine",
         "56",
         "1a1ddb8e840f90dc765583768b6ce610",
         "10.1152/ajpcell.00455.2021",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Medicine'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "27",
         "8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "Open Problems in Mechanistic Interpretability",
         "Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, Stella Biderman, Adrià Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, Eric Todd, Atticus Geiger, Mor Geva, Jesse Hoogland, Daniel Murfet, Thomas McGrath",
         "['Lee Sharkey', ' Bilal Chughtai', ' Joshua Batson', ' Jack Lindsey', ' Jeff Wu', ' Lucius Bushnaq', ' Nicholas Goldowsky-Dill', ' Stefan Heimersheim', ' Alejandro Ortega', ' Joseph Bloom', ' Stella Biderman', ' Adrià Garriga-Alonso', ' Arthur Conmy', ' Neel Nanda', ' Jessica Rumbelow', ' Martin Wattenberg', ' Nandi Schoots', ' Joseph Miller', ' Eric J. Michaud', ' Stephen Casper', ' Max Tegmark', ' William Saunders', ' David Bau', ' Eric Todd', ' Atticus Geiger', ' Mor Geva', ' Jesse Hoogland', ' Daniel Murfet', ' Thomas McGrath']",
         "2025",
         "Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "https://arxiv.org/pdf/2501.16496.pdf",
         "https://www.semanticscholar.org/paper/8a94d7fb8b580621979396042aef89dbd6ec37fb",
         "arXiv.org",
         "Computer Science, Computer Science, Philosophy",
         "52",
         "91df2ef4eadf077383bb23722f77664f",
         "10.48550/arXiv.2501.16496",
         "2501.16496",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:20.370015+00:00",
         "2025-09-29 20:01:51.158008+00:00"
        ],
        [
         "28",
         "1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "High-throughput genetic clustering of type 2 diabetes loci reveals heterogeneous mechanistic pathways of metabolic disease",
         "Hyunkyung Kim, K. Westerman, Kirk Smith, Joshua Chiou, J. Cole, T. Majarian, Marcin von Grotthuss, S. Kwak, Jaegil Kim, J. Mercader, J. Florez, K. Gaulton, A. Manning, M. Udler",
         "['Hyunkyung Kim', ' K. Westerman', ' Kirk Smith', ' Joshua Chiou', ' J. Cole', ' T. Majarian', ' Marcin von Grotthuss', ' S. Kwak', ' Jaegil Kim', ' J. Mercader', ' J. Florez', ' K. Gaulton', ' A. Manning', ' M. Udler']",
         "2022",
         null,
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "https://link.springer.com/content/pdf/10.1007/s00125-022-05848-6.pdf",
         "https://www.semanticscholar.org/paper/1063f9d8388b8f4d5c5766e9e4136c7c4a92cd86",
         "Diabetologia",
         "Medicine, Medicine, Biology",
         "50",
         "6177f0d87f15e961d672e7d0629df25d",
         "10.1007/s00125-022-05848-6",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "29",
         "9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Non-negative Matrix Factorization: A Survey",
         "Jiangzhang Gan, Tong Liu, Li Li, Jilian Zhang",
         "['Jiangzhang Gan', ' Tong Liu', ' Li Li', ' Jilian Zhang']",
         "2021",
         "\n Non-negative matrix factorization (NMF) is a powerful tool for data science researchers, and it has been successfully applied to data mining and machine learning community, due to its advantages such as simple form, good interpretability and less storage space. In this paper, we give a detailed survey on existing NMF methods, including a comprehensive analysis of their design principles, characteristics and drawbacks. In addition, we also discuss various variants of NMF methods and analyse properties and applications of these variants. Finally, we evaluate the performance of nine NMF methods through numerical experiments, and the results show that NMF methods perform well in clustering tasks.",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "https://mro.massey.ac.nz/bitstreams/7dbd6b5e-4d71-490a-b1b6-654e40181693/download",
         "https://www.semanticscholar.org/paper/9e04e50f67ea086d6dac4b580e483183a7ddd536",
         "Computer/law journal",
         "Computer Science, Mathematics, Computer Science, Mathematics",
         "50",
         "59e53699c3921eb318bb078214c055c5",
         "10.1093/COMJNL/BXAB103",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "30",
         "2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
         "Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, Ziyu Yao",
         "['Daking Rai', ' Yilun Zhou', ' Shi Feng', ' Abulhair Saparov', ' Ziyu Yao']",
         "2024",
         "Mechanistic interpretability (MI) is an emerging sub-field of interpretability that seeks to understand a neural network model by reverse-engineering its internal computations. Recently, MI has garnered significant attention for interpreting transformer-based language models (LMs), resulting in many novel insights yet introducing new challenges. However, there has not been work that comprehensively reviews these insights and challenges, particularly as a guide for newcomers to this field. To fill this gap, we provide a comprehensive survey from a task-centric perspective, organizing the taxonomy of MI research around specific research questions or tasks. We outline the fundamental objects of study in MI, along with the techniques, evaluation methods, and key findings for each task in the taxonomy. In particular, we present a task-centric taxonomy as a roadmap for beginners to navigate the field by helping them quickly identify impactful problems in which they are most interested and leverage MI for their benefit. Finally, we discuss the current gaps in the field and suggest potential future directions for MI research.",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "https://arxiv.org/pdf/2407.02646.pdf",
         "https://www.semanticscholar.org/paper/2ac231b9cff4f5f9054d86c9b540429d4dd687f4",
         "arXiv.org",
         "Computer Science, Computer Science",
         "50",
         "315f88620b6902745a1f3b994fd0e831",
         "10.48550/arXiv.2407.02646",
         "2407.02646",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.481838+00:00",
         "2025-09-29 20:01:43.961857+00:00"
        ],
        [
         "31",
         "7748391c938dc6f6a5bae6ac56f33faf37686714",
         "The rotational and divergent components of atmospheric circulation on tidally locked planets",
         "M. Hammond, N. Lewis",
         "['M. Hammond', ' N. Lewis']",
         "2021",
         "Significance Tidally locked exoplanets have a permanent day side and night side. Understanding the atmospheric circulation on these planets is crucial for interpreting telescope observations and assessing their habitability. We show that the main components of the circulation—a jet going around the planet, stationary atmospheric waves, and direct flow from the day side to the night side—can be separated using a simple mathematical decomposition. This decomposition will significantly aid future study of tidally locked atmospheres. As an illustration, we use it to quantify heat transport due to different components of the circulation. This analysis reveals that the direct day–night component can dominate heat transport from the day side to the night side, even when the jet is strong. Tidally locked exoplanets likely host global atmospheric circulations with a superrotating equatorial jet, planetary-scale stationary waves, and thermally driven overturning circulation. In this work, we show that each of these features can be separated from the total circulation by using a Helmholtz decomposition, which splits the circulation into rotational (divergence-free) and divergent (vorticity-free) components. This technique is applied to the simulated circulation of a terrestrial planet and a gaseous hot Jupiter. For both planets, the rotational component comprises the equatorial jet and stationary waves, and the divergent component contains the overturning circulation. Separating out each component allows us to evaluate their spatial structure and relative contribution to the total flow. In contrast with previous work, we show that divergent velocities are not negligible when compared with rotational velocities and that divergent, overturning circulation takes the form of a single, roughly isotropic cell that ascends on the day side and descends on the night side. These conclusions are drawn for both the terrestrial case and the hot Jupiter. To illustrate the utility of the Helmholtz decomposition for studying atmospheric processes, we compute the contribution of each of the circulation components to heat transport from day side to night side. Surprisingly, we find that the divergent circulation dominates day–night heat transport in the terrestrial case and accounts for around half of the heat transport for the hot Jupiter. The relative contributions of the rotational and divergent components to day–night heat transport are likely sensitive to multiple planetary parameters and atmospheric processes and merit further study.",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "https://www.pnas.org/doi/pdf/10.1073/pnas.2022705118",
         "https://www.semanticscholar.org/paper/7748391c938dc6f6a5bae6ac56f33faf37686714",
         "Proceedings of the National Academy of Sciences of the United States of America",
         "Medicine, Physics, Physics, Environmental Science",
         "48",
         "abff31af6dcd5fe122dec99d8ade4088",
         "10.1073/pnas.2022705118",
         "2102.1176",
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "32",
         "02ad427b0d20fb976741e332f69c2fd00c751164",
         "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning",
         "Dan Braun, Jordan K. Taylor, Nicholas Goldowsky-Dill, Lee Sharkey",
         "['Dan Braun', ' Jordan K. Taylor', ' Nicholas Goldowsky-Dill', ' Lee Sharkey']",
         "2024",
         "Identifying the features learned by neural networks is a core challenge in mechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse, overcomplete dictionary that reconstructs a network's internal activations, have been used to identify these features. However, SAEs may learn more about the structure of the datatset than the computational structure of the network. There is therefore only indirect reason to believe that the directions found in these dictionaries are functionally important to the network. We propose end-to-end (e2e) sparse dictionary learning, a method for training SAEs that ensures the features learned are functionally important by minimizing the KL divergence between the output distributions of the original model and the model with SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a Pareto improvement: They explain more network performance, require fewer total features, and require fewer simultaneously active features per datapoint, all with no cost to interpretability. We explore geometric and qualitative differences between e2e SAE features and standard SAE features. E2e dictionary learning brings us closer to methods that can explain network behavior concisely and accurately. We release our library for training e2e SAEs and reproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "https://arxiv.org/pdf/2405.12241.pdf",
         "https://www.semanticscholar.org/paper/02ad427b0d20fb976741e332f69c2fd00c751164",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "46",
         "5dc8cc7891318ba16ac9c75ba5693d16",
         "10.48550/arXiv.2405.12241",
         "2405.12241",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "33",
         "f8029060e91209f048b3f9882f2cdd3607785ccd",
         "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability",
         "Ziming Liu, Eric Gan, Max Tegmark",
         "['Ziming Liu', ' Eric Gan', ' Max Tegmark']",
         "2023",
         "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that BIMT discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "http://arxiv.org/pdf/2305.08746",
         "https://www.semanticscholar.org/paper/f8029060e91209f048b3f9882f2cdd3607785ccd",
         "arXiv.org",
         "Computer Science, Physics, Mathematics, Biology, Computer Science",
         "46",
         "e067eaaff103d512e5af5296af1cdb46",
         "10.48550/arXiv.2305.08746",
         "2305.08746",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Physics'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.083803+00:00",
         "2025-09-29 20:01:45.576156+00:00"
        ],
        [
         "34",
         "e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "On scalable oversight with weak LLMs judging strong LLMs",
         "Zachary Kenton, Noah Y. Siegel, J'anos Kram'ar, Jonah Brown-Cohen, Samuel Albanie, Jannis Bulian, Rishabh Agarwal, David Lindner, Yunhao Tang, Noah D. Goodman, Rohin Shah",
         "['Zachary Kenton', ' Noah Y. Siegel', \" J'anos Kram'ar\", ' Jonah Brown-Cohen', ' Samuel Albanie', ' Jannis Bulian', ' Rishabh Agarwal', ' David Lindner', ' Yunhao Tang', ' Noah D. Goodman', ' Rohin Shah']",
         "2024",
         "Scalable oversight protocols aim to enable humans to accurately supervise superhuman AI. In this paper we study debate, where two AI's compete to convince a judge; consultancy, where a single AI tries to convince a judge that asks questions; and compare to a baseline of direct question-answering, where the judge just answers outright without the AI. We use large language models (LLMs) as both AI agents and as stand-ins for human judges, taking the judge models to be weaker than agent models. We benchmark on a diverse range of asymmetries between judges and agents, extending previous work on a single extractive QA task with information asymmetry, to also include mathematics, coding, logic and multimodal reasoning asymmetries. We find that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer. Comparing debate to direct question answering, the results depend on the type of task: in extractive QA tasks with information asymmetry debate outperforms direct question answering, but in other tasks without information asymmetry the results are mixed. Previous work assigned debaters/consultants an answer to argue for. When we allow them to instead choose which answer to argue for, we find judges are less frequently convinced by the wrong answer in debate than in consultancy. Further, we find that stronger debater models increase judge accuracy, though more modestly than in previous studies.",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "https://arxiv.org/pdf/2407.04622.pdf",
         "https://www.semanticscholar.org/paper/e4a5d94e72f7ef540b98991f5e01b8ae022cc8d7",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science",
         "44",
         "9c1fb35a2858675c73be477fb0ece0b3",
         "10.48550/arXiv.2407.04622",
         "2407.04622",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "35",
         "0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "PVC-SLP: Perceptual Vibrotactile-Signal Compression Based-on Sparse Linear Prediction",
         "Rania Hassen, Başak Güleçyüz, E. Steinbach",
         "['Rania Hassen', ' Başak Güleçyüz', ' E. Steinbach']",
         "2021",
         "Developing a signal compression technique that is able to achieve a low bit rate while maintaining high perceptual signal quality is a classical signal processing problem vigorously studied for audio, speech, image, and video type of signals. Yet, until recently, there has been limited effort directed toward the compression of vibrotactile signals, which represent a crucial element of rich touch (haptic) information. A vibrotactile signal; produced when stroking a textured surface with a tool-tip or bare-finger; like other signals contains a great deal of redundant and imperceptible information that can be exploited for efficient compression. This paper presents PVC-SLP, a vibrotactile perceptual coding approach. PVC-SLP employs a model of tactile sensitivity; called ASF (Acceleration Sensitivity Function); for perceptual coding. The ASF is inspired by the four channels model that mediate the perception of vibrotactile stimuli in the glabrous skin. The compression algorithm introduces sparsity constraints in a linear prediction scheme both on the residual and the predictor coefficients. The perceptual quantization of the residual is developed through the use of ASF. The quantization parameters of the residual and the predictor coefficients were jointly optimized; by means of both squared error and perceptual quality measures; to find the sweet spot of the rate-distortion curve. PVC-SLP coding performance is evaluated using two publicly available databases that collectively comprise 1281 vibrotactile signals covering 193 material classes. Furthermore, we compare PVC-SLP with a recent vibrotactile compression method and show that PVC-SLP perceptually outperforms existing method by a sizable margin. Most recently, PVC-SLP has been selected to become part of the haptic codec standard currently under preparation by IEEE P1918.1.1, aka Haptic Codecs for the Tactile Internet.",
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         null,
         "https://www.semanticscholar.org/paper/0b83a9674c5219e236e0632eb17a462ecd1996bb",
         "IEEE transactions on multimedia",
         "Computer Science, Computer Science",
         "44",
         "99db78f4eb2492099f409ede6822e163",
         "10.1109/tmm.2020.3042674",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:45:59.362493+00:00",
         "2025-09-30 00:45:59.362493+00:00"
        ],
        [
         "36",
         "ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Hybrid modelling of water resource recovery facilities: status and opportunities.",
         "M. Y. Schneider, Ward Quaghebeur, Sina Borzooei, A. Froemelt, Feiyi Li, R. Saagi, Matthew John Wade, Jun‐Jie Zhu, E. Torfs",
         "['M. Y. Schneider', ' Ward Quaghebeur', ' Sina Borzooei', ' A. Froemelt', ' Feiyi Li', ' R. Saagi', ' Matthew John Wade', ' Jun‐Jie Zhu', ' E. Torfs']",
         "2022",
         "Mathematical modelling is an indispensable tool to support water resource recovery facility (WRRF) operators and engineers with the ambition of creating a truly circular economy and assuring a sustainable future. Despite the successful application of mechanistic models in the water sector, they show some important limitations and do not fully profit from the increasing digitalisation of systems and processes. Recent advances in data-driven methods have provided options for harnessing the power of Industry 4.0, but they are often limited by the lack of interpretability and extrapolation capabilities. Hybrid modelling (HM) combines these two modelling paradigms and aims to leverage both the rapidly increasing volumes of data collected, as well as the continued pursuit of greater process understanding. Despite the potential of HM in a sector that is undergoing a significant digital and cultural transformation, the application of hybrid models remains vague. This article presents an overview of HM methodologies applied to WRRFs and aims to stimulate the wider adoption and development of HM. We also highlight challenges and research needs for HM design and architecture, good modelling practice, data assurance, and software compatibility. HM is a paradigm for WRRF modelling to transition towards a more resource-efficient, resilient, and sustainable future.",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "https://iwaponline.com/wst/article-pdf/85/9/2503/1064960/wst085092503.pdf",
         "https://www.semanticscholar.org/paper/ef496fda9e238b6c287ef8122ddf6c5f21de1928",
         "Water Science and Technology",
         "Medicine, Environmental Science, Engineering",
         "42",
         "46d3af83fe7d76740b0f84253214e6c5",
         "10.2166/wst.2022.115",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "37",
         "63a87feede94433b44b2c2b194e5902c3c5158f2",
         "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation",
         "Aaditya K. Singh, Ted Moskovitz, Felix Hill, S. C. Chan, Andrew M. Saxe",
         "['Aaditya K. Singh', ' Ted Moskovitz', ' Felix Hill', ' S. C. Chan', ' Andrew M. Saxe']",
         "2024",
         "In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning -- the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By clamping subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to\"go right\"for an induction head.",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "https://arxiv.org/pdf/2404.07129.pdf",
         "https://www.semanticscholar.org/paper/63a87feede94433b44b2c2b194e5902c3c5158f2",
         "International Conference on Machine Learning",
         "Computer Science",
         "41",
         "160d0353f52a1dccf893bdae96e30380",
         "10.48550/arXiv.2404.07129",
         "2404.07129",
         "[{'source': 'external', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.524693+00:00",
         "2025-09-29 20:02:01.691828+00:00"
        ],
        [
         "38",
         "680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
         "Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe",
         "['Peter Hase', ' Mohit Bansal', ' Peter Clark', ' Sarah Wiegreffe']",
         "2024",
         "How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current pretrained language models often generalize relatively well from easy to hard data, even performing as well as oracle models finetuned on hard data. We demonstrate this kind of easy-to-hard generalization using simple finetuning methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect easy data rather than hard data for finetuning, since hard data is generally noisier and costlier to collect. Our experiments use open models up to 70b in size and four publicly available question-answering datasets with questions ranging in difficulty from 3rd grade science questions to college level STEM questions and general-knowledge trivia. We conclude that easy-to-hard generalization in LMs is surprisingly strong for the tasks studied. Our code is available at: https://github.com/allenai/easy-to-hard-generalization",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "https://arxiv.org/pdf/2401.06751.pdf",
         "https://www.semanticscholar.org/paper/680b7ff9fe0b3667bb4b6ea9039e633f6a813f62",
         "Annual Meeting of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "39",
         "fd9c2650583db7080c93fe4ad97bc16a",
         "10.48550/arXiv.2401.06751",
         "2401.06751",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "39",
         "d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "Multi-Modal Convolutional Dictionary Learning",
         "Fangyuan Gao, Xin Deng, Mai Xu, Jingyi Xu, P. Dragotti",
         "['Fangyuan Gao', ' Xin Deng', ' Mai Xu', ' Jingyi Xu', ' P. Dragotti']",
         "2022",
         "Convolutional dictionary learning has become increasingly popular in signal and image processing for its ability to overcome the limitations of traditional patch-based dictionary learning. Although most studies on convolutional dictionary learning mainly focus on the unimodal case, real-world image processing tasks usually involve images from multiple modalities, e.g., visible and near-infrared (NIR) images. Thus, it is necessary to explore convolutional dictionary learning across different modalities. In this paper, we propose a novel multi-modal convolutional dictionary learning algorithm, which efficiently correlates different image modalities and fully considers neighborhood information at the image level. In this model, each modality is represented by two convolutional dictionaries, in which one dictionary is for common feature representation and the other is for unique feature representation. The model is constrained by the requirement that the convolutional sparse representations (CSRs) for the common features should be the same across different modalities, considering that these images are captured from the same scene. We propose a new training method based on the alternating direction method of multipliers (ADMM) to alternatively learn the common and unique dictionaries in the discrete Fourier transform (DFT) domain. We show that our model converges in less than 20 iterations between the convolutional dictionary updating and the CSRs calculation. The effectiveness of the proposed dictionary learning algorithm is demonstrated on various multimodal image processing tasks, achieves better performance than both dictionary learning methods and deep learning based methods with limited training data.",
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         null,
         "https://www.semanticscholar.org/paper/d460fc6b6999a27d1f1d779195e9bfa47abe2960",
         "IEEE Transactions on Image Processing",
         "Computer Science, Medicine, Computer Science, Environmental Science",
         "39",
         "e087496c780892e3207eb83d96645f87",
         "10.1109/TIP.2022.3141251",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Environmental Science'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "40",
         "2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "Diffusion Models for Audio Restoration: A review [Special Issue On Model-Based and Data-Driven Audio Signal Processing]",
         "Jean-Marie Lemercier, Julius Richter, Simon Welker, Eloi Moliner, V. Välimäki, Timo Gerkmann",
         "['Jean-Marie Lemercier', ' Julius Richter', ' Simon Welker', ' Eloi Moliner', ' V. Välimäki', ' Timo Gerkmann']",
         "2024",
         "With the development of audio playback devices and fast data transmission, the demand for high sound quality is rising for both entertainment and communications. In this quest for better sound quality, challenges emerge from distortions and interferences originating at the recording side or caused by an imperfect transmission pipeline. To address this problem, audio restoration methods aim to recover clean sound signals from the corrupted input data. We present here audio restoration algorithms based on diffusion models, with a focus on speech enhancement and music restoration tasks. Traditional approaches, often grounded in handcrafted rules and statistical heuristics, have shaped our understanding of audio signals. In the past decades, there has been a notable shift toward data-driven methods that exploit the modeling capabilities of deep neural networks (DNNs). Deep generative models, and among them diffusion models, have emerged as powerful techniques for learning complex data distributions. However, relying solely on DNN-based learning approaches carries the risk of reducing interpretability, particularly when employing end-to-end models. Nonetheless, data-driven approaches allow more flexibility in comparison to statistical model-based frameworks, whose performance depends on distributional and statistical assumptions that can be difficult to guarantee. Here, we aim to show that diffusion models can combine the best of both worlds and offer the opportunity to design audio restoration algorithms with a good degree of interpretability and a remarkable performance in terms of sound quality. In this article, we review the use of diffusion models for audio restoration. We explain the diffusion formalism and its application to the conditional generation of clean audio signals. We believe that diffusion models open an exciting field of research with the potential to spawn new audio restoration algorithms that are natural-sounding and remain robust in difficult acoustic situations.",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "https://arxiv.org/pdf/2402.09821.pdf",
         "https://www.semanticscholar.org/paper/2befe6e08c33c72a62d779759076d2c7ab9f410a",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Computer Science, Engineering",
         "37",
         "e188cd7a5af5364280ca4c2fd54355b5",
         "10.1109/MSP.2024.3445871",
         "2402.09821",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "41",
         "5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Interpretability of artificial neural network models in artificial intelligence versus neuroscience",
         "Kohitij Kar, Simon Kornblith, Evelina Fedorenko",
         "['Kohitij Kar', ' Simon Kornblith', ' Evelina Fedorenko']",
         "2022",
         "Computationally explicit hypotheses of brain function derived from machine learning (ML)-based models have recently revolutionized neuroscience. Despite the unprecedented ability of these artificial neural networks (ANNs) to capture responses in biological neural networks (brains), and our full access to all internal model components (unlike the brain), ANNs are often referred to as black-boxes with limited interpretability. Interpretability, however, is a multi-faceted construct that is used differently across fields. In particular, interpretability, or explainability, efforts in Artificial Intelligence (AI) focus on understanding how different model components contribute to its output (i.e., decision making). In contrast, the neuroscientific interpretability of ANNs requires explicit alignment between model components and neuroscientific constructs (e.g., different brain areas or phenomena, like recurrence or top-down feedback). Given the widespread calls to improve the interpretability of AI systems, we here highlight these different notions of interpretability and argue that the neuroscientific interpretability of ANNs can be pursued in parallel with, but independently from, the ongoing efforts in AI. Certain ML techniques (e.g., deep dream) can be leveraged in both fields, to ask what stimulus optimally activates the specific model features (feature visualization by optimization), or how different features contribute to the model's output (feature attribution). However, without appropriate brain alignment, certain features will remain uninterpretable to neuroscientists.",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "https://arxiv.org/pdf/2206.03951",
         "https://www.semanticscholar.org/paper/5d47b8a502d8bd776fc52a2b9785c03fa1c8f080",
         "Nat. Mac. Intell.",
         "Computer Science, Biology, Computer Science, Philosophy",
         "36",
         "7387e8bb067dd5c477ba0c3fe39df6a4",
         "10.1038/s42256-022-00592-3",
         "2206.03951",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Philosophy'}]",
         "2025-09-29 20:01:59.476166+00:00",
         "2025-09-29 20:01:59.476166+00:00"
        ],
        [
         "42",
         "c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Application of non-negative matrix factorization in oncology: one approach for establishing precision medicine",
         "Ryuji Hamamoto, Ken Takasawa, Hidenori Machino, Kazuma Kobayashi, Satoshi Takahashi, Amina Bolatkan, Norio Shinkai, Akira Sakai, R. Aoyama, Masayoshi Yamada, Ken Asada, M. Komatsu, Koji Okamoto, H. Kameoka, S. Kaneko",
         "['Ryuji Hamamoto', ' Ken Takasawa', ' Hidenori Machino', ' Kazuma Kobayashi', ' Satoshi Takahashi', ' Amina Bolatkan', ' Norio Shinkai', ' Akira Sakai', ' R. Aoyama', ' Masayoshi Yamada', ' Ken Asada', ' M. Komatsu', ' Koji Okamoto', ' H. Kameoka', ' S. Kaneko']",
         "2022",
         "Abstract The increase in the expectations of artificial intelligence (AI) technology has led to machine learning technology being actively used in the medical field. Non-negative matrix factorization (NMF) is a machine learning technique used for image analysis, speech recognition, and language processing; recently, it is being applied to medical research. Precision medicine, wherein important information is extracted from large-scale medical data to provide optimal medical care for every individual, is considered important in medical policies globally, and the application of machine learning techniques to this end is being handled in several ways. NMF is also introduced differently because of the characteristics of its algorithms. In this review, the importance of NMF in the field of medicine, with a focus on the field of oncology, is described by explaining the mathematical science of NMF and the characteristics of the algorithm, providing examples of how NMF can be used to establish precision medicine, and presenting the challenges of NMF. Finally, the direction regarding the effective use of NMF in the field of oncology is also discussed.",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "https://academic.oup.com/bib/article-pdf/23/4/bbac246/45017265/bbac246.pdf",
         "https://www.semanticscholar.org/paper/c62fdc1881dd26001b8f7eff582b4d615762754f",
         "Briefings Bioinform.",
         "Medicine, Computer Science, Medicine, Computer Science",
         "35",
         "cea76d54281f58364f2cdbd89a30795c",
         "10.1093/bib/bbac246",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ],
        [
         "43",
         "59b988fda9c1737465921a9bade731d511500718",
         "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
         "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
         "['Aaron Mueller', ' Jannik Brinkmann', ' Millicent Li', ' Samuel Marks', ' Koyena Pal', ' Nikhil Prakash', ' Can Rager', ' Aruna Sankaranarayanan', ' Arnab Sen Sharma', ' Jiuding Sun', ' Eric Todd', ' David Bau', ' Yonatan Belinkov']",
         "2024",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         null,
         "https://www.semanticscholar.org/paper/59b988fda9c1737465921a9bade731d511500718",
         "arXiv.org",
         "Computer Science, Psychology",
         "35",
         "ba9e6b607a4904c9b0fa98dd7fb06b26",
         "10.48550/arXiv.2408.01416",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Psychology'}]",
         "2025-09-30 00:45:40.147869+00:00",
         "2025-09-30 00:45:40.147869+00:00"
        ],
        [
         "44",
         "b437d4398b443234aa253156404e12326ba899a5",
         "Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis",
         "Mitchell Ostrow, Adam Eisen, L. Kozachkov, I. Fiete",
         "['Mitchell Ostrow', ' Adam Eisen', ' L. Kozachkov', ' I. Fiete']",
         "2023",
         "How can we tell whether two neural networks utilize the same internal processes for a particular computation? This question is pertinent for multiple subfields of neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of dynamics, and two networks performing the same computation with equivalent dynamics need not exhibit the same geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics, called Dynamical Similarity Analysis (DSA). Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare different systems passed through this embedding using a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. In four case studies, we demonstrate that our method disentangles conjugate and non-conjugate recurrent neural networks (RNNs), while geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method opens the door to comparative analyses of the essential temporal structure of computation in neural circuits.",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "https://arxiv.org/pdf/2306.10168",
         "https://www.semanticscholar.org/paper/b437d4398b443234aa253156404e12326ba899a5",
         "Neural Information Processing Systems",
         "Biology, Computer Science, Computer Science",
         "35",
         "fada21b27d9df8d40aef2026b27654ac",
         "10.48550/arXiv.2306.10168",
         "2306.10168",
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:41.941797+00:00",
         "2025-09-29 20:01:41.941797+00:00"
        ],
        [
         "45",
         "557dce8787129ca623fcb2cca2e76e9920347b69",
         "Optimal and Differentially Private Data Acquisition: Central and Local Mechanisms",
         "Alireza Fallah, A. Makhdoumi, Azarakhsh Malekian, A. Ozdaglar",
         "['Alireza Fallah', ' A. Makhdoumi', ' Azarakhsh Malekian', ' A. Ozdaglar']",
         "2022",
         "We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "https://arxiv.org/pdf/2201.03968.pdf",
         "https://www.semanticscholar.org/paper/557dce8787129ca623fcb2cca2e76e9920347b69",
         "ACM Conference on Economics and Computation",
         "Computer Science, Computer Science, Economics",
         "34",
         "6f74ae4cba716c1607ae234c9694a38e",
         "10.1145/3490486.3538329",
         "2201.03968",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Economics'}]",
         "2025-09-30 00:48:00.124992+00:00",
         "2025-09-30 00:48:00.124992+00:00"
        ],
        [
         "46",
         "d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP",
         "Vedant Palit, Rohan Pandey, Aryaman Arora, Paul Pu Liang",
         "['Vedant Palit', ' Rohan Pandey', ' Aryaman Arora', ' Paul Pu Liang']",
         "2023",
         "Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have identified neural circuits that copy spans of text, capture factual knowledge, and more, they remain unusable for multimodal models since adapting these tools to the vision-language domain requires considerable architectural changes. In this work, we adapt a unimodal causal tracing tool to BLIP to enable the study of the neural mechanisms underlying image-conditioned text generation. We demonstrate our approach on a visual question answering dataset, highlighting the causal relevance of later layer representations for all tokens. Furthermore, we release our BLIP causal tracing tool as open source to enable further experimentation in vision-language mechanistic interpretability by the community. Our code is available at this URL.",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "https://arxiv.org/pdf/2308.14179",
         "https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7",
         "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
         "Computer Science, Computer Science",
         "34",
         "9cf5a58ea2e4185711ce7b8677794afc",
         "10.1109/ICCVW60793.2023.00307",
         "2308.14179",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:16.758641+00:00",
         "2025-09-29 20:01:46.494319+00:00"
        ],
        [
         "47",
         "6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning",
         "Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang",
         "['Ruixin Hong', ' Hongming Zhang', ' Xinyu Pang', ' Dong Yu', ' Changshui Zhang']",
         "2023",
         "Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "https://arxiv.org/pdf/2311.07954.pdf",
         "https://www.semanticscholar.org/paper/6233b5863f9a0e8bacce47ce21bc3e81c09497bd",
         "North American Chapter of the Association for Computational Linguistics",
         "Computer Science, Computer Science",
         "32",
         "c392393c2dc5c78e3dc51c1d7ab07def",
         "10.48550/arXiv.2311.07954",
         "2311.07954",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "48",
         "f3658afcd181e4078e1e96ff86eac224fd92faab",
         "ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability",
         "ZhongXiang Sun, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu, Xiao Zhang, Weijie Yu, Han Li",
         "['ZhongXiang Sun', ' Xiaoxue Zang', ' Kai Zheng', ' Yang Song', ' Jun Xu', ' Xiao Zhang', ' Weijie Yu', ' Han Li']",
         "2024",
         "Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric (internal) knowledge. However, even with accurate and relevant retrieved content, RAG models can still produce hallucinations by generating outputs that conflict with the retrieved information. Detecting such hallucinations requires disentangling how Large Language Models (LLMs) utilize external and parametric knowledge. Current detection methods often focus on one of these mechanisms or without decoupling their intertwined effects, making accurate detection difficult. In this paper, we investigate the internal mechanisms behind hallucinations in RAG scenarios. We discover hallucinations occur when the Knowledge FFNs in LLMs overemphasize parametric knowledge in the residual stream, while Copying Heads fail to effectively retain or integrate external knowledge from retrieved content. Based on these findings, we propose ReDeEP, a novel method that detects hallucinations by decoupling LLM's utilization of external context and parametric knowledge. Our experiments show that ReDeEP significantly improves RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by modulating the contributions of Knowledge FFNs and Copying Heads.",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "https://arxiv.org/pdf/2410.11414.pdf",
         "https://www.semanticscholar.org/paper/f3658afcd181e4078e1e96ff86eac224fd92faab",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "32",
         "ac30ae75b45154f43567d24b201cee78",
         "10.48550/arXiv.2410.11414",
         "2410.11414",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:14.714672+00:00",
         "2025-09-29 20:01:43.739899+00:00"
        ],
        [
         "49",
         "7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Orthogonal Non-negative Tensor Factorization based Multi-view Clustering",
         "Jing Li, Quanxue Gao, Qianqian Wang, Ming Yang, Wei Xia",
         "['Jing Li', ' Quanxue Gao', ' Qianqian Wang', ' Ming Yang', ' Wei Xia']",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         null,
         "https://www.semanticscholar.org/paper/7adfa7f8d280ca21b0d12e76d2417d8d922c390f",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Mathematics",
         "31",
         "20a966da2d81a77230eb9bf78d244a46",
         null,
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:12.191642+00:00",
         "2025-09-30 00:46:12.191642+00:00"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 759
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>authors_list</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>[David Rein,  Betty Li Hou,  Asa Cooper Stickl...</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edd112383ad494f5f2eba72b6f4ffae122ce61f</td>\n",
       "      <td>Interpretability in the Wild: a Circuit for In...</td>\n",
       "      <td>Kevin Wang, Alexandre Variengien, Arthur Conmy...</td>\n",
       "      <td>[Kevin Wang,  Alexandre Variengien,  Arthur Co...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Research in mechanistic interpretability seeks...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>https://arxiv.org/pdf/2211.00593</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6edd1123...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>644</td>\n",
       "      <td>1ff47a5be9a68e64e23ad2359d220370</td>\n",
       "      <td>10.48550/arXiv.2211.00593</td>\n",
       "      <td>2211.00593</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:28.298552+00:00</td>\n",
       "      <td>2025-09-29 20:02:03.480569+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0893549771094fac547432cb4f84e9605c911a86</td>\n",
       "      <td>The imperative for regulatory oversight of lar...</td>\n",
       "      <td>B. Meskó, E. Topol</td>\n",
       "      <td>[B. Meskó,  E. Topol]</td>\n",
       "      <td>2023</td>\n",
       "      <td>The rapid advancements in artificial intellige...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>https://www.nature.com/articles/s41746-023-008...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08935497...</td>\n",
       "      <td>npj Digit. Medicine</td>\n",
       "      <td>Computer Science, Medicine, Medicine, Computer...</td>\n",
       "      <td>627</td>\n",
       "      <td>920cc7dbbd6a0bb608e11b65097d69ef</td>\n",
       "      <td>10.1038/s41746-023-00873-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f680d47a51a0e470fcb228bf0110c026535ead1b</td>\n",
       "      <td>Progress measures for grokking via mechanistic...</td>\n",
       "      <td>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...</td>\n",
       "      <td>[Neel Nanda,  Lawrence Chan,  Tom Lieberum,  J...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Neural networks often exhibit emergent behavio...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05217</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f680d47a...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>517</td>\n",
       "      <td>953089e9556a8e0b37293683f8ff8807</td>\n",
       "      <td>10.48550/arXiv.2301.05217</td>\n",
       "      <td>2301.05217</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:13.784216+00:00</td>\n",
       "      <td>2025-09-29 20:01:43.521903+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eefbd8b384a58f464827b19e30a6920ba976def9</td>\n",
       "      <td>Towards Automated Circuit Discovery for Mechan...</td>\n",
       "      <td>Arthur Conmy, Augustine N. Mavor-Parker, Aengu...</td>\n",
       "      <td>[Arthur Conmy,  Augustine N. Mavor-Parker,  Ae...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Through considerable effort and intuition, sev...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>https://arxiv.org/pdf/2304.14997</td>\n",
       "      <td>https://www.semanticscholar.org/paper/eefbd8b3...</td>\n",
       "      <td>Neural Information Processing Systems</td>\n",
       "      <td>Computer Science, Computer Science, Engineering</td>\n",
       "      <td>356</td>\n",
       "      <td>a97a69c6234d51eeafeb50c9077b71ba</td>\n",
       "      <td>10.48550/arXiv.2304.14997</td>\n",
       "      <td>2304.14997</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:14.252982+00:00</td>\n",
       "      <td>2025-09-29 20:01:44.864490+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2</td>\n",
       "      <td>Mechanistic Interpretability of GPT-like Model...</td>\n",
       "      <td>Anurag Mishra</td>\n",
       "      <td>[Anurag Mishra]</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability research seeks to...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.17073.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1ecc468...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>3771d70ffd60f9c3f692d0e8f989f74d</td>\n",
       "      <td>10.48550/arXiv.2505.17073</td>\n",
       "      <td>2505.17073</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.786419+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.195754+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>663292eaef24c22c0692f1b4a9120d24662d7fc7</td>\n",
       "      <td>Causal Intervention Framework for Variational ...</td>\n",
       "      <td>Dip Roy</td>\n",
       "      <td>[Dip Roy]</td>\n",
       "      <td>2025</td>\n",
       "      <td>Mechanistic interpretability of deep learning ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>https://arxiv.org/pdf/2505.03530.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/663292ea...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>2f8d578153eefbc0b11361f9e71a0194</td>\n",
       "      <td>10.48550/arXiv.2505.03530</td>\n",
       "      <td>2505.03530</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:25.332786+00:00</td>\n",
       "      <td>2025-09-29 20:01:57.450585+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>[Marcos Florencio,  Thomas Barton]</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>49072764553763f1686121fd03e3dadda259f273</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>[Jason Li]</td>\n",
       "      <td>2024</td>\n",
       "      <td>Recent research (arXiv:2310.11453, arXiv:2402....</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>https://arxiv.org/pdf/2405.17703.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>81612dabd9dc5de68fc08c32d1ed9a14</td>\n",
       "      <td>10.48550/arXiv.2405.17703</td>\n",
       "      <td>2405.17703</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.685040+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.957507+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>[Tristan Trim,  Triston Grayston]</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_id  \\\n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "1    6edd112383ad494f5f2eba72b6f4ffae122ce61f   \n",
       "2    0893549771094fac547432cb4f84e9605c911a86   \n",
       "3    f680d47a51a0e470fcb228bf0110c026535ead1b   \n",
       "4    eefbd8b384a58f464827b19e30a6920ba976def9   \n",
       "..                                        ...   \n",
       "754  f1ecc468bc42de25ccd71dc84a6b7a8dafab6ed2   \n",
       "755  663292eaef24c22c0692f1b4a9120d24662d7fc7   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "757  49072764553763f1686121fd03e3dadda259f273   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "1    Interpretability in the Wild: a Circuit for In...   \n",
       "2    The imperative for regulatory oversight of lar...   \n",
       "3    Progress measures for grokking via mechanistic...   \n",
       "4    Towards Automated Circuit Discovery for Mechan...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic Interpretability of GPT-like Model...   \n",
       "755  Causal Intervention Framework for Variational ...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "757  Mechanistic Interpretability of Binary and Ter...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                               authors  \\\n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...   \n",
       "1    Kevin Wang, Alexandre Variengien, Arthur Conmy...   \n",
       "2                                   B. Meskó, E. Topol   \n",
       "3    Neel Nanda, Lawrence Chan, Tom Lieberum, Jess ...   \n",
       "4    Arthur Conmy, Augustine N. Mavor-Parker, Aengu...   \n",
       "..                                                 ...   \n",
       "754                                      Anurag Mishra   \n",
       "755                                            Dip Roy   \n",
       "756                    Marcos Florencio, Thomas Barton   \n",
       "757                                           Jason Li   \n",
       "758                     Tristan Trim, Triston Grayston   \n",
       "\n",
       "                                          authors_list  year  \\\n",
       "0    [David Rein,  Betty Li Hou,  Asa Cooper Stickl...  2023   \n",
       "1    [Kevin Wang,  Alexandre Variengien,  Arthur Co...  2022   \n",
       "2                                [B. Meskó,  E. Topol]  2023   \n",
       "3    [Neel Nanda,  Lawrence Chan,  Tom Lieberum,  J...  2023   \n",
       "4    [Arthur Conmy,  Augustine N. Mavor-Parker,  Ae...  2023   \n",
       "..                                                 ...   ...   \n",
       "754                                    [Anurag Mishra]  2025   \n",
       "755                                          [Dip Roy]  2025   \n",
       "756                 [Marcos Florencio,  Thomas Barton]  2025   \n",
       "757                                         [Jason Li]  2024   \n",
       "758                  [Tristan Trim,  Triston Grayston]  2024   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    We present GPQA, a challenging dataset of 448 ...   \n",
       "1    Research in mechanistic interpretability seeks...   \n",
       "2    The rapid advancements in artificial intellige...   \n",
       "3    Neural networks often exhibit emergent behavio...   \n",
       "4    Through considerable effort and intuition, sev...   \n",
       "..                                                 ...   \n",
       "754  Mechanistic interpretability research seeks to...   \n",
       "755  Mechanistic interpretability of deep learning ...   \n",
       "756  Architectural obfuscation - e.g., permuting hi...   \n",
       "757  Recent research (arXiv:2310.11453, arXiv:2402....   \n",
       "758  This paper explores the mechanistic interpreta...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                               pdf_url  \\\n",
       "0                 https://arxiv.org/pdf/2311.12022.pdf   \n",
       "1                     https://arxiv.org/pdf/2211.00593   \n",
       "2    https://www.nature.com/articles/s41746-023-008...   \n",
       "3                      http://arxiv.org/pdf/2301.05217   \n",
       "4                     https://arxiv.org/pdf/2304.14997   \n",
       "..                                                 ...   \n",
       "754               https://arxiv.org/pdf/2505.17073.pdf   \n",
       "755               https://arxiv.org/pdf/2505.03530.pdf   \n",
       "756               https://arxiv.org/pdf/2506.18053.pdf   \n",
       "757               https://arxiv.org/pdf/2405.17703.pdf   \n",
       "758               https://arxiv.org/pdf/2411.00867.pdf   \n",
       "\n",
       "                                           scholar_url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "1    https://www.semanticscholar.org/paper/6edd1123...   \n",
       "2    https://www.semanticscholar.org/paper/08935497...   \n",
       "3    https://www.semanticscholar.org/paper/f680d47a...   \n",
       "4    https://www.semanticscholar.org/paper/eefbd8b3...   \n",
       "..                                                 ...   \n",
       "754  https://www.semanticscholar.org/paper/f1ecc468...   \n",
       "755  https://www.semanticscholar.org/paper/663292ea...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                                 venue  \\\n",
       "0                                            arXiv.org   \n",
       "1    International Conference on Learning Represent...   \n",
       "2                                  npj Digit. Medicine   \n",
       "3    International Conference on Learning Represent...   \n",
       "4                Neural Information Processing Systems   \n",
       "..                                                 ...   \n",
       "754                                          arXiv.org   \n",
       "755                                          arXiv.org   \n",
       "756                                          arXiv.org   \n",
       "757                                          arXiv.org   \n",
       "758                                          arXiv.org   \n",
       "\n",
       "                                              keywords  citations  \\\n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "1                   Computer Science, Computer Science        644   \n",
       "2    Computer Science, Medicine, Medicine, Computer...        627   \n",
       "3                   Computer Science, Computer Science        517   \n",
       "4      Computer Science, Computer Science, Engineering        356   \n",
       "..                                                 ...        ...   \n",
       "754                 Computer Science, Computer Science          0   \n",
       "755                 Computer Science, Computer Science          0   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "757                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "\n",
       "                           title_hash                         doi    arxiv_id  \\\n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                         NaN  2311.12022   \n",
       "1    1ff47a5be9a68e64e23ad2359d220370   10.48550/arXiv.2211.00593  2211.00593   \n",
       "2    920cc7dbbd6a0bb608e11b65097d69ef  10.1038/s41746-023-00873-0         NaN   \n",
       "3    953089e9556a8e0b37293683f8ff8807   10.48550/arXiv.2301.05217  2301.05217   \n",
       "4    a97a69c6234d51eeafeb50c9077b71ba   10.48550/arXiv.2304.14997  2304.14997   \n",
       "..                                ...                         ...         ...   \n",
       "754  3771d70ffd60f9c3f692d0e8f989f74d   10.48550/arXiv.2505.17073  2505.17073   \n",
       "755  2f8d578153eefbc0b11361f9e71a0194   10.48550/arXiv.2505.03530  2505.03530   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34   10.48550/arXiv.2506.18053  2506.18053   \n",
       "757  81612dabd9dc5de68fc08c32d1ed9a14   10.48550/arXiv.2405.17703  2405.17703   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82   10.48550/arXiv.2411.00867  2411.00867   \n",
       "\n",
       "                                             s2_fields  \\\n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "1    [{'source': 'external', 'category': 'Computer ...   \n",
       "2    [{'source': 'external', 'category': 'Computer ...   \n",
       "3    [{'source': 'external', 'category': 'Computer ...   \n",
       "4    [{'source': 'external', 'category': 'Computer ...   \n",
       "..                                                 ...   \n",
       "754  [{'source': 'external', 'category': 'Computer ...   \n",
       "755  [{'source': 'external', 'category': 'Computer ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "757  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                           created_at                        updated_at  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "1    2025-09-29 20:01:28.298552+00:00  2025-09-29 20:02:03.480569+00:00  \n",
       "2    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "3    2025-09-29 20:01:13.784216+00:00  2025-09-29 20:01:43.521903+00:00  \n",
       "4    2025-09-29 20:01:14.252982+00:00  2025-09-29 20:01:44.864490+00:00  \n",
       "..                                ...                               ...  \n",
       "754  2025-09-29 20:01:25.786419+00:00  2025-09-29 20:01:55.195754+00:00  \n",
       "755  2025-09-29 20:01:25.332786+00:00  2025-09-29 20:01:57.450585+00:00  \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00  \n",
       "757  2025-09-29 20:01:19.685040+00:00  2025-09-29 20:01:48.957507+00:00  \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00  \n",
       "\n",
       "[759 rows x 18 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df = semantic_df[['paper_id', 'title', 'authors', 'authors_list', 'year', 'abstract', 'url', 'pdf_url',\n",
    "       'scholar_url', 'venue', 'keywords', 'citations', 'title_hash', 'doi',\n",
    "       'arxiv_id', 's2_fields', 'created_at', 'updated_at']]\n",
    "\n",
    "semantic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2be482",
   "metadata": {},
   "source": [
    "Adding a new column for authors as invidivuals and adding a row for each paper author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a0cfb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_url",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "scholar_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "arxiv_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s2_fields",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "82a90cac-5da8-48ad-8ec6-55fe98e87bc9",
       "rows": [
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         "David Rein",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Betty Li Hou",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Asa Cooper Stickland",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Jackson Petty",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Richard Yuanzhe Pang",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Julien Dirani",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Julian Michael",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "0",
         "210b0a3d76e93079cc51b03c4115fde545eea966",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman",
         " Samuel R. Bowman",
         "2023",
         "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "https://arxiv.org/pdf/2311.12022.pdf",
         "https://www.semanticscholar.org/paper/210b0a3d76e93079cc51b03c4115fde545eea966",
         "arXiv.org",
         "Computer Science, Biology, Physics, Computer Science, Chemistry",
         "1065",
         "d2390e0e97b7199093a42b27a5cf32bc",
         null,
         "2311.12022",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}, {'source': 's2-fos-model', 'category': 'Physics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Chemistry'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         "Kevin Wang",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         " Alexandre Variengien",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         " Arthur Conmy",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         " Buck Shlegeris",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "1",
         "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, J. Steinhardt",
         " J. Steinhardt",
         "2022",
         "Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "https://arxiv.org/pdf/2211.00593",
         "https://www.semanticscholar.org/paper/6edd112383ad494f5f2eba72b6f4ffae122ce61f",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "644",
         "1ff47a5be9a68e64e23ad2359d220370",
         "10.48550/arXiv.2211.00593",
         "2211.00593",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:28.298552+00:00",
         "2025-09-29 20:02:03.480569+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Meskó, E. Topol",
         "B. Meskó",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "2",
         "0893549771094fac547432cb4f84e9605c911a86",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "B. Meskó, E. Topol",
         " E. Topol",
         "2023",
         "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "https://www.nature.com/articles/s41746-023-00873-0.pdf",
         "https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86",
         "npj Digit. Medicine",
         "Computer Science, Medicine, Medicine, Computer Science, Law",
         "627",
         "920cc7dbbd6a0bb608e11b65097d69ef",
         "10.1038/s41746-023-00873-0",
         null,
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Law'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         "Neel Nanda",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         " Lawrence Chan",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         " Tom Lieberum",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         " Jess Smith",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "3",
         "f680d47a51a0e470fcb228bf0110c026535ead1b",
         "Progress measures for grokking via mechanistic interpretability",
         "Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, J. Steinhardt",
         " J. Steinhardt",
         "2023",
         "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "http://arxiv.org/pdf/2301.05217",
         "https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b",
         "International Conference on Learning Representations",
         "Computer Science, Computer Science",
         "517",
         "953089e9556a8e0b37293683f8ff8807",
         "10.48550/arXiv.2301.05217",
         "2301.05217",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}]",
         "2025-09-29 20:01:13.784216+00:00",
         "2025-09-29 20:01:43.521903+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         "Arthur Conmy",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         " Augustine N. Mavor-Parker",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         " Aengus Lynch",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         " Stefan Heimersheim",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "4",
         "eefbd8b384a58f464827b19e30a6920ba976def9",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso",
         " Adrià Garriga-Alonso",
         "2023",
         "Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "https://arxiv.org/pdf/2304.14997",
         "https://www.semanticscholar.org/paper/eefbd8b384a58f464827b19e30a6920ba976def9",
         "Neural Information Processing Systems",
         "Computer Science, Computer Science, Engineering",
         "356",
         "a97a69c6234d51eeafeb50c9077b71ba",
         "10.48550/arXiv.2304.14997",
         "2304.14997",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.252982+00:00",
         "2025-09-29 20:01:44.864490+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         "X. Fang",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         " C. Lloyd",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "5",
         "3d23699f2123dc6dbad841c97761cda832432b02",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "X. Fang, C. Lloyd, B. Palsson",
         " B. Palsson",
         "2020",
         null,
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7981288",
         "https://www.semanticscholar.org/paper/3d23699f2123dc6dbad841c97761cda832432b02",
         "Nature Reviews Microbiology",
         "Biology, Medicine, Computer Science, Biology",
         "208",
         "514f21d4b7968a9eb4f2c5000b750a63",
         "10.1038/s41579-020-00440-4",
         null,
         "[{'source': 'external', 'category': 'Biology'}, {'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:46:26.107098+00:00",
         "2025-09-30 00:46:26.107098+00:00"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         "Leonard Bereska",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00"
        ],
        [
         "6",
         "8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Leonard Bereska, E. Gavves",
         " E. Gavves",
         "2024",
         "Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "https://arxiv.org/pdf/2404.14082.pdf",
         "https://www.semanticscholar.org/paper/8b750488d139f9beba0815ff8f46ebe15ebb3e58",
         "Trans. Mach. Learn. Res.",
         "Computer Science, Computer Science, Engineering",
         "201",
         "41b189124d10eb4237a0505320669e26",
         "10.48550/arXiv.2404.14082",
         "2404.14082",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Engineering'}]",
         "2025-09-29 20:01:14.024076+00:00",
         "2025-09-29 20:01:43.296227+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         "Xiaowen Dong",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         " D. Thanou",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         " L. Toni",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         " M. Bronstein",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "7",
         "9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Xiaowen Dong, D. Thanou, L. Toni, M. Bronstein, P. Frossard",
         " P. Frossard",
         "2020",
         "The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "https://arxiv.org/pdf/2007.16061",
         "https://www.semanticscholar.org/paper/9160756d319bbe476a0e8b24ab85346c985d3c3f",
         "IEEE Signal Processing Magazine",
         "Computer Science, Engineering, Mathematics, Computer Science, Mathematics",
         "181",
         "0acf21e0b3a2becdf95f121fd31650e7",
         "10.1109/MSP.2020.3014591",
         "2007.16061",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 'external', 'category': 'Engineering'}, {'source': 'external', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}]",
         "2025-09-30 00:46:06.117109+00:00",
         "2025-09-30 00:46:06.117109+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         "Caio Seguin",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         " O. Sporns",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "8",
         "dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Brain network communication: concepts, models and applications",
         "Caio Seguin, O. Sporns, A. Zalesky",
         " A. Zalesky",
         "2023",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         null,
         "https://www.semanticscholar.org/paper/dd07477d365d2f31689b4a2f99215b5da340d4bc",
         "Nature Reviews Neuroscience",
         "Medicine, Computer Science, Mathematics, Biology",
         "154",
         "b5fd429038cef4c88eb4686f716576bc",
         "10.1038/s41583-023-00718-5",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Mathematics'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         "S. Loomba",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Jakob Straehle",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " V. Gangadharan",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Natalie Heike",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Abdelrahman Khalifa",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Alessandro Motta",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Niansheng Ju",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " Meike Sievers",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " J. Gempt",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " H. S. Meyer",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "9",
         "226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Connectomic comparison of mouse and human cortex",
         "S. Loomba, Jakob Straehle, V. Gangadharan, Natalie Heike, Abdelrahman Khalifa, Alessandro Motta, Niansheng Ju, Meike Sievers, J. Gempt, H. S. Meyer, M. Helmstaedter",
         " M. Helmstaedter",
         "2022",
         "The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human.",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "https://www.science.org/cms/asset/e9769bff-fc04-4e2d-bbc3-d187a367cff3/science.abo0924.v1.pdf",
         "https://www.semanticscholar.org/paper/226c81c22846ba91ba60c3d83e5f7c191bf2e4d4",
         "Science",
         "Medicine, Biology",
         "152",
         "f3fd75b91aee1e3f769322fc9abc6604",
         "10.1126/science.abo0924",
         null,
         "[{'source': 'external', 'category': 'Medicine'}, {'source': 's2-fos-model', 'category': 'Biology'}]",
         "2025-09-30 00:45:52.493537+00:00",
         "2025-09-30 00:45:52.493537+00:00"
        ],
        [
         "10",
         "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Sam Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilė Lukošiūtė, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, C. McKinnon, Chris Olah, D. Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, John Kernion, Jamie Kerr, J. Mueller, Jeffrey Ladish, J. Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noem'i Mercado, Nova Dassarma, Robin Larson, Sam McCandlish, S. Kundu, Scott Johnston, Shauna Kravec, S. E. Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom B. Brown, T. Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Benjamin Mann, Jared Kaplan",
         "Sam Bowman",
         "2022",
         "Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks.",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "https://arxiv.org/pdf/2211.03540",
         "https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",
         "arXiv.org",
         "Computer Science, Computer Science, Linguistics",
         "149",
         "bd891ffa97410f74480c289f6510913c",
         "10.48550/arXiv.2211.03540",
         "2211.0354",
         "[{'source': 'external', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Computer Science'}, {'source': 's2-fos-model', 'category': 'Linguistics'}]",
         "2025-09-30 00:46:58.124675+00:00",
         "2025-09-30 00:46:58.124675+00:00"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 3412
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>authors_list</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>scholar_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citations</th>\n",
       "      <th>title_hash</th>\n",
       "      <th>doi</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>s2_fields</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>David Rein</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>Betty Li Hou</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>Asa Cooper Stickland</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>Jackson Petty</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210b0a3d76e93079cc51b03c4115fde545eea966</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>David Rein, Betty Li Hou, Asa Cooper Stickland...</td>\n",
       "      <td>Richard Yuanzhe Pang</td>\n",
       "      <td>2023</td>\n",
       "      <td>We present GPQA, a challenging dataset of 448 ...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>https://arxiv.org/pdf/2311.12022.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/210b0a3d...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Biology, Physics, Computer S...</td>\n",
       "      <td>1065</td>\n",
       "      <td>d2390e0e97b7199093a42b27a5cf32bc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2311.12022</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "      <td>2025-09-30 00:46:58.124675+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>Marcos Florencio</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3a910119666673ce6d77894055fd356f600ca5e4</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Marcos Florencio, Thomas Barton</td>\n",
       "      <td>Thomas Barton</td>\n",
       "      <td>2025</td>\n",
       "      <td>Architectural obfuscation - e.g., permuting hi...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>https://arxiv.org/pdf/2506.18053.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/3a910119...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>89c5f7d7ddb26766a6eff262d5e0aa34</td>\n",
       "      <td>10.48550/arXiv.2506.18053</td>\n",
       "      <td>2506.18053</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:24.877895+00:00</td>\n",
       "      <td>2025-09-29 20:01:55.416994+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>49072764553763f1686121fd03e3dadda259f273</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>Jason Li</td>\n",
       "      <td>2024</td>\n",
       "      <td>Recent research (arXiv:2310.11453, arXiv:2402....</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>https://arxiv.org/pdf/2405.17703.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/49072764...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>81612dabd9dc5de68fc08c32d1ed9a14</td>\n",
       "      <td>10.48550/arXiv.2405.17703</td>\n",
       "      <td>2405.17703</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.685040+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.957507+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>Tristan Trim</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>a800bac1609408eb955625b7ce0df234d48d3845</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Tristan Trim, Triston Grayston</td>\n",
       "      <td>Triston Grayston</td>\n",
       "      <td>2024</td>\n",
       "      <td>This paper explores the mechanistic interpreta...</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>https://arxiv.org/pdf/2411.00867.pdf</td>\n",
       "      <td>https://www.semanticscholar.org/paper/a800bac1...</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>Computer Science, Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>ff64df4544d96f3711ebfc6255e44f82</td>\n",
       "      <td>10.48550/arXiv.2411.00867</td>\n",
       "      <td>2411.00867</td>\n",
       "      <td>[{'source': 'external', 'category': 'Computer ...</td>\n",
       "      <td>2025-09-29 20:01:19.456152+00:00</td>\n",
       "      <td>2025-09-29 20:01:48.743394+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3412 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_id  \\\n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "0    210b0a3d76e93079cc51b03c4115fde545eea966   \n",
       "..                                        ...   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "756  3a910119666673ce6d77894055fd356f600ca5e4   \n",
       "757  49072764553763f1686121fd03e3dadda259f273   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "758  a800bac1609408eb955625b7ce0df234d48d3845   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0    GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "..                                                 ...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "756  Mechanistic Interpretability in the Presence o...   \n",
       "757  Mechanistic Interpretability of Binary and Ter...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "758  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                               authors           authors_list  \\\n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...             David Rein   \n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...           Betty Li Hou   \n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...   Asa Cooper Stickland   \n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...          Jackson Petty   \n",
       "0    David Rein, Betty Li Hou, Asa Cooper Stickland...   Richard Yuanzhe Pang   \n",
       "..                                                 ...                    ...   \n",
       "756                    Marcos Florencio, Thomas Barton       Marcos Florencio   \n",
       "756                    Marcos Florencio, Thomas Barton          Thomas Barton   \n",
       "757                                           Jason Li               Jason Li   \n",
       "758                     Tristan Trim, Triston Grayston           Tristan Trim   \n",
       "758                     Tristan Trim, Triston Grayston       Triston Grayston   \n",
       "\n",
       "     year                                           abstract  \\\n",
       "0    2023  We present GPQA, a challenging dataset of 448 ...   \n",
       "0    2023  We present GPQA, a challenging dataset of 448 ...   \n",
       "0    2023  We present GPQA, a challenging dataset of 448 ...   \n",
       "0    2023  We present GPQA, a challenging dataset of 448 ...   \n",
       "0    2023  We present GPQA, a challenging dataset of 448 ...   \n",
       "..    ...                                                ...   \n",
       "756  2025  Architectural obfuscation - e.g., permuting hi...   \n",
       "756  2025  Architectural obfuscation - e.g., permuting hi...   \n",
       "757  2024  Recent research (arXiv:2310.11453, arXiv:2402....   \n",
       "758  2024  This paper explores the mechanistic interpreta...   \n",
       "758  2024  This paper explores the mechanistic interpreta...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...   \n",
       "..                                                 ...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...   \n",
       "757  https://www.semanticscholar.org/paper/49072764...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...   \n",
       "\n",
       "                                  pdf_url  \\\n",
       "0    https://arxiv.org/pdf/2311.12022.pdf   \n",
       "0    https://arxiv.org/pdf/2311.12022.pdf   \n",
       "0    https://arxiv.org/pdf/2311.12022.pdf   \n",
       "0    https://arxiv.org/pdf/2311.12022.pdf   \n",
       "0    https://arxiv.org/pdf/2311.12022.pdf   \n",
       "..                                    ...   \n",
       "756  https://arxiv.org/pdf/2506.18053.pdf   \n",
       "756  https://arxiv.org/pdf/2506.18053.pdf   \n",
       "757  https://arxiv.org/pdf/2405.17703.pdf   \n",
       "758  https://arxiv.org/pdf/2411.00867.pdf   \n",
       "758  https://arxiv.org/pdf/2411.00867.pdf   \n",
       "\n",
       "                                           scholar_url      venue  \\\n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...  arXiv.org   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...  arXiv.org   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...  arXiv.org   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...  arXiv.org   \n",
       "0    https://www.semanticscholar.org/paper/210b0a3d...  arXiv.org   \n",
       "..                                                 ...        ...   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...  arXiv.org   \n",
       "756  https://www.semanticscholar.org/paper/3a910119...  arXiv.org   \n",
       "757  https://www.semanticscholar.org/paper/49072764...  arXiv.org   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...  arXiv.org   \n",
       "758  https://www.semanticscholar.org/paper/a800bac1...  arXiv.org   \n",
       "\n",
       "                                              keywords  citations  \\\n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "0    Computer Science, Biology, Physics, Computer S...       1065   \n",
       "..                                                 ...        ...   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "756                 Computer Science, Computer Science          0   \n",
       "757                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "758                 Computer Science, Computer Science          0   \n",
       "\n",
       "                           title_hash                        doi    arxiv_id  \\\n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                        NaN  2311.12022   \n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                        NaN  2311.12022   \n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                        NaN  2311.12022   \n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                        NaN  2311.12022   \n",
       "0    d2390e0e97b7199093a42b27a5cf32bc                        NaN  2311.12022   \n",
       "..                                ...                        ...         ...   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34  10.48550/arXiv.2506.18053  2506.18053   \n",
       "756  89c5f7d7ddb26766a6eff262d5e0aa34  10.48550/arXiv.2506.18053  2506.18053   \n",
       "757  81612dabd9dc5de68fc08c32d1ed9a14  10.48550/arXiv.2405.17703  2405.17703   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82  10.48550/arXiv.2411.00867  2411.00867   \n",
       "758  ff64df4544d96f3711ebfc6255e44f82  10.48550/arXiv.2411.00867  2411.00867   \n",
       "\n",
       "                                             s2_fields  \\\n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "0    [{'source': 'external', 'category': 'Computer ...   \n",
       "..                                                 ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "756  [{'source': 'external', 'category': 'Computer ...   \n",
       "757  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "758  [{'source': 'external', 'category': 'Computer ...   \n",
       "\n",
       "                           created_at                        updated_at  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "0    2025-09-30 00:46:58.124675+00:00  2025-09-30 00:46:58.124675+00:00  \n",
       "..                                ...                               ...  \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00  \n",
       "756  2025-09-29 20:01:24.877895+00:00  2025-09-29 20:01:55.416994+00:00  \n",
       "757  2025-09-29 20:01:19.685040+00:00  2025-09-29 20:01:48.957507+00:00  \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00  \n",
       "758  2025-09-29 20:01:19.456152+00:00  2025-09-29 20:01:48.743394+00:00  \n",
       "\n",
       "[3412 rows x 18 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df_exploded = semantic_df.explode('authors_list')\n",
    "semantic_df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d36e458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df_exploded['authors_list'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b97811",
   "metadata": {},
   "source": [
    "# Simple Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2e302",
   "metadata": {},
   "source": [
    "Simplest approach using Lesswrong user names and semantic scholar data authors with fuzzy search methods (these do not consider any other column beyond author names nor semantic context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dd445e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def find_best_match(lw_username:str, authors_list:list, n_limit:int=5):\n",
    "\n",
    "    result = process.extract(lw_username, authors_list, scorer=fuzz.WRatio, limit=n_limit)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b47ee861",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_df_authors_list = semantic_df_exploded['authors_list'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751e4b7",
   "metadata": {},
   "source": [
    "We evaluate for the first lesswrong username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a1ec47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Elaine Shi', 48.857142857142854, 676),\n",
       " ('Alex Grzankowski', 48.484848484848484, 1256),\n",
       " ('Lei Yu', 45.0, 502),\n",
       " ('Mei Yu', 45.0, 575),\n",
       " (' Li Li', 42.75, 225)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_match(\n",
    "    lw_username= lesswrong_df['username'][0],\n",
    "    authors_list= semantic_df_authors_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87795c03",
   "metadata": {},
   "source": [
    "We iterate all Lesswrong users to try to find a real match from the semantic scholar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4ce4e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches_by_username = {}\n",
    "\n",
    "for index, row in lesswrong_df.iterrows():\n",
    "    lw_user = row['username']\n",
    "\n",
    "    top_matches = find_best_match(lw_username=lw_user, authors_list=semantic_df_authors_list)\n",
    "\n",
    "    best_matches_by_username[lw_user] = top_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "03446ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eliezer_Yudkowsky': [(' Elaine Shi', 48.857142857142854, 676),\n",
       "  ('Alex Grzankowski', 48.484848484848484, 1256),\n",
       "  ('Lei Yu', 45.0, 502),\n",
       "  ('Mei Yu', 45.0, 575),\n",
       "  (' Li Li', 42.75, 225)],\n",
       " 'Raemon': [(' Rachel Ramoni', 75.00000000000001, 1861),\n",
       "  (' J. Lara-Ramos', 65.45454545454547, 1879),\n",
       "  (' Zhixiang Rao', 60.00000000000001, 138),\n",
       "  ('M. Hammond', 60.00000000000001, 232),\n",
       "  ('Rania Hassen', 60.00000000000001, 252)],\n",
       " 'Zvi': [(' Asaf Zviran', 90.0, 2756),\n",
       "  ('Ziming Liu', 72.0, 238),\n",
       "  ('Zihao Lin', 72.0, 1020),\n",
       "  (' Venkatesh Kavididevi', 72.0, 1092),\n",
       "  (' S. Schiavi', 72.0, 1711)],\n",
       " 'RobbBB': [(' Rob d’Hondt', 57.0, 3021),\n",
       "  (' Robin Larson', 54.0, 80),\n",
       "  (' Robert Krzyzanowski', 54.0, 351),\n",
       "  (' Robert D. Kleinberg', 54.0, 680),\n",
       "  (' Robin Heidel', 54.0, 1193)],\n",
       " 'ryan_greenblatt': [('nan', 60.00000000000001, 3019),\n",
       "  ('Sean Bryan', 51.42857142857142, 2367),\n",
       "  (' Xuyang Ge', 50.0, 437),\n",
       "  ('Gang Chen', 50.0, 794),\n",
       "  (' Xuyang Ge', 50.0, 802)],\n",
       " 'ricraz': [(' A. Pižurica', 72.0, 3295),\n",
       "  (' V. Sriram', 65.45454545454547, 1100),\n",
       "  (' F. A. B. S. Ferreira', 65.45454545454547, 1460),\n",
       "  (' Eric Gan', 60.00000000000001, 239),\n",
       "  (' A. Barbeira', 60.00000000000001, 497)],\n",
       " 'lsusr': [('Ueli Rutishauser', 60.00000000000001, 172),\n",
       "  (' Amina Manseur', 60.00000000000001, 1568),\n",
       "  ('Konstantin Donhauser', 60.00000000000001, 3100),\n",
       "  (' E. Macaluso', 60.00000000000001, 3314),\n",
       "  (' B. Palsson', 54.0, 27)],\n",
       " 'orthonormal': [(' Komal', 68.4, 2568),\n",
       "  (' Senthooran Rajamanoharan', 57.0, 2513),\n",
       "  (' Thomas Barton', 55.416666666666664, 3408),\n",
       "  (' Ufuoma Oyiborhoro', 52.94117647058824, 1404),\n",
       "  ('Arthur Conmy', 52.17391304347826, 20)],\n",
       " 'evhub': [('Diriba Gemechu', 60.00000000000001, 1960),\n",
       "  (' Maxim Rakhuba', 60.00000000000001, 2845),\n",
       "  (' Zehui Xiong', 57.0, 121),\n",
       "  (' Zehui Xiong', 57.0, 373),\n",
       "  ('Yuehui Wang', 57.0, 2816)],\n",
       " 'Buck': [(' Buck Shlegeris', 90.0, 11),\n",
       "  (' Christian Buck', 90.0, 411),\n",
       "  (' Bukar Hassan', 73.28571428571429, 2787),\n",
       "  (' T. Bruckmann', 67.5, 1196),\n",
       "  (' H. Cruickshank', 67.5, 1581)],\n",
       " 'jessica.liu.taylor': [('J. Saylor', 67.5, 909),\n",
       "  (' Jessica Rumbelow', 51.42857142857142, 194),\n",
       "  (' Kyle Sporn', 48.857142857142854, 2215),\n",
       "  (' R. Salvador', 47.5, 3346),\n",
       "  (' Jessica W. Tsai', 47.05882352941176, 2723)],\n",
       " 'Mitchell_Porter': [('Mitchell Ostrow', 66.66666666666667, 315),\n",
       "  (' Michelle Chen Huebscher', 60.00000000000001, 410),\n",
       "  ('M.', 60.00000000000001, 3204),\n",
       "  ('Michael Curry', 57.14285714285714, 944),\n",
       "  ('Michael T. Pearce', 56.25, 926)],\n",
       " 'JenniferRM': [(' Jennifer Wortman Vaughan', 76.0, 1584),\n",
       "  (' Jennifer A. Hipp', 76.0, 2484),\n",
       "  (' Jennifer S. W. Campbell', 75.78947368421052, 1710),\n",
       "  (' Andrew M Leifer', 60.35294117647058, 1487),\n",
       "  ('nan', 60.00000000000001, 3019)],\n",
       " 'DanielFilan': [('Dan Xie', 75.00000000000001, 3233),\n",
       "  ('nan', 72.0, 3019),\n",
       "  ('Daniel Brand', 69.56521739130434, 2304),\n",
       "  (' Daniel Schoepflin', 60.35294117647058, 2102),\n",
       "  (' Danielle Rivera', 59.25925925925925, 2372)],\n",
       " 'Thane Ruthenis': [('nan', 60.00000000000001, 3019),\n",
       "  (' Wen Tan', 57.0, 3272),\n",
       "  (' Shenmin Zhang', 56.29629629629629, 428),\n",
       "  (' Wusheng Zhang', 56.29629629629629, 647),\n",
       "  (' Shengli Zhang', 56.29629629629629, 2641)],\n",
       " 'tailcalled': [('Researc H Article', 60.00000000000001, 506),\n",
       "  ('Researc H Article', 60.00000000000001, 825),\n",
       "  (' Mobolaji Olalekan Komolafe', 54.0, 517),\n",
       "  (' Michael Elad', 52.17391304347826, 662),\n",
       "  (' Michelle Chen Huebscher', 50.294117647058826, 410)],\n",
       " 'Chris_Leong': [(' Cyril Leung', 60.86956521739131, 374),\n",
       "  ('Chao Xiong', 57.14285714285714, 3090),\n",
       "  (' Christopher Potts', 57.0, 135),\n",
       "  (' Christopher Potts', 57.0, 1542),\n",
       "  (' Christopher Harding', 57.0, 1733)],\n",
       " 'Seth Herd': [(' Keith F. Joiner', 60.35294117647058, 1450),\n",
       "  (' Stephen Casper', 57.0, 199),\n",
       "  ('Stephen Casper', 57.0, 781),\n",
       "  (' Sebastian Ruder', 57.0, 2177),\n",
       "  (' Senthooran Rajamanoharan', 57.0, 2513)],\n",
       " 'leogao': [('Vincenzo Galgano', 65.45454545454547, 905),\n",
       "  (' Alejandro Ortega', 60.00000000000001, 188),\n",
       "  (' Fengtao Wang', 60.00000000000001, 799),\n",
       "  ('Abdelghafour Atlas', 60.00000000000001, 840),\n",
       "  (' Georgios Tsaousoglou', 60.00000000000001, 1071)],\n",
       " 'thomas-kwa': [(' Thomas Kwa', 66.66666666666667, 938),\n",
       "  (' Thomas Kwa', 66.66666666666667, 1551),\n",
       "  ('J. X. Prochaska', 60.00000000000001, 1896),\n",
       "  (' Thomas F. Icard', 57.0, 136),\n",
       "  (' Thomas McGrath', 57.0, 208)]}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matches_by_username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d53b0",
   "metadata": {},
   "source": [
    "We onbserve that limited successfull results appeared.\n",
    "\n",
    "Now we try to use displayName from Lesswrong to check if it is better,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "77bf3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches_by_displayed_name = {}\n",
    "\n",
    "for index, row in lesswrong_df.iterrows():\n",
    "    lw_user = row['displayName']\n",
    "\n",
    "    top_matches = find_best_match(lw_username=lw_user, authors_list=semantic_df_authors_list)\n",
    "\n",
    "    best_matches_by_displayed_name[lw_user] = top_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8fe85312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eliezer Yudkowsky': [('Lei Yu', 60.00000000000001, 502),\n",
       "  ('Mei Yu', 60.00000000000001, 575),\n",
       "  ('Ke Wu', 54.0, 675),\n",
       "  (' Yu Tao', 51.42857142857142, 2389),\n",
       "  (' Yu Ma', 51.300000000000004, 989)],\n",
       " 'Raemon': [(' Rachel Ramoni', 75.00000000000001, 1861),\n",
       "  (' J. Lara-Ramos', 65.45454545454547, 1879),\n",
       "  (' Zhixiang Rao', 60.00000000000001, 138),\n",
       "  ('M. Hammond', 60.00000000000001, 232),\n",
       "  ('Rania Hassen', 60.00000000000001, 252)],\n",
       " 'Zvi': [(' Asaf Zviran', 90.0, 2756),\n",
       "  ('Ziming Liu', 72.0, 238),\n",
       "  ('Zihao Lin', 72.0, 1020),\n",
       "  (' Venkatesh Kavididevi', 72.0, 1092),\n",
       "  (' S. Schiavi', 72.0, 1711)],\n",
       " 'Rob Bensinger': [('Roy Chen', 60.00000000000001, 2119),\n",
       "  ('Bing He', 60.00000000000001, 3192),\n",
       "  (' Robert D. Kleinberg', 59.192307692307686, 680),\n",
       "  (' Bing Li', 56.25, 718),\n",
       "  (' Toby Kenney', 56.00000000000001, 1315)],\n",
       " 'ryan_greenblatt': [('nan', 60.00000000000001, 3019),\n",
       "  ('Sean Bryan', 51.42857142857142, 2367),\n",
       "  (' Xuyang Ge', 50.0, 437),\n",
       "  ('Gang Chen', 50.0, 794),\n",
       "  (' Xuyang Ge', 50.0, 802)],\n",
       " 'Richard_Ngo': [('Richard H. Chapple', 70.00000000000001, 2819),\n",
       "  ('Richard H. Chapple', 70.00000000000001, 2916),\n",
       "  (' Richard K. Perez', 66.50000000000001, 692),\n",
       "  (' Richard Yuanzhe Pang', 66.31578947368422, 4),\n",
       "  (' Richard Holden', 61.53846153846154, 1771)],\n",
       " 'lsusr': [('Ueli Rutishauser', 60.00000000000001, 172),\n",
       "  (' Amina Manseur', 60.00000000000001, 1568),\n",
       "  ('Konstantin Donhauser', 60.00000000000001, 3100),\n",
       "  (' E. Macaluso', 60.00000000000001, 3314),\n",
       "  (' B. Palsson', 54.0, 27)],\n",
       " 'orthonormal': [(' Komal', 68.4, 2568),\n",
       "  (' Senthooran Rajamanoharan', 57.0, 2513),\n",
       "  (' Thomas Barton', 55.416666666666664, 3408),\n",
       "  (' Ufuoma Oyiborhoro', 52.94117647058824, 1404),\n",
       "  ('Arthur Conmy', 52.17391304347826, 20)],\n",
       " 'evhub': [('Diriba Gemechu', 60.00000000000001, 1960),\n",
       "  (' Maxim Rakhuba', 60.00000000000001, 2845),\n",
       "  (' Zehui Xiong', 57.0, 121),\n",
       "  (' Zehui Xiong', 57.0, 373),\n",
       "  ('Yuehui Wang', 57.0, 2816)],\n",
       " 'Buck': [(' Buck Shlegeris', 90.0, 11),\n",
       "  (' Christian Buck', 90.0, 411),\n",
       "  (' Bukar Hassan', 73.28571428571429, 2787),\n",
       "  (' T. Bruckmann', 67.5, 1196),\n",
       "  (' H. Cruickshank', 67.5, 1581)],\n",
       " 'jessicata': [(' Jessica Rumbelow', 64.125, 194),\n",
       "  (' Jessica W. Tsai', 64.125, 2723),\n",
       "  (' Dmitry Besstrashnov', 53.4375, 2810),\n",
       "  (' Tessa Han', 52.63157894736843, 2052),\n",
       "  (' Tessa O. House', 52.61538461538461, 2722)],\n",
       " 'Mitchell_Porter': [('Mitchell Ostrow', 66.66666666666667, 315),\n",
       "  (' Michelle Chen Huebscher', 60.00000000000001, 410),\n",
       "  ('M.', 60.00000000000001, 3204),\n",
       "  ('Michael Curry', 57.14285714285714, 944),\n",
       "  ('Michael T. Pearce', 56.25, 926)],\n",
       " 'JenniferRM': [(' Jennifer Wortman Vaughan', 76.0, 1584),\n",
       "  (' Jennifer A. Hipp', 76.0, 2484),\n",
       "  (' Jennifer S. W. Campbell', 75.78947368421052, 1710),\n",
       "  (' Andrew M Leifer', 60.35294117647058, 1487),\n",
       "  ('nan', 60.00000000000001, 3019)],\n",
       " 'DanielFilan': [('Dan Xie', 75.00000000000001, 3233),\n",
       "  ('nan', 72.0, 3019),\n",
       "  ('Daniel Brand', 69.56521739130434, 2304),\n",
       "  (' Daniel Schoepflin', 60.35294117647058, 2102),\n",
       "  (' Danielle Rivera', 59.25925925925925, 2372)],\n",
       " 'Thane Ruthenis': [('nan', 60.00000000000001, 3019),\n",
       "  (' Wen Tan', 57.0, 3272),\n",
       "  (' Shenmin Zhang', 56.29629629629629, 428),\n",
       "  (' Wusheng Zhang', 56.29629629629629, 647),\n",
       "  (' Shengli Zhang', 56.29629629629629, 2641)],\n",
       " 'tailcalled': [('Researc H Article', 60.00000000000001, 506),\n",
       "  ('Researc H Article', 60.00000000000001, 825),\n",
       "  (' Mobolaji Olalekan Komolafe', 54.0, 517),\n",
       "  (' Michael Elad', 52.17391304347826, 662),\n",
       "  (' Michelle Chen Huebscher', 50.294117647058826, 410)],\n",
       " 'Chris_Leong': [(' Cyril Leung', 60.86956521739131, 374),\n",
       "  ('Chao Xiong', 57.14285714285714, 3090),\n",
       "  (' Christopher Potts', 57.0, 135),\n",
       "  (' Christopher Potts', 57.0, 1542),\n",
       "  (' Christopher Harding', 57.0, 1733)],\n",
       " 'Seth Herd': [(' Keith F. Joiner', 60.35294117647058, 1450),\n",
       "  (' Stephen Casper', 57.0, 199),\n",
       "  ('Stephen Casper', 57.0, 781),\n",
       "  (' Sebastian Ruder', 57.0, 2177),\n",
       "  (' Senthooran Rajamanoharan', 57.0, 2513)],\n",
       " 'leogao': [('Vincenzo Galgano', 65.45454545454547, 905),\n",
       "  (' Alejandro Ortega', 60.00000000000001, 188),\n",
       "  (' Fengtao Wang', 60.00000000000001, 799),\n",
       "  ('Abdelghafour Atlas', 60.00000000000001, 840),\n",
       "  (' Georgios Tsaousoglou', 60.00000000000001, 1071)],\n",
       " 'Thomas Kwa': [(' Thomas Kwa', 95.23809523809523, 938),\n",
       "  (' Thomas Kwa', 95.23809523809523, 1551),\n",
       "  (' Thomas F. Icard', 85.5, 136),\n",
       "  (' Thomas McGrath', 85.5, 208),\n",
       "  (' Thomas Hofmann', 85.5, 1742)]}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matches_by_displayed_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebc2b8",
   "metadata": {},
   "source": [
    "Apparenty it still has some similar perfomance. The usernames are not that easy to match to paper authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c55e08",
   "metadata": {},
   "source": [
    "# Embeddings search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7a5d4137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'username', 'displayName', 'karma', 'afKarma',\n",
       "       'ai_safety_tags', 'post_count_in_ai_safety', '_id', 'slug', 'bio',\n",
       "       'jobTitle', 'organization', 'careerStage', 'website',\n",
       "       'linkedinProfileURL', 'githubProfileURL', 'twitterProfileURL',\n",
       "       'postCount', 'commentCount', 'createdAt', 'profileTagIds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesswrong_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "87c6b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "userId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "username",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "27e9aaf3-0475-4363-9d72-01ab074946b6",
       "rows": [
        [
         "0",
         "nmk3nLpQE89dMRzzN",
         "Eliezer_Yudkowsky"
        ],
        [
         "1",
         "r38pkCm7wF4M44MDQ",
         "Raemon"
        ],
        [
         "2",
         "N9zj5qpTfqmbn9dro",
         "Zvi"
        ],
        [
         "3",
         "2aoRX3ookcCozcb3m",
         "RobbBB"
        ],
        [
         "4",
         "dfZAq9eZxs4BB4Ji5",
         "ryan_greenblatt"
        ],
        [
         "5",
         "BCmzFRdQhqLPREvat",
         "ricraz"
        ],
        [
         "6",
         "n6LYNw2uGfYnD4pX2",
         "lsusr"
        ],
        [
         "7",
         "4fh2AAe3n7oBviyxx",
         "orthonormal"
        ],
        [
         "8",
         "AThTtkDufXp3rmMDa",
         "evhub"
        ],
        [
         "9",
         "rx7xLaHCh3m7Po385",
         "Buck"
        ],
        [
         "10",
         "gSKzrqGFdS7DkXhuE",
         "jessica.liu.taylor"
        ],
        [
         "11",
         "fjERoRhgjipqw3z2b",
         "Mitchell_Porter"
        ],
        [
         "12",
         "g8JkZfL8PTqAefpvx",
         "JenniferRM"
        ],
        [
         "13",
         "DgsGzjyBXN8XSK22q",
         "DanielFilan"
        ],
        [
         "14",
         "nDpieb7g8huozpx9j",
         "Thane Ruthenis"
        ],
        [
         "15",
         "mfgrYb4LMk7NWXsSB",
         "tailcalled"
        ],
        [
         "16",
         "XLwKyCK7JmC292ZCC",
         "Chris_Leong"
        ],
        [
         "17",
         "TCjNiBLBPyhZq5BuM",
         "Seth Herd"
        ],
        [
         "18",
         "QpvwBD5AtmmFDTC3T",
         "leogao"
        ],
        [
         "19",
         "x5S2Kuj6TfQTGuo63",
         "thomas-kwa"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmk3nLpQE89dMRzzN</td>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r38pkCm7wF4M44MDQ</td>\n",
       "      <td>Raemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N9zj5qpTfqmbn9dro</td>\n",
       "      <td>Zvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2aoRX3ookcCozcb3m</td>\n",
       "      <td>RobbBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfZAq9eZxs4BB4Ji5</td>\n",
       "      <td>ryan_greenblatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BCmzFRdQhqLPREvat</td>\n",
       "      <td>ricraz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6LYNw2uGfYnD4pX2</td>\n",
       "      <td>lsusr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4fh2AAe3n7oBviyxx</td>\n",
       "      <td>orthonormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AThTtkDufXp3rmMDa</td>\n",
       "      <td>evhub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rx7xLaHCh3m7Po385</td>\n",
       "      <td>Buck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gSKzrqGFdS7DkXhuE</td>\n",
       "      <td>jessica.liu.taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fjERoRhgjipqw3z2b</td>\n",
       "      <td>Mitchell_Porter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g8JkZfL8PTqAefpvx</td>\n",
       "      <td>JenniferRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DgsGzjyBXN8XSK22q</td>\n",
       "      <td>DanielFilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nDpieb7g8huozpx9j</td>\n",
       "      <td>Thane Ruthenis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mfgrYb4LMk7NWXsSB</td>\n",
       "      <td>tailcalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XLwKyCK7JmC292ZCC</td>\n",
       "      <td>Chris_Leong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCjNiBLBPyhZq5BuM</td>\n",
       "      <td>Seth Herd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QpvwBD5AtmmFDTC3T</td>\n",
       "      <td>leogao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x5S2Kuj6TfQTGuo63</td>\n",
       "      <td>thomas-kwa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId            username\n",
       "0   nmk3nLpQE89dMRzzN   Eliezer_Yudkowsky\n",
       "1   r38pkCm7wF4M44MDQ              Raemon\n",
       "2   N9zj5qpTfqmbn9dro                 Zvi\n",
       "3   2aoRX3ookcCozcb3m              RobbBB\n",
       "4   dfZAq9eZxs4BB4Ji5     ryan_greenblatt\n",
       "5   BCmzFRdQhqLPREvat              ricraz\n",
       "6   n6LYNw2uGfYnD4pX2               lsusr\n",
       "7   4fh2AAe3n7oBviyxx         orthonormal\n",
       "8   AThTtkDufXp3rmMDa               evhub\n",
       "9   rx7xLaHCh3m7Po385                Buck\n",
       "10  gSKzrqGFdS7DkXhuE  jessica.liu.taylor\n",
       "11  fjERoRhgjipqw3z2b     Mitchell_Porter\n",
       "12  g8JkZfL8PTqAefpvx          JenniferRM\n",
       "13  DgsGzjyBXN8XSK22q         DanielFilan\n",
       "14  nDpieb7g8huozpx9j      Thane Ruthenis\n",
       "15  mfgrYb4LMk7NWXsSB          tailcalled\n",
       "16  XLwKyCK7JmC292ZCC         Chris_Leong\n",
       "17  TCjNiBLBPyhZq5BuM           Seth Herd\n",
       "18  QpvwBD5AtmmFDTC3T              leogao\n",
       "19  x5S2Kuj6TfQTGuo63          thomas-kwa"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesswrong_df_for_emb = lesswrong_df[['userId', 'username']]\n",
    "lesswrong_df_for_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fd141",
   "metadata": {},
   "source": [
    "We create a column usr_info with both the name and the tags assigned to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "db81b32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/4c4tkfqs3dn3fmj8pjs7lbcw0000gn/T/ipykernel_15114/3111924325.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lesswrong_df_for_emb['usr_info'] = lesswrong_df.apply(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "userId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "username",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "usr_info",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1561a728-0b77-4d5b-9ac3-501e4b7ca0dd",
       "rows": [
        [
         "0",
         "nmk3nLpQE89dMRzzN",
         "Eliezer_Yudkowsky",
         "Eliezer_Yudkowsky ['MIRI', 'MIRI'] "
        ],
        [
         "1",
         "r38pkCm7wF4M44MDQ",
         "Raemon",
         "Raemon ['MIRI', 'AI Governance'] LessWrong team member / moderator. I've been a LessWrong organizer since 2011, with roughly equal focus on the cultural, practical and intellectual aspects of the community. My first project was creating the Secular Solstice and helping groups across the world run their own version of it. More recently I've been interested in improving my own epistemic standards and helping others to do so as well."
        ],
        [
         "2",
         "N9zj5qpTfqmbn9dro",
         "Zvi",
         "Zvi ['AI Governance', 'AI Governance', 'Chain-of-Thought Alignment'] "
        ],
        [
         "3",
         "2aoRX3ookcCozcb3m",
         "RobbBB",
         "RobbBB ['MIRI', 'MIRI', 'MIRI', 'MIRI', 'MIRI'] Communications @ MIRI. Unless otherwise indicated, my posts and comments here reflect my own views, and not necessarily my employer's. (Though we agree about an awful lot.)"
        ],
        [
         "4",
         "dfZAq9eZxs4BB4Ji5",
         "ryan_greenblatt",
         "ryan_greenblatt ['Outer Alignment', 'AI Governance', 'AI Governance'] I'm the chief scientist at Redwood Research."
        ],
        [
         "5",
         "BCmzFRdQhqLPREvat",
         "ricraz",
         "ricraz ['Inner Alignment', 'Inner Alignment', 'AI Governance'] Formerly alignment and governance researcher at DeepMind and OpenAI. Now independent."
        ],
        [
         "6",
         "n6LYNw2uGfYnD4pX2",
         "lsusr",
         "lsusr ['Mesa-Optimization'] Here is a [list of all my public writings and videos (from before February 2025).](https://www.lsusr.com/)"
        ],
        [
         "7",
         "4fh2AAe3n7oBviyxx",
         "orthonormal",
         "orthonormal ['Mesa-Optimization'] "
        ],
        [
         "8",
         "AThTtkDufXp3rmMDa",
         "evhub",
         "evhub ['MIRI'] Evan Hubinger (he/him/his) ([evanjhub@gmail.com](mailto:evanjhub@gmail.com))\n\nHead of [Alignment Stress-Testing](https://www.alignmentforum.org/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic) at [Anthropic](https://www.anthropic.com/). My posts and comments are my own and do not represent Anthropic's positions, policies, strategies, or opinions.\n\nPreviously: MIRI, OpenAI\n\nSee: “[Why I'm joining Anthropic](https://www.lesswrong.com/posts/7jn5aDadcMH6sFeJe/why-i-m-joining-anthropic)”\n\nSelected work:\n\n*   “[Auditing language models for hidden objectives](https://www.alignmentforum.org/posts/wSKPuBfgkkqfTpmWJ/auditing-language-models-for-hidden-objectives)”\n*   “[Alignment faking in large language models](https://www.alignmentforum.org/posts/njAZwT8nkHnjipJku/alignment-faking-in-large-language-models)”\n*   “[Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://www.alignmentforum.org/posts/ZAsJv7xijKTfZkMtr/sleeper-agents-training-deceptive-llms-that-persist-through)”\n*   “[Conditioning Predictive Models](https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX)”\n*   “[An overview of 11 proposals for building safe advanced AI](https://www.alignmentforum.org/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai)”\n*   “[Risks from Learned Optimization](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB)”"
        ],
        [
         "9",
         "rx7xLaHCh3m7Po385",
         "Buck",
         "Buck ['AI Governance'] CEO at Redwood Research.\n\nAI safety is a highly collaborative field--almost all the points I make were either explained to me by someone else, or developed in conversation with other people. I'm saying this here because it would feel repetitive to say \"these ideas were developed in collaboration with various people\" in all my comments, but I want to have it on the record that the ideas I present were almost entirely not developed by me in isolation.\n\nPlease contact me via email (bshlegeris@gmail.com) instead of messaging me on LessWrong.\n\nIf we are ever arguing on LessWrong and you feel like it's kind of heated and would go better if we just talked about it verbally, please feel free to contact me and I'll probably be willing to call to discuss briefly."
        ],
        [
         "10",
         "gSKzrqGFdS7DkXhuE",
         "jessica.liu.taylor",
         "jessica.liu.taylor ['MIRI', 'MIRI'] Jessica Taylor. CS undergrad and Master's at Stanford; former research fellow at MIRI.\n\nI work on decision theory, social epistemology, strategy, naturalized agency, mathematical foundations, decentralized networking systems and applications, theory of mind, and functional programming languages.\n\nBlog: [unstableontology.com](http://unstableontology.com)\n\nTwitter: [https://twitter.com/jessi_cata](https://twitter.com/jessi_cata)"
        ],
        [
         "11",
         "fjERoRhgjipqw3z2b",
         "Mitchell_Porter",
         "Mitchell_Porter ['AI Governance'] "
        ],
        [
         "12",
         "g8JkZfL8PTqAefpvx",
         "JenniferRM",
         "JenniferRM ['Mesa-Optimization'] "
        ],
        [
         "13",
         "DgsGzjyBXN8XSK22q",
         "DanielFilan",
         "DanielFilan ['Inner Alignment', 'AI Governance', 'Mesa-Optimization'] "
        ],
        [
         "14",
         "nDpieb7g8huozpx9j",
         "Thane Ruthenis",
         "Thane Ruthenis ['Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization', 'Mesa-Optimization'] Agent-foundations researcher. Working on [Synthesizing Standalone World-Models](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking), aiming at a technical solution to the AGI risk fit for worlds where alignment is punishingly hard and we only get one try.\n\nCurrently looking for additional funders ($1k+, [details](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking#Funding)). Consider reaching out if you're interested, or [donating](https://manifund.org/projects/synthesizing-standalone-world-models) directly.\n\nOr [get me to pay *you* money](https://www.lesswrong.com/posts/LngR93YwiEpJ3kiWh/synthesizing-standalone-world-models-bounties-seeking#Bounties) ($5-$100) by spotting holes in my agenda or providing other useful information."
        ],
        [
         "15",
         "mfgrYb4LMk7NWXsSB",
         "tailcalled",
         "tailcalled ['MIRI'] "
        ],
        [
         "16",
         "XLwKyCK7JmC292ZCC",
         "Chris_Leong",
         "Chris_Leong ['MIRI', 'Inner Alignment'] "
        ],
        [
         "17",
         "TCjNiBLBPyhZq5BuM",
         "Seth Herd",
         "Seth Herd ['Inner Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment', 'Chain-of-Thought Alignment'] Message me here or at seth dot herd at gmail dot com.\n\nI was a researcher in cognitive psychology and cognitive neuroscience for two decades and change. I studied complex human thought using neural network models of brain function. I'm applying that knowledge to figuring out how we can align AI as developers make it to \"think for itself\" in all the ways that make humans capable and dangerous.\n\nIf you're new to alignment, see the Research Overview section below. Field veterans who are curious about my particular take and approach should see the More on My Approach section at the end of the profile.\n\nImportant posts:\n----------------\n\n*   On LLM-based agents as a route to takeover-capable AGI\n    *   [LLM AGI will have memory, and memory changes alignment](https://www.lesswrong.com/posts/aKncW36ZdEnzxLo8A/llm-agi-will-have-memory-and-memory-changes-alignment)\n    *   [Brief argument for short timelines being quite possible](https://www.lesswrong.com/posts/oC4wv4nTrs2yrP5hz/what-are-the-strongest-arguments-for-very-short-timelines?commentId=3vSTG4gZgvz9ki5LP)\n    *   [Capabilities and alignment of LLM cognitive architectures](https://www.lesswrong.com/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures)\n        *   Cognitive psychology perspective on routes to LLM-based AGI with no breakthroughs needed\n*   AGI risk interactions with societal power structures and incentives:\n    *   [Whether governments will control AGI is important and neglected](https://www.lesswrong.com/posts/fFqABwAHMvhHSFmce/whether-governments-will-control-agi-is-important-and)\n    *   [If we solve alignment, do we die anyway?](https://www.lesswrong.com/posts/kLpFvEBisPagBLTtM/if-we-solve-alignment-do-we-die-anyway-1)\n        *   Risks of proliferating human-controlled AGI\n    *   [Fear of centralized power vs. fear of misaligned AGI: Vitalik Buterin on 80,000 Hours](https://www.lesswrong.com/posts/6iJrd8c9jxRstxJyE/fear-of-centralized-power-vs-fear-of-misaligned-agi-vitalik)\n*   On the psychology of alignment as a field:\n    *   [Cruxes of disagreement on alignment difficulty](https://www.lesswrong.com/posts/ye78Dip8YNgLBKGcy/seth-herd-s-shortform?commentId=FpdvoZsmmrNLekkz9)\n    *   [Motivated reasoning/confirmation bias as the most important cognitive bias](https://www.lesswrong.com/posts/j789HDCKLoiKGjBik/which-biases-are-most-important-to-overcome#LW8zAxTguKj8ibDfX)\n*   On technical alignment of LLM-based AGI agents:\n    *   [System 2 Alignment](https://www.lesswrong.com/posts/cus5CGmLrjBRgcPSF/system-2-alignment) on how developers will try to align LLM agent AGI\n    *   [Seven sources of goals in LLM agents](https://www.lesswrong.com/posts/nHDhst47yzDCpGstx/seven-sources-of-goals-in-llm-agents) brief problem statement\n    *   [Internal independent review for language model agent alignment](https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent)\n*   On AGI alignment targets assuming technical alignment\n    *   [Problems with instruction-following as an alignment target](https://www.lesswrong.com/posts/CSFa9rvGNGAfCzBk6/problems-with-instruction-following-as-an-alignment-target)\n    *   [Instruction-following AGI is easier and more likely than value aligned AGI](https://www.lesswrong.com/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than)\n    *   [Goals selected from learned knowledge: an alternative to RL alignment](https://www.alignmentforum.org/posts/DfJCTp4MxmTFnYvgF/goals-selected-from-learned-knowledge-an-alternative-to-rl)\n*   On communicating AGI risks:\n    *   [Anthropomorphizing AI might be good, actually](https://www.lesswrong.com/posts/JfgME2Kdo5tuWkP59/anthropomorphizing-ai-might-be-good-actually)\n    *   [Humanity isn’t remotely longtermist, so arguments for AGI x-risk should focus on the near term](https://www.lesswrong.com/posts/fdracpKGbH4xqprQK/humanity-isn-t-remotely-longtermist-so-arguments-for-agi-x)\n    *   [AI scares and changing public beliefs](https://www.lesswrong.com/posts/ou5raNNjamAaahtWG/ai-scares-and-changing-public-beliefs)\n\nResearch Overview:\n------------------\n\n*Alignment* is the study of how to give AIs goals or values aligned with ours, so we're not in competition with our own creations. Recent breakthroughs in AI like ChatGPT make it possible we'll have smarter-than-human AIs soon. So we'd better get ready. If their goals don't align well enough with ours, they'll probably outsmart us and get their way — and treat us as we do ants or monkeys. See this [excellent intro video](https://www.youtube.com/watch?v=-H7e4XlMgg0) for more. \n\nThere are [good and deep reasons](https://www.lesswrong.com/posts/LLRtjkvh9AackwuNB/on-a-list-of-lethalities) to think that aligning AI will be very hard. But I think we have [promising solutions](https://alignmentforum.org/posts/xqqhwbH2mq6i4iLmK/we-have-promising-alignment-plans-with-low-taxes) that bypass most of those difficulties, and could be relatively easy to use for the types of AGI we're most likely to develop first. \n\nThat doesn't mean I think building AGI is safe. Humans often screw up complex projects, particularly on the first try, and we won't get many tries. If it were up to me I'd Shut It All Down, but I don't see how we could get all of humanity to stop building AGI. So I focus on finding alignment solutions for the types of AGI people are building.\n\nIn brief I think we can probably [build and align language model agents](https://alignmentforum.org/posts/ogHr8SvGqg9pW5wsT/capabilities-and-alignment-of-llm-cognitive-architectures) (or language model cognitive architectures) even when they're more autonomous and competent than humans. We'd use a [stacking suite of alignment methods](https://www.alignmentforum.org/posts/Q7XWGqL4HjjRmhEyG/internal-independent-review-for-language-model-agent) that can mostly or entirely [avoid using RL for alignment](https://alignmentforum.org/posts/DfJCTp4MxmTFnYvgF/goals-selected-from-learned-knowledge-an-alternative-to-rl), and achieve corrigibility (human-in-the-loop error correction) by having a [central goal of following instructions](https://alignmentforum.org/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than). This scenario leaves multiple humans in charge of ASIs, creating some dangerous dynamics, but those problems might be navigated, too. \n\nBio\n---\n\nI did computational cognitive neuroscience research from getting my PhD in 2006 until the end of 2022. I've worked on computational theories of vision, executive function, episodic memory, and decision-making, using neural network models of brain function to integrate data across levels of analysis from psychological down to molecular mechanisms of learning in neurons, and everything in between. I've focused on the interactions between different brain neural networks that are needed to explain complex thought. [Here's a list of my publications.](https://sethaherd.com/neuroscience-publications/) \n\nI was increasingly concerned with AGI applications of the research, and reluctant to publish my full theories lest they be used to accelerate AI progress. I'm incredibly excited to now be working full-time on alignment, currently as a research fellow at the [Astera Institute](https://astera.org).  \n\nMore on My Approach\n-------------------\n\nThe field of AGI alignment is \"pre-paradigmatic.\" So I spend a lot of my time thinking about what problems need to be solved, and how we should go about solving them. Solving the wrong problems seems like a waste of time we can't afford.\n\nWhen LLMs suddenly started looking intelligent and useful, I noted that applying cognitive neuroscience ideas to them might well enable them to reach AGI and soon ASI levels. Current LLMs are like humans with no episodic memory for their experiences, and very little executive function for planning and goal-directed self-control. Adding those cognitive systems to LLMs can make them into cognitive architectures with all of humans' cognitive capacities - a [\"real\" artificial general intelligence](https://www.lesswrong.com/posts/YW249knFccwATGxki/real-agi) that will soon be able to outsmart humans. \n\nMy work since then has convinced me that we could probably also align such an AGI so that it stays aligned even if it grows much smarter than we are.  Instead of trying to give it a definition of ethics it can't misunderstand or re-interpret (value alignment mis-specification), we'll continue doing with the alignment target developers currently use: [Instruction-following](https://www.lesswrong.com/posts/7NvKrqoQgJkZJmcuD/instruction-following-agi-is-easier-and-more-likely-than). It's counter-intuitive to imagine an intelligent entity that wants nothing more than to follow instructions, but there's no logical reason this can't be done.  An instruction-following proto-AGI can be instructed to act as a helpful collaborator in keeping it aligned as it grows smarter. \n\nThere are significant problems to be solved in prioritizing instructions; we would need an agent to prioritize more recent instructions over previous ones, including hypothetical future instructions. \n\nI increasingly suspect we should be actively working to build such intelligences. It seems like our our best hope of survival, since I don't see how we can convince the whole world to pause AGI efforts, and other routes to AGI seem much harder to align since they won't \"think\" in English. Thus far, I haven't been able to engage enough careful critique of my ideas to know if this is wishful thinking, so I haven't embarked on actually helping develop language model cognitive architectures.\n\nEven though these approaches are pretty straightforward, they'd have to be implemented carefully. Humans often get things wrong on their first try at a complex project. So my p(doom) estimate of our long-term survival as a species is in the 50% range, too complex to call. That's despite having a pretty good mix of relevant knowledge and having spent a lot of time working through various scenarios. So I think anyone with a very high or very low estimate is overestimating their certainty."
        ],
        [
         "18",
         "QpvwBD5AtmmFDTC3T",
         "leogao",
         "leogao ['Mesa-Optimization'] "
        ],
        [
         "19",
         "x5S2Kuj6TfQTGuo63",
         "thomas-kwa",
         "thomas-kwa ['MIRI'] Member of technical staff at [METR](https://metr.org/).\n\nPreviously: [Vivek Hebbar's team at MIRI](https://www.lesswrong.com/posts/qbcuk8WwFnTZcXTd6/thomas-kwa-s-miri-research-experience) **→** [Adrià Garriga-Alonso](https://agarri.ga/) on [](https://agarri.ga/) [various empirical alignment projects](https://www.lesswrong.com/posts/bf3vciB36dnd75ZKJ/thomas-kwa-s-research-journal) → METR.\n\nI have signed no contracts or agreements whose existence I cannot mention."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>username</th>\n",
       "      <th>usr_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmk3nLpQE89dMRzzN</td>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>Eliezer_Yudkowsky ['MIRI', 'MIRI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r38pkCm7wF4M44MDQ</td>\n",
       "      <td>Raemon</td>\n",
       "      <td>Raemon ['MIRI', 'AI Governance'] LessWrong tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N9zj5qpTfqmbn9dro</td>\n",
       "      <td>Zvi</td>\n",
       "      <td>Zvi ['AI Governance', 'AI Governance', 'Chain-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2aoRX3ookcCozcb3m</td>\n",
       "      <td>RobbBB</td>\n",
       "      <td>RobbBB ['MIRI', 'MIRI', 'MIRI', 'MIRI', 'MIRI'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfZAq9eZxs4BB4Ji5</td>\n",
       "      <td>ryan_greenblatt</td>\n",
       "      <td>ryan_greenblatt ['Outer Alignment', 'AI Govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BCmzFRdQhqLPREvat</td>\n",
       "      <td>ricraz</td>\n",
       "      <td>ricraz ['Inner Alignment', 'Inner Alignment', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6LYNw2uGfYnD4pX2</td>\n",
       "      <td>lsusr</td>\n",
       "      <td>lsusr ['Mesa-Optimization'] Here is a [list of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4fh2AAe3n7oBviyxx</td>\n",
       "      <td>orthonormal</td>\n",
       "      <td>orthonormal ['Mesa-Optimization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AThTtkDufXp3rmMDa</td>\n",
       "      <td>evhub</td>\n",
       "      <td>evhub ['MIRI'] Evan Hubinger (he/him/his) ([ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rx7xLaHCh3m7Po385</td>\n",
       "      <td>Buck</td>\n",
       "      <td>Buck ['AI Governance'] CEO at Redwood Research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gSKzrqGFdS7DkXhuE</td>\n",
       "      <td>jessica.liu.taylor</td>\n",
       "      <td>jessica.liu.taylor ['MIRI', 'MIRI'] Jessica Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fjERoRhgjipqw3z2b</td>\n",
       "      <td>Mitchell_Porter</td>\n",
       "      <td>Mitchell_Porter ['AI Governance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g8JkZfL8PTqAefpvx</td>\n",
       "      <td>JenniferRM</td>\n",
       "      <td>JenniferRM ['Mesa-Optimization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DgsGzjyBXN8XSK22q</td>\n",
       "      <td>DanielFilan</td>\n",
       "      <td>DanielFilan ['Inner Alignment', 'AI Governance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nDpieb7g8huozpx9j</td>\n",
       "      <td>Thane Ruthenis</td>\n",
       "      <td>Thane Ruthenis ['Mesa-Optimization', 'Mesa-Opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mfgrYb4LMk7NWXsSB</td>\n",
       "      <td>tailcalled</td>\n",
       "      <td>tailcalled ['MIRI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XLwKyCK7JmC292ZCC</td>\n",
       "      <td>Chris_Leong</td>\n",
       "      <td>Chris_Leong ['MIRI', 'Inner Alignment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCjNiBLBPyhZq5BuM</td>\n",
       "      <td>Seth Herd</td>\n",
       "      <td>Seth Herd ['Inner Alignment', 'Chain-of-Though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QpvwBD5AtmmFDTC3T</td>\n",
       "      <td>leogao</td>\n",
       "      <td>leogao ['Mesa-Optimization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x5S2Kuj6TfQTGuo63</td>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>thomas-kwa ['MIRI'] Member of technical staff ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               userId            username  \\\n",
       "0   nmk3nLpQE89dMRzzN   Eliezer_Yudkowsky   \n",
       "1   r38pkCm7wF4M44MDQ              Raemon   \n",
       "2   N9zj5qpTfqmbn9dro                 Zvi   \n",
       "3   2aoRX3ookcCozcb3m              RobbBB   \n",
       "4   dfZAq9eZxs4BB4Ji5     ryan_greenblatt   \n",
       "5   BCmzFRdQhqLPREvat              ricraz   \n",
       "6   n6LYNw2uGfYnD4pX2               lsusr   \n",
       "7   4fh2AAe3n7oBviyxx         orthonormal   \n",
       "8   AThTtkDufXp3rmMDa               evhub   \n",
       "9   rx7xLaHCh3m7Po385                Buck   \n",
       "10  gSKzrqGFdS7DkXhuE  jessica.liu.taylor   \n",
       "11  fjERoRhgjipqw3z2b     Mitchell_Porter   \n",
       "12  g8JkZfL8PTqAefpvx          JenniferRM   \n",
       "13  DgsGzjyBXN8XSK22q         DanielFilan   \n",
       "14  nDpieb7g8huozpx9j      Thane Ruthenis   \n",
       "15  mfgrYb4LMk7NWXsSB          tailcalled   \n",
       "16  XLwKyCK7JmC292ZCC         Chris_Leong   \n",
       "17  TCjNiBLBPyhZq5BuM           Seth Herd   \n",
       "18  QpvwBD5AtmmFDTC3T              leogao   \n",
       "19  x5S2Kuj6TfQTGuo63          thomas-kwa   \n",
       "\n",
       "                                             usr_info  \n",
       "0                 Eliezer_Yudkowsky ['MIRI', 'MIRI']   \n",
       "1   Raemon ['MIRI', 'AI Governance'] LessWrong tea...  \n",
       "2   Zvi ['AI Governance', 'AI Governance', 'Chain-...  \n",
       "3   RobbBB ['MIRI', 'MIRI', 'MIRI', 'MIRI', 'MIRI'...  \n",
       "4   ryan_greenblatt ['Outer Alignment', 'AI Govern...  \n",
       "5   ricraz ['Inner Alignment', 'Inner Alignment', ...  \n",
       "6   lsusr ['Mesa-Optimization'] Here is a [list of...  \n",
       "7                  orthonormal ['Mesa-Optimization']   \n",
       "8   evhub ['MIRI'] Evan Hubinger (he/him/his) ([ev...  \n",
       "9   Buck ['AI Governance'] CEO at Redwood Research...  \n",
       "10  jessica.liu.taylor ['MIRI', 'MIRI'] Jessica Ta...  \n",
       "11                 Mitchell_Porter ['AI Governance']   \n",
       "12                  JenniferRM ['Mesa-Optimization']   \n",
       "13  DanielFilan ['Inner Alignment', 'AI Governance...  \n",
       "14  Thane Ruthenis ['Mesa-Optimization', 'Mesa-Opt...  \n",
       "15                               tailcalled ['MIRI']   \n",
       "16           Chris_Leong ['MIRI', 'Inner Alignment']   \n",
       "17  Seth Herd ['Inner Alignment', 'Chain-of-Though...  \n",
       "18                      leogao ['Mesa-Optimization']   \n",
       "19  thomas-kwa ['MIRI'] Member of technical staff ...  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesswrong_df_for_emb['usr_info'] = lesswrong_df.apply(\n",
    "    lambda row: f'{row['username']} {row['ai_safety_tags']} {row['bio']}',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "lesswrong_df_for_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "082e3261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0f3511e0-3cae-4dc2-9d69-d570728b04bf",
       "rows": [
        [
         "0",
         "David Rein",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Betty Li Hou",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Asa Cooper Stickland",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Jackson Petty",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Richard Yuanzhe Pang",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Julien Dirani",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Julian Michael",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "0",
         " Samuel R. Bowman",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark"
        ],
        [
         "1",
         "Kevin Wang",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        ],
        [
         "1",
         " Alexandre Variengien",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        ],
        [
         "1",
         " Arthur Conmy",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        ],
        [
         "1",
         " Buck Shlegeris",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        ],
        [
         "1",
         " J. Steinhardt",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        ],
        [
         "2",
         "B. Meskó",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare"
        ],
        [
         "2",
         " E. Topol",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare"
        ],
        [
         "3",
         "Neel Nanda",
         "Progress measures for grokking via mechanistic interpretability"
        ],
        [
         "3",
         " Lawrence Chan",
         "Progress measures for grokking via mechanistic interpretability"
        ],
        [
         "3",
         " Tom Lieberum",
         "Progress measures for grokking via mechanistic interpretability"
        ],
        [
         "3",
         " Jess Smith",
         "Progress measures for grokking via mechanistic interpretability"
        ],
        [
         "3",
         " J. Steinhardt",
         "Progress measures for grokking via mechanistic interpretability"
        ],
        [
         "4",
         "Arthur Conmy",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability"
        ],
        [
         "4",
         " Augustine N. Mavor-Parker",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability"
        ],
        [
         "4",
         " Aengus Lynch",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability"
        ],
        [
         "4",
         " Stefan Heimersheim",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability"
        ],
        [
         "4",
         " Adrià Garriga-Alonso",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability"
        ],
        [
         "5",
         "X. Fang",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications"
        ],
        [
         "5",
         " C. Lloyd",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications"
        ],
        [
         "5",
         " B. Palsson",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications"
        ],
        [
         "6",
         "Leonard Bereska",
         "Mechanistic Interpretability for AI Safety - A Review"
        ],
        [
         "6",
         " E. Gavves",
         "Mechanistic Interpretability for AI Safety - A Review"
        ],
        [
         "7",
         "Xiaowen Dong",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives"
        ],
        [
         "7",
         " D. Thanou",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives"
        ],
        [
         "7",
         " L. Toni",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives"
        ],
        [
         "7",
         " M. Bronstein",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives"
        ],
        [
         "7",
         " P. Frossard",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives"
        ],
        [
         "8",
         "Caio Seguin",
         "Brain network communication: concepts, models and applications"
        ],
        [
         "8",
         " O. Sporns",
         "Brain network communication: concepts, models and applications"
        ],
        [
         "8",
         " A. Zalesky",
         "Brain network communication: concepts, models and applications"
        ],
        [
         "9",
         "S. Loomba",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Jakob Straehle",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " V. Gangadharan",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Natalie Heike",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Abdelrahman Khalifa",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Alessandro Motta",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Niansheng Ju",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " Meike Sievers",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " J. Gempt",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " H. S. Meyer",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "9",
         " M. Helmstaedter",
         "Connectomic comparison of mouse and human cortex"
        ],
        [
         "10",
         "Sam Bowman",
         "Measuring Progress on Scalable Oversight for Large Language Models"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3412
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_list</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Rein</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Li Hou</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asa Cooper Stickland</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jackson Petty</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Yuanzhe Pang</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Marcos Florencio</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Thomas Barton</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Jason Li</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Tristan Trim</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Triston Grayston</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              authors_list                                              title\n",
       "0               David Rein  GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n",
       "0             Betty Li Hou  GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n",
       "0     Asa Cooper Stickland  GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n",
       "0            Jackson Petty  GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n",
       "0     Richard Yuanzhe Pang  GPQA: A Graduate-Level Google-Proof Q&A Benchmark\n",
       "..                     ...                                                ...\n",
       "756       Marcos Florencio  Mechanistic Interpretability in the Presence o...\n",
       "756          Thomas Barton  Mechanistic Interpretability in the Presence o...\n",
       "757               Jason Li  Mechanistic Interpretability of Binary and Ter...\n",
       "758           Tristan Trim  Mechanistic Interpretability of Reinforcement ...\n",
       "758       Triston Grayston  Mechanistic Interpretability of Reinforcement ...\n",
       "\n",
       "[3412 rows x 2 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df_for_emb = semantic_df_exploded[['authors_list', 'title']]\n",
    "semantic_df_for_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ef14adac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'title', 'authors', 'authors_list', 'year', 'abstract',\n",
       "       'url', 'pdf_url', 'scholar_url', 'venue', 'keywords', 'citations',\n",
       "       'title_hash', 'doi', 'arxiv_id', 's2_fields', 'created_at',\n",
       "       'updated_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df_exploded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cc349",
   "metadata": {},
   "source": [
    "We create a column author_info to add some context of the work to the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "bb3c521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/4c4tkfqs3dn3fmj8pjs7lbcw0000gn/T/ipykernel_15114/4291622764.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  semantic_df_for_emb['author_info'] = semantic_df_exploded.apply(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_info",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d169113f-c10d-4d4c-9bad-419d5f72b657",
       "rows": [
        [
         "0",
         "David Rein",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author:David Rein.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Betty Li Hou",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Betty Li Hou.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Asa Cooper Stickland",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Asa Cooper Stickland.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Jackson Petty",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Jackson Petty.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Richard Yuanzhe Pang",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Richard Yuanzhe Pang.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Julien Dirani",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Julien Dirani.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Julian Michael",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Julian Michael.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "0",
         " Samuel R. Bowman",
         "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
         "Author: Samuel R. Bowman.\n Abstract: We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities. Computer Science, Biology, Physics, Computer Science, Chemistry"
        ],
        [
         "1",
         "Kevin Wang",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Author:Kevin Wang.\n Abstract: Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks. Computer Science, Computer Science"
        ],
        [
         "1",
         " Alexandre Variengien",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Author: Alexandre Variengien.\n Abstract: Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks. Computer Science, Computer Science"
        ],
        [
         "1",
         " Arthur Conmy",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Author: Arthur Conmy.\n Abstract: Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks. Computer Science, Computer Science"
        ],
        [
         "1",
         " Buck Shlegeris",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Author: Buck Shlegeris.\n Abstract: Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks. Computer Science, Computer Science"
        ],
        [
         "1",
         " J. Steinhardt",
         "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small",
         "Author: J. Steinhardt.\n Abstract: Research in mechanistic interpretability seeks to explain behaviors of machine learning models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior\"in the wild\"in a language model. We evaluate the reliability of our explanation using three quantitative criteria--faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks. Computer Science, Computer Science"
        ],
        [
         "2",
         "B. Meskó",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "Author:B. Meskó.\n Abstract: The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality. Computer Science, Medicine, Medicine, Computer Science, Law"
        ],
        [
         "2",
         " E. Topol",
         "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
         "Author: E. Topol.\n Abstract: The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality. Computer Science, Medicine, Medicine, Computer Science, Law"
        ],
        [
         "3",
         "Neel Nanda",
         "Progress measures for grokking via mechanistic interpretability",
         "Author:Neel Nanda.\n Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components. Computer Science, Computer Science"
        ],
        [
         "3",
         " Lawrence Chan",
         "Progress measures for grokking via mechanistic interpretability",
         "Author: Lawrence Chan.\n Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components. Computer Science, Computer Science"
        ],
        [
         "3",
         " Tom Lieberum",
         "Progress measures for grokking via mechanistic interpretability",
         "Author: Tom Lieberum.\n Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components. Computer Science, Computer Science"
        ],
        [
         "3",
         " Jess Smith",
         "Progress measures for grokking via mechanistic interpretability",
         "Author: Jess Smith.\n Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components. Computer Science, Computer Science"
        ],
        [
         "3",
         " J. Steinhardt",
         "Progress measures for grokking via mechanistic interpretability",
         "Author: J. Steinhardt.\n Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components. Computer Science, Computer Science"
        ],
        [
         "4",
         "Arthur Conmy",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Author:Arthur Conmy.\n Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery. Computer Science, Computer Science, Engineering"
        ],
        [
         "4",
         " Augustine N. Mavor-Parker",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Author: Augustine N. Mavor-Parker.\n Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery. Computer Science, Computer Science, Engineering"
        ],
        [
         "4",
         " Aengus Lynch",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Author: Aengus Lynch.\n Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery. Computer Science, Computer Science, Engineering"
        ],
        [
         "4",
         " Stefan Heimersheim",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Author: Stefan Heimersheim.\n Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery. Computer Science, Computer Science, Engineering"
        ],
        [
         "4",
         " Adrià Garriga-Alonso",
         "Towards Automated Circuit Discovery for Mechanistic Interpretability",
         "Author: Adrià Garriga-Alonso.\n Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systematizes the mechanistic interpretability process they followed. First, researchers choose a metric and dataset that elicit the desired model behavior. Then, they apply activation patching to find which abstract neural network units are involved in the behavior. By varying the dataset, metric, and units under investigation, researchers can understand the functionality of each component. We automate one of the process' steps: to identify the circuit that implements the specified behavior in the model's computational graph. We propose several algorithms and reproduce previous interpretability results to validate them. For example, the ACDC algorithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that computes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2 Small, all of which were manually found by previous work. Our code is available at https://github.com/ArthurConmy/Automatic-Circuit-Discovery. Computer Science, Computer Science, Engineering"
        ],
        [
         "5",
         "X. Fang",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "Author:X. Fang.\n Abstract: nan Biology, Medicine, Computer Science, Biology"
        ],
        [
         "5",
         " C. Lloyd",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "Author: C. Lloyd.\n Abstract: nan Biology, Medicine, Computer Science, Biology"
        ],
        [
         "5",
         " B. Palsson",
         "Reconstructing organisms in silico: genome-scale models and their emerging applications",
         "Author: B. Palsson.\n Abstract: nan Biology, Medicine, Computer Science, Biology"
        ],
        [
         "6",
         "Leonard Bereska",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Author:Leonard Bereska.\n Abstract: Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable. Computer Science, Computer Science, Engineering"
        ],
        [
         "6",
         " E. Gavves",
         "Mechanistic Interpretability for AI Safety - A Review",
         "Author: E. Gavves.\n Abstract: Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We examine benefits in understanding, control, alignment, and risks such as capability gains and dual-use concerns. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable. Computer Science, Computer Science, Engineering"
        ],
        [
         "7",
         "Xiaowen Dong",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Author:Xiaowen Dong.\n Abstract: The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age. Computer Science, Engineering, Mathematics, Computer Science, Mathematics"
        ],
        [
         "7",
         " D. Thanou",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Author: D. Thanou.\n Abstract: The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age. Computer Science, Engineering, Mathematics, Computer Science, Mathematics"
        ],
        [
         "7",
         " L. Toni",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Author: L. Toni.\n Abstract: The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age. Computer Science, Engineering, Mathematics, Computer Science, Mathematics"
        ],
        [
         "7",
         " M. Bronstein",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Author: M. Bronstein.\n Abstract: The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age. Computer Science, Engineering, Mathematics, Computer Science, Mathematics"
        ],
        [
         "7",
         " P. Frossard",
         "Graph Signal Processing for Machine Learning: A Review and New Perspectives",
         "Author: P. Frossard.\n Abstract: The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age. Computer Science, Engineering, Mathematics, Computer Science, Mathematics"
        ],
        [
         "8",
         "Caio Seguin",
         "Brain network communication: concepts, models and applications",
         "Author:Caio Seguin.\n Abstract: nan Medicine, Computer Science, Mathematics, Biology"
        ],
        [
         "8",
         " O. Sporns",
         "Brain network communication: concepts, models and applications",
         "Author: O. Sporns.\n Abstract: nan Medicine, Computer Science, Mathematics, Biology"
        ],
        [
         "8",
         " A. Zalesky",
         "Brain network communication: concepts, models and applications",
         "Author: A. Zalesky.\n Abstract: nan Medicine, Computer Science, Mathematics, Biology"
        ],
        [
         "9",
         "S. Loomba",
         "Connectomic comparison of mouse and human cortex",
         "Author:S. Loomba.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Jakob Straehle",
         "Connectomic comparison of mouse and human cortex",
         "Author: Jakob Straehle.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " V. Gangadharan",
         "Connectomic comparison of mouse and human cortex",
         "Author: V. Gangadharan.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Natalie Heike",
         "Connectomic comparison of mouse and human cortex",
         "Author: Natalie Heike.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Abdelrahman Khalifa",
         "Connectomic comparison of mouse and human cortex",
         "Author: Abdelrahman Khalifa.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Alessandro Motta",
         "Connectomic comparison of mouse and human cortex",
         "Author: Alessandro Motta.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Niansheng Ju",
         "Connectomic comparison of mouse and human cortex",
         "Author: Niansheng Ju.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " Meike Sievers",
         "Connectomic comparison of mouse and human cortex",
         "Author: Meike Sievers.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " J. Gempt",
         "Connectomic comparison of mouse and human cortex",
         "Author: J. Gempt.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " H. S. Meyer",
         "Connectomic comparison of mouse and human cortex",
         "Author: H. S. Meyer.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "9",
         " M. Helmstaedter",
         "Connectomic comparison of mouse and human cortex",
         "Author: M. Helmstaedter.\n Abstract: The human cerebral cortex houses 1000 times more neurons than that of the cerebral cortex of a mouse, but the possible differences in synaptic circuits between these species are still poorly understood. We used three-dimensional electron microscopy of mouse, macaque, and human cortical samples to study their cell type composition and synaptic circuit architecture. The 2.5-fold increase in interneurons in humans compared with mice was compensated by a change in axonal connection probabilities and therefore did not yield a commensurate increase in inhibitory-versus-excitatory synaptic input balance on human pyramidal cells. Rather, increased inhibition created an expanded interneuron-to-interneuron network, driven by an expansion of interneuron-targeting interneuron types and an increase in their synaptic selectivity for interneuron innervation. These constitute key neuronal network alterations in the human cortex. Description The difference between human and mouse Over the past few decades, the mouse has become a model organism for brain research. Because of the close evolutionary similarity of ion channels, synaptic receptors, and other key molecular constituents of the brain to that of humans, corresponding similarity has been assumed for cortical neuronal circuits. However, comparative synaptic-resolution connectomic studies are required to determine the degree to which circuit structure has evolved between species. Using three-dimensional electron microscopy, Loomba et al. compared mouse and human/macaque cortex synaptic connectivity. Although human cells are much larger compared with mouse neurons and are more numerous, on average, they do not receive more synapses. And, even though there are three times more interneurons in the human cortex than in the mouse, the excitation-to-inhibition ratio is similar between the species. —PRS Three-dimensional electron microscopy of mouse, macaque, and human brain samples elucidates cell type composition and synaptic circuit architecture. INTRODUCTION The analysis of the human brain is a central goal of neuroscience, but for methodological reasons, research has focused on model organisms, the mouse in particular. Because substantial homology was found at the level of ion channels, transcriptional programs, and basic neuronal types, a strong similarity of neuronal circuits across species has also been assumed. However, a rigorous test of the configuration of local neuronal circuitry in mouse versus human—in particular, in the gray matter of the cerebral cortex—is missing. The about 1000-fold increase in number of neurons is the most obvious evolutionary change of neuronal network properties from mouse to human. Whether the structure of the local cortical circuitry has changed as well is, however, unclear. Recent data from transcriptomic analyses has indicated an increase in the proportion of inhibitory interneurons from mouse to human. But what the effect of such a change is on the circuit configurations found in the human cerebral cortex is not known. This is, however, of particular interest also to the study of neuropsychiatric disorders because in these, the alteration of inhibitory-to-excitatory synaptic balance has been identified as one possible mechanistic underpinning. RATIONALE We used recent methodological improvements in connectomics to acquire data from one macaque and two human individuals, using biopsies of the temporal, parietal, and frontal cortex. Human tissue was obtained from neurosurgical interventions related to tumor removal, in which access path tissue was harvested that was not primarily affected by the underlying disease. A key concern in the analysis of human patient tissue has been the relation to epilepsy surgery, when the underlying disease has required often year-long treatment with pharmaceuticals, plausibly altering synaptic connectivity. Therefore, the analysis of nonepileptic surgery tissue seemed of particular importance. We also included data from one macaque individual, who was not known to have any brain-related pathology. RESULTS We acquired three-dimensional electron microscopy data from temporal and frontal cortex of human and temporal and parietal cortex of macaque. From these, we obtained connectomic reconstructions and compared these with five connectomes from mouse cortex. On the basis of these data, we were able to determine the effect of the about 2.5-fold expansion of the interneuron pool in macaque and human cortex compared with that of mouse. Contrary to expectation, the inhibitory-to-excitatory synaptic balance on pyramidal neurons in macaque and human cortex was not substantially altered. Rather, the interneuron pool was selectively expanded for bipolar-type interneurons, which prefer the innervation of other interneurons, and which further increased their preference for interneuron innervation from mouse to human. These changes were each multifold, yielding in effect an about 10-fold expanded interneuron-to-interneuron network in the human cortex that is only sparsely present in mouse. The total amount of synaptic input to pyramidal neurons, however, did not change according to the threefold thickening of the cortex; rather, a modest increase from about 12,000 synaptic inputs in mouse to about 15,000 in human was found. CONCLUSION The principal cells of the cerebral cortex, pyramidal neurons, maintain almost constant inhibitory-to-excitatory input balance and total synaptic input across 100 million years of evolutionary divergence, which is particularly noteworthy with the concomitant 1000-fold expansion of the neuronal network size and the 2.5-fold increase of inhibitory interneurons from mouse to human. Rather, the key network change from mouse to human is an expansion of almost an order of magnitude of an interneuron-to-interneuron network that is virtually absent in mouse but constitutes a substantial part of the human cortical network. Whether this new network is primarily created through the expansion of existing neuronal types, or is related to the creation of new interneuron subtypes, requires further study. The discovery of this network component in human cortex encourages detailed analysis of its function in health and disease. Connectomic screening across mammalian species: Comparison of five mouse, two macaque, and two human connectomic datasets from the cerebral cortex. (A) Automated reconstructions of all neurons with their cell bodies in the volume shown, using random colors. The analyzed connectomes comprised a total of ~1.6 million synapses. Arrows indicate evolutionary divergence: the last common ancestor between human and mouse, approximately 100 million years ago, and the last common ancestor between human and macaque, about 20 million years ago. (B) Illustration of the about 10-fold expansion of the interneuron-to-interneuron network from mouse to human. Medicine, Biology"
        ],
        [
         "10",
         "Sam Bowman",
         "Measuring Progress on Scalable Oversight for Large Language Models",
         "Author:Sam Bowman.\n Abstract: Developing safe and useful general-purpose AI systems will require us to make progress on scalable oversight: the problem of supervising systems that potentially outperform us on most skills relevant to the task at hand. Empirical work on this problem is not straightforward, since we do not yet have systems that broadly exceed our abilities. This paper discusses one of the major ways we think about this problem, with a focus on ways it can be studied empirically. We first present an experimental design centered on tasks for which human specialists succeed but unaided humans and current general AI systems fail. We then present a proof-of-concept experiment meant to demonstrate a key feature of this experimental design and show its viability with two question-answering tasks: MMLU and time-limited QuALITY. On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance. These results are an encouraging sign that scalable oversight will be tractable to study with present models and bolster recent findings that large language models can productively assist humans with difficult tasks. Computer Science, Computer Science, Linguistics"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3412
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_list</th>\n",
       "      <th>title</th>\n",
       "      <th>author_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Rein</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>Author:David Rein.\\n Abstract: We present GPQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Li Hou</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>Author: Betty Li Hou.\\n Abstract: We present G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asa Cooper Stickland</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>Author: Asa Cooper Stickland.\\n Abstract: We p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jackson Petty</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>Author: Jackson Petty.\\n Abstract: We present ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Yuanzhe Pang</td>\n",
       "      <td>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</td>\n",
       "      <td>Author: Richard Yuanzhe Pang.\\n Abstract: We p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Marcos Florencio</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Author:Marcos Florencio.\\n Abstract: Architect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Thomas Barton</td>\n",
       "      <td>Mechanistic Interpretability in the Presence o...</td>\n",
       "      <td>Author: Thomas Barton.\\n Abstract: Architectur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Jason Li</td>\n",
       "      <td>Mechanistic Interpretability of Binary and Ter...</td>\n",
       "      <td>Author:Jason Li.\\n Abstract: Recent research (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Tristan Trim</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Author:Tristan Trim.\\n Abstract: This paper ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Triston Grayston</td>\n",
       "      <td>Mechanistic Interpretability of Reinforcement ...</td>\n",
       "      <td>Author: Triston Grayston.\\n Abstract: This pap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              authors_list                                              title  \\\n",
       "0               David Rein  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0             Betty Li Hou  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0     Asa Cooper Stickland  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0            Jackson Petty  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "0     Richard Yuanzhe Pang  GPQA: A Graduate-Level Google-Proof Q&A Benchmark   \n",
       "..                     ...                                                ...   \n",
       "756       Marcos Florencio  Mechanistic Interpretability in the Presence o...   \n",
       "756          Thomas Barton  Mechanistic Interpretability in the Presence o...   \n",
       "757               Jason Li  Mechanistic Interpretability of Binary and Ter...   \n",
       "758           Tristan Trim  Mechanistic Interpretability of Reinforcement ...   \n",
       "758       Triston Grayston  Mechanistic Interpretability of Reinforcement ...   \n",
       "\n",
       "                                           author_info  \n",
       "0    Author:David Rein.\\n Abstract: We present GPQA...  \n",
       "0    Author: Betty Li Hou.\\n Abstract: We present G...  \n",
       "0    Author: Asa Cooper Stickland.\\n Abstract: We p...  \n",
       "0    Author: Jackson Petty.\\n Abstract: We present ...  \n",
       "0    Author: Richard Yuanzhe Pang.\\n Abstract: We p...  \n",
       "..                                                 ...  \n",
       "756  Author:Marcos Florencio.\\n Abstract: Architect...  \n",
       "756  Author: Thomas Barton.\\n Abstract: Architectur...  \n",
       "757  Author:Jason Li.\\n Abstract: Recent research (...  \n",
       "758  Author:Tristan Trim.\\n Abstract: This paper ex...  \n",
       "758  Author: Triston Grayston.\\n Abstract: This pap...  \n",
       "\n",
       "[3412 rows x 3 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df_for_emb['author_info'] = semantic_df_exploded.apply(\n",
    "    lambda row: f'Author:{row['authors_list']}.\\n Abstract: {row['abstract']} {row['keywords']}',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "semantic_df_for_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "03dc5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_df_for_emb = semantic_df_for_emb.groupby('authors_list')['author_info'].apply(\n",
    "    lambda x: ' '.join(x)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3424336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "authors_list",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_info",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d4ab02e3-c9ad-4c21-a0ae-ad34bfb2ceee",
       "rows": [
        [
         "1",
         " A. Alhassan",
         "Author: A. Alhassan.\n Abstract: The Board plays a pivotal role in the administration of corporate affairs.   An effective Board oversight function basically consists of proper mechanisms for providing entrepreneurial and strategic leadership as well as promoting ethical values that allow stakeholders to exercise their rights to protect their investments’ sustainability. This study examined the effect of corporate governance mechanisms on sustainability reporting of listed non-financial firms in Nigeria. The study measured corporate governance attributes with board size, board independence, board gender diversity, board financial expertise and sustainability reporting was measured by sustainability disclosures metrics in line with Global Reporting Initiative (GRI) standards. The study adopted correlation research design relying on secondary data obtained from annual reports of the population, which comprised of 116 non-financial firms listed on Nigeria Exchange Group (NGX) as at 31st December 2020 with a sample size of 51 firms, covering the period of 2011 – 2020. The study employed multiple regression panel model to analyze the data with the aid of E-view 10 statistical tool. According to the results of random effect regression, board size and board members’ financial expertise have positive and significant effect on sustainability reporting. Based on the findings, the study concluded that corporate governance attributes have the capacity to effectively enhance the sustainability reporting of firms. Thus, the study recommended among others that regulators in financial reporting should mandate firms to have a sizeable board with members having financial expertise as a measure of enhancing sustainability reporting in Nigeria. Business, Environmental Science"
        ],
        [
         "2",
         " A. Arafa",
         "Author: A. Arafa.\n Abstract: Mathematical simulation of biological fluids is of upmost significance due to its numerous medical uses. Interpreting various biological flows necessitates a thorough knowledge of the peristaltic mechanism. This paper presents a computational study for the peristaltic pumping within vertical asymmetric channels filled with BN‐EG nanofluid under the influence of temperature‐dependent electrical conductivity and thermal radiation. Experimental study showed that the nanofluid created by suspending Boron Nitride particles in a combination of Ethylene Glycol exhibited non‐Newtonian characteristics. Further, the Carreau's fluid model provides accurate predictions about the rheological properties of BN‐EG nanofluid. Various configurations of the outer boundaries are considered, namely, square wave, multi‐sinusoidal wave, trapezoidal wave, and triangular wave. A uniform magnetic field together with nanoparticles and mass concentrations, joule heating, first‐order chemical reaction as well as viscous dissipation are considered. Influences of the Dufour and Soret numbers are examined, and the cases of biological scientific assumptions which is known as low Reynolds number and long wavelength are applied. All the computations are obtained numerically using Mathematica symbolical software (ND‐Solve), and the obtained results are presented in terms of the axial velocity u, heat transfer rate Z, concentration profile Ω, temperature profile θ, extra stress tensor Sxy${S}_{xy}$ , pressure gradient dpdx$\\frac{{dp}}{{dx}}$ , pressure rise Δpλ${\\mathrm{\\Delta p}}_{{\\lambda}}$ and stream function ψ. The major outcomes revealed that the maximizing in electrical conductivity coefficient, variable viscosity coefficient and magnetic field parameter is better to obtain a higher rate of the heat transfer while the increase in thermo‐diffusion effects as well as linear thermal radiation coefficient causes a reduction in the rate of heat transfer. Engineering, Materials Science, Physics Author: A. Arafa.\n Abstract: The proliferation of real-time applications has spurred much interest in data freshness, captured by the age-of-information (AoI) metric. When strategic data sources have private market information, a fundamental economic challenge is how to incentivize them to acquire fresh data and optimize the age-related performance. In this work, we consider an information update system in which a destination acquires, and pays for, fresh data updates from multiple sources. The destination incurs an age-related cost, modeled as a general increasing function of the AoI. Each source is strategic and incurs a sampling cost, which is its private information and may not be truthfully reported to the destination. The destination decides on the price of updates, when to get them, and who should generate them, based on the sources’ reported sampling costs. We show that a benchmark that naively trusts the sources’ reports can lead to an arbitrarily bad outcome compared to the case where sources truthfully report. To tackle this issue, we design an optimal (economic) mechanism for timely information acquisition following Myerson’s seminal work. To this end, our proposed optimal mechanism minimizes the sum of the destination’s age-related cost and its payment to the sources, while ensuring that the sources truthfully report their private information and will voluntarily participate in the mechanism. However, finding the optimal mechanisms may suffer from prohibitively expensive computational overheads as it involves solving a nonlinear infinite-dimensional optimization problem. We further propose a quantized version of the optimal mechanism that achieves asymptotic optimality, maintains the other economic properties, and enables one to tradeoff between optimality and computational overheads. Our analytical and numerical studies show that (i) both the optimal and quantized mechanisms can lead to an unbounded benefit under some distributions of the source costs compared against a benchmark; (ii) the optimal and quantized mechanisms are most beneficial when there are few sources with heterogeneous sampling costs. Computer Science, Computer Science, Economics Author: A. Arafa.\n Abstract: In this paper, we study a fresh data acquisition problem to acquire fresh data and optimize the age-related performance when strategic data sources have private market information. We consider an information update system in which a destination acquires, and pays for, fresh data updates from a source. The destination incurs an age-related cost, modeled as a general increasing function of the age-of-information (AoI). The source is strategic and incurs a sampling cost, which is its private information and may not be truthfully reported to the destination. To this end, we design an optimal (economic) mechanism for timely information acquisition by generalizing Myerson's seminal work. The goal is to minimize the sum of the destination's age-related cost and its payment to the source, while ensuring that the source truthfully reports its private information and will voluntarily participate in the mechanism. Our results show that, under some distributions of the source's cost, our proposed optimal mechanism can lead to an unbounded benefit, compared against a benchmark that naively trusts the source's report and thus incentivizes its maximal over-reporting. Computer Science, Computer Science, Economics"
        ],
        [
         "3",
         " A. B. Sagingalieva",
         "Author: A. B. Sagingalieva.\n Abstract: Quantum key distribution (QKD) is a revolutionary cryptography response to the rapidly growing cyberattacks threat posed by quantum computing. Yet, the roadblock limiting the vast expanse of secure quantum communication is the exponential decay of the transmitted quantum signal with the distance. Today’s quantum cryptography is trying to solve this problem by focusing on quantum repeaters. However, efficient and secure quantum repetition at sufficient distances is still far beyond modern technology. Here, we shift the paradigm and build the long-distance security of the QKD upon the quantum foundations of the Second Law of Thermodynamics and end-to-end physical oversight over the transmitted optical quantum states. Our approach enables us to realize quantum states’ repetition by optical amplifiers keeping states’ wave properties and phase coherence. The unprecedented secure distance range attainable through our approach opens the door for the development of scalable quantum-resistant communication networks of the future. Physics, Medicine, Physics, Engineering"
        ],
        [
         "4",
         " A. Banerjee",
         "Author: A. Banerjee.\n Abstract: Recent years have seen a growing interest in spike based encoding of continuous time signals–a hallmark of biological computation. In this context, we present a mathematical framework for signal representation, leveraging a simple but robust mechanistic model of a biologically plausible spiking neuron. The framework considers encoding of a signal through spike trains generated by an ensemble of neurons via a standard convolve-then-threshold mechanism, albeit with a wide variety of convolution kernels. Reconstruction is posited as a convex optimization minimizing energy. Formal conditions under which perfect and approximate reconstruction of the signal from the spike trains is possible are then identified. The strength of the framework is shown in experiments on a large audio dataset, demonstrating good reconstruction at a spike rate of one fifth the Nyquist rate. Comparison against a benchmark sparse coding technique, viz convolutional orthogonal matching pursuit, shows competitive results in reconstruction with orders of magnitude improvement in runtime efficiency. Computer Science, Computer Science, Mathematics"
        ],
        [
         "5",
         " A. Barbeira",
         "Author: A. Barbeira.\n Abstract: Genetic regulation of gene expression, revealed by expression quantitative trait loci (eQTLs), exhibits complex patterns of tissue-specific effects. Characterization of these patterns may allow us to better understand mechanisms of gene regulation and disease etiology. We develop a constrained matrix factorization model, sn-spMF, to learn patterns of tissue-sharing and apply it to 49 human tissues from the Genotype-Tissue Expression (GTEx) project. The learned factors reflect tissues with known biological similarity and identify transcription factors that may mediate tissue-specific effects. sn-spMF, available at https://github.com/heyuan7676/ts_eQTLs, can be applied to learn biologically interpretable patterns of eQTL tissue-specificity and generate testable mechanistic hypotheses. Medicine, Biology, Computer Science, Biology"
        ],
        [
         "6",
         " A. Battle",
         "Author: A. Battle.\n Abstract: Genetic regulation of gene expression, revealed by expression quantitative trait loci (eQTLs), exhibits complex patterns of tissue-specific effects. Characterization of these patterns may allow us to better understand mechanisms of gene regulation and disease etiology. We develop a constrained matrix factorization model, sn-spMF, to learn patterns of tissue-sharing and apply it to 49 human tissues from the Genotype-Tissue Expression (GTEx) project. The learned factors reflect tissues with known biological similarity and identify transcription factors that may mediate tissue-specific effects. sn-spMF, available at https://github.com/heyuan7676/ts_eQTLs, can be applied to learn biologically interpretable patterns of eQTL tissue-specificity and generate testable mechanistic hypotheses. Medicine, Biology, Computer Science, Biology"
        ],
        [
         "7",
         " A. Bentbib",
         "Author: A. Bentbib.\n Abstract: Dictionary learning is a widely used technique in signal processing and machine learning that aims to represent data as a linear combination of a few elements from an overcomplete dictionary. In this work, we propose a generalization of the dictionary learning technique using the t-product framework, enabling efficient handling of multidimensional tensor data. We address the dictionary learning problem through online methods suitable for tensor structures. To effectively address the sparsity problem, we utilize an accelerated Iterative Shrinkage-Thresholding Algorithm (ISTA) enhanced with an extrapolation technique known as Anderson acceleration. This approach significantly improves signal reconstruction results. Extensive experiments prove that our proposed method outperforms existing acceleration techniques, particularly in applications such as data completion. These results suggest that our approach can be highly beneficial for large-scale tensor data analysis in various domains. Computer Science, Mathematics, Computer Science"
        ],
        [
         "8",
         " A. Bloch",
         "Author: A. Bloch.\n Abstract: nan Mathematics, Engineering"
        ],
        [
         "9",
         " A. Catarino",
         "Author: A. Catarino.\n Abstract: nan Medicine, Psychology, Computer Science, Medicine Author: A. Catarino.\n Abstract: Background Escalating mental health demand exceeds existing clinical capacity, necessitating scalable digital solutions. However, engagement remains challenging. Conversational agents can enhance engagement by making digital programs more interactive and personalized, but they have not been widely adopted. This study evaluated a digital program for anxiety in comparison to external comparators. The program used an artificial intelligence (AI)–driven conversational agent to deliver clinician-written content via machine learning, with clinician oversight and user support. Objective This study aims to evaluate the engagement, effectiveness, and safety of this structured, evidence-based digital program with human support for mild, moderate, and severe generalized anxiety. Statistical analyses sought to determine whether the program reduced anxiety more than a propensity-matched waiting control and was statistically noninferior to real-world, propensity-matched face-to-face and typed cognitive behavioral therapy (CBT). Methods Prospective participants (N=299) were recruited from the National Health Service (NHS) or social media in the United Kingdom and given access to the digital program for up to 9 weeks (study conducted from October 2023 to May 2024). End points were collected before, during, and after the digital program, as well as at a 1-month follow-up. External comparator groups were created through propensity matching of the digital program sample with NHS Talking Therapies (NHS TT) data from ieso Digital Health (typed CBT) and Dorset HealthCare (DHC) University NHS Foundation Trust (face-to-face CBT). Superiority and noninferiority analyses were conducted to compare anxiety symptom reduction (change on the 7-item Generalized Anxiety Disorder Scale [GAD-7]) between the digital program group and the external comparator groups. The program included human support, and clinician time spent per participant was calculated. Results Participants used the program for a median of 6 hours over 53 days, with 232 of the 299 (77.6%) engaged (ie, completing a median of 2 hours over 14 days). There was a large, clinically meaningful reduction in anxiety symptoms for the digital program group (per-protocol [PP; n=169]: mean GAD-7 change –7.4, d=1.6; intention-to-treat [ITT; n= 99]: mean GAD-7 change –5.4, d=1.1). The PP effect was statistically superior to the waiting control (d=1.3) and noninferior to the face-to-face CBT group (P<.001) and the typed CBT group (P<.001). Similarly, for the ITT sample, the digital program showed superiority to waiting control (d=0.8) and noninferiority to face-to-face CBT (P=.002), with noninferiority to typed CBT approaching significance (P=.06). Effects were sustained at the 1-month follow-up. Clinicians overseeing the digital program spent a mean of 1.6 hours (range 31-200 minutes) of clinician time in sessions per participant. Conclusions By combining AI and human support, the digital program achieved clinical outcomes comparable to human-delivered care, while significantly reducing the required clinician time by up to 8 times compared with global care estimates. These findings highlight the potential of technology to scale evidence-based mental health care, address unmet needs, and ultimately impact quality of life and reduce the economic burden globally. Trial Registration ISRCTN Registry ISRCTN52546704; http://www.isrctn.com/ISRCTN52546704 Medicine, Computer Science, Psychology, Medicine"
        ],
        [
         "10",
         " A. Cherif",
         "Author: A. Cherif.\n Abstract: We reviewed some of the latest advancements in the use of mathematical models in nephrology. We looked over 2 distinct categories of mathematical models that are widely used in biological research and pointed out some of their strengths and weaknesses when applied to health care, especially in the context of nephrology. A mechanistic dynamical system allows the representation of causal relations among the system variables but with a more complex and longer development/implementation phase. Artificial intelligence/machine learning provides predictive tools that allow identifying correlative patterns in large data sets, but they are usually harder-to-interpret black boxes. Chronic kidney disease (CKD), a major worldwide health problem, generates copious quantities of data that can be leveraged by choice of the appropriate model; also, there is a large number of dialysis parameters that need to be determined at every treatment session that can benefit from predictive mechanistic models. Following important steps in the use of mathematical methods in medical science might be in the intersection of seemingly antagonistic frameworks, by leveraging the strength of each to provide better care. Medicine, Medicine, Computer Science"
        ],
        [
         "11",
         " A. D. Blackwell",
         "Author: A. D. Blackwell.\n Abstract: nan Medicine, Psychology, Computer Science, Medicine Author: A. D. Blackwell.\n Abstract: Background Escalating mental health demand exceeds existing clinical capacity, necessitating scalable digital solutions. However, engagement remains challenging. Conversational agents can enhance engagement by making digital programs more interactive and personalized, but they have not been widely adopted. This study evaluated a digital program for anxiety in comparison to external comparators. The program used an artificial intelligence (AI)–driven conversational agent to deliver clinician-written content via machine learning, with clinician oversight and user support. Objective This study aims to evaluate the engagement, effectiveness, and safety of this structured, evidence-based digital program with human support for mild, moderate, and severe generalized anxiety. Statistical analyses sought to determine whether the program reduced anxiety more than a propensity-matched waiting control and was statistically noninferior to real-world, propensity-matched face-to-face and typed cognitive behavioral therapy (CBT). Methods Prospective participants (N=299) were recruited from the National Health Service (NHS) or social media in the United Kingdom and given access to the digital program for up to 9 weeks (study conducted from October 2023 to May 2024). End points were collected before, during, and after the digital program, as well as at a 1-month follow-up. External comparator groups were created through propensity matching of the digital program sample with NHS Talking Therapies (NHS TT) data from ieso Digital Health (typed CBT) and Dorset HealthCare (DHC) University NHS Foundation Trust (face-to-face CBT). Superiority and noninferiority analyses were conducted to compare anxiety symptom reduction (change on the 7-item Generalized Anxiety Disorder Scale [GAD-7]) between the digital program group and the external comparator groups. The program included human support, and clinician time spent per participant was calculated. Results Participants used the program for a median of 6 hours over 53 days, with 232 of the 299 (77.6%) engaged (ie, completing a median of 2 hours over 14 days). There was a large, clinically meaningful reduction in anxiety symptoms for the digital program group (per-protocol [PP; n=169]: mean GAD-7 change –7.4, d=1.6; intention-to-treat [ITT; n= 99]: mean GAD-7 change –5.4, d=1.1). The PP effect was statistically superior to the waiting control (d=1.3) and noninferior to the face-to-face CBT group (P<.001) and the typed CBT group (P<.001). Similarly, for the ITT sample, the digital program showed superiority to waiting control (d=0.8) and noninferiority to face-to-face CBT (P=.002), with noninferiority to typed CBT approaching significance (P=.06). Effects were sustained at the 1-month follow-up. Clinicians overseeing the digital program spent a mean of 1.6 hours (range 31-200 minutes) of clinician time in sessions per participant. Conclusions By combining AI and human support, the digital program achieved clinical outcomes comparable to human-delivered care, while significantly reducing the required clinician time by up to 8 times compared with global care estimates. These findings highlight the potential of technology to scale evidence-based mental health care, address unmet needs, and ultimately impact quality of life and reduce the economic burden globally. Trial Registration ISRCTN Registry ISRCTN52546704; http://www.isrctn.com/ISRCTN52546704 Medicine, Computer Science, Psychology, Medicine"
        ],
        [
         "12",
         " A. Darzi",
         "Author: A. Darzi.\n Abstract: nan Computer Science, Medicine, Computer Science"
        ],
        [
         "13",
         " A. Elshekhipy",
         "Author: A. Elshekhipy.\n Abstract: Mathematical simulation of biological fluids is of upmost significance due to its numerous medical uses. Interpreting various biological flows necessitates a thorough knowledge of the peristaltic mechanism. This paper presents a computational study for the peristaltic pumping within vertical asymmetric channels filled with BN‐EG nanofluid under the influence of temperature‐dependent electrical conductivity and thermal radiation. Experimental study showed that the nanofluid created by suspending Boron Nitride particles in a combination of Ethylene Glycol exhibited non‐Newtonian characteristics. Further, the Carreau's fluid model provides accurate predictions about the rheological properties of BN‐EG nanofluid. Various configurations of the outer boundaries are considered, namely, square wave, multi‐sinusoidal wave, trapezoidal wave, and triangular wave. A uniform magnetic field together with nanoparticles and mass concentrations, joule heating, first‐order chemical reaction as well as viscous dissipation are considered. Influences of the Dufour and Soret numbers are examined, and the cases of biological scientific assumptions which is known as low Reynolds number and long wavelength are applied. All the computations are obtained numerically using Mathematica symbolical software (ND‐Solve), and the obtained results are presented in terms of the axial velocity u, heat transfer rate Z, concentration profile Ω, temperature profile θ, extra stress tensor Sxy${S}_{xy}$ , pressure gradient dpdx$\\frac{{dp}}{{dx}}$ , pressure rise Δpλ${\\mathrm{\\Delta p}}_{{\\lambda}}$ and stream function ψ. The major outcomes revealed that the maximizing in electrical conductivity coefficient, variable viscosity coefficient and magnetic field parameter is better to obtain a higher rate of the heat transfer while the increase in thermo‐diffusion effects as well as linear thermal radiation coefficient causes a reduction in the rate of heat transfer. Engineering, Materials Science, Physics"
        ],
        [
         "14",
         " A. Endert",
         "Author: A. Endert.\n Abstract: Typical deep neural networks (DNNs) are complex black-box models and their decision making process can be difficult to comprehend even for experienced machine learning practitioners. Therefore their use could be limited in mission-critical scenarios despite state-of-the-art performance on many challenging ML tasks. Through this work, we empower users to interpret DNNs with a post-hoc analysis protocol. We propose ProtoFac, an explainable matrix factorization technique that decomposes the latent representations at any selected layer in a pre-trained DNN as a collection of weighted prototypes, which are a small number of exemplars extracted from the original data (e.g. image patches, shapelets). Using the factorized weights and prototypes we build a surrogate model for interpretation by replacing the corresponding layer in the neural network. We identify a number of desired properties of ProtoFac including authenticity, interpretability, simplicity and propose the optimization objective and training procedure accordingly. The method is model-agnostic and can be applied to DNNs with varying architectures. It goes beyond per-sample feature-based explanation by providing prototypes as a condensed set of evidences used by the model for decision making. We applied ProtoFac to interpret pretrained DNNs for a variety of ML tasks including time series classification on electrocardiograms, and image classification. The result shows that ProtoFac is able to extract meaningful prototypes to explain the models' decisions while truthfully reflects the models' operation. We also evaluated human interpretability through Amazon Mechanical Turk (MTurk), showing that ProtoFac is able to produce interpretable and user-friendly explanations. Computer Science, Computer Science"
        ],
        [
         "15",
         " A. Frigessi",
         "Author: A. Frigessi.\n Abstract: Predicting cancer dynamics under treatment is challenging due to high inter-patient heterogeneity, lack of predictive biomarkers, and sparse and noisy longitudinal data. Mathematical models can summarize cancer dynamics by a few interpretable parameters per patient. Machine learning methods can then be trained to predict the model parameters from baseline covariates, but do not account for uncertainty in the parameter estimates. Instead, hierarchical Bayesian modeling can model the relationship between baseline covariates to longitudinal measurements via mechanistic parameters while accounting for uncertainty in every part of the model. The mapping from baseline covariates to model parameters can be modeled in several ways. A linear mapping simplifies inference but fails to capture nonlinear covariate effects and scale poorly for interaction modeling when the number of covariates is large. In contrast, Bayesian neural networks can potentially discover interactions between covariates automatically, but at a substantial cost in computational complexity. In this work, we develop a hierarchical Bayesian model of subpopulation dynamics that uses baseline covariate information to predict cancer dynamics under treatment, inspired by cancer dynamics in multiple myeloma (MM), where serum M protein is a well-known proxy of tumor burden. As a working example, we apply the model to a simulated dataset and compare its ability to predict M protein trajectories to a model with linear covariate effects. Our results show that the Bayesian neural network covariate effect model predicts cancer dynamics more accurately than a linear covariate effect model when covariate interactions are present. The framework can also be applied to other types of cancer or other time series prediction problems that can be described with a parametric model. Biology, Mathematics, Medicine, Computer Science"
        ],
        [
         "16",
         " A. Froemelt",
         "Author: A. Froemelt.\n Abstract: Mathematical modelling is an indispensable tool to support water resource recovery facility (WRRF) operators and engineers with the ambition of creating a truly circular economy and assuring a sustainable future. Despite the successful application of mechanistic models in the water sector, they show some important limitations and do not fully profit from the increasing digitalisation of systems and processes. Recent advances in data-driven methods have provided options for harnessing the power of Industry 4.0, but they are often limited by the lack of interpretability and extrapolation capabilities. Hybrid modelling (HM) combines these two modelling paradigms and aims to leverage both the rapidly increasing volumes of data collected, as well as the continued pursuit of greater process understanding. Despite the potential of HM in a sector that is undergoing a significant digital and cultural transformation, the application of hybrid models remains vague. This article presents an overview of HM methodologies applied to WRRFs and aims to stimulate the wider adoption and development of HM. We also highlight challenges and research needs for HM design and architecture, good modelling practice, data assurance, and software compatibility. HM is a paradigm for WRRF modelling to transition towards a more resource-efficient, resilient, and sustainable future. Medicine, Environmental Science, Engineering"
        ],
        [
         "17",
         " A. Grillo",
         "Author: A. Grillo.\n Abstract: This work concerns the study of the effective balance equations governing linear elastic electrostrictive composites, where mechanical strains can be observed due to the application of a given electric field in the so-called small strain and moderate electric field regime. The formulation is developed in the framework of the active elastic composites. The latter are defined as composite materials constitutively described by an additive decomposition of the stress tensor into a purely linear elastic contribution and another component, which is assumed to be given and quadratic in the applied electric field when further specialised to electrostrictive composites. We derive the new mathematical model by describing the effective mechanical behaviour of the whole material by means of the asymptotic (periodic) homogenisation technique. We assume that there exists a sharp separation between the micro-scale, where the distance among different sub-phases (i.e. inclusions and/or fibres and/or strata) is resolved, and the macro-scale, which is related to the average size of the whole system at hand. This way, we formally decompose spatial variations by assuming that every physical field and material property are depending on both the macro-scale and the micro-scale. The effective governing equations encode the role of the micro-structure, and the effective contributions to the global stress tensor are to be computed by solving appropriate linear-elastic-type cell problems on the periodic cell. We also provide analytic formulae for the electrostrictive tensor when the applied electric field is either microscopically uniform or given by a suitable multiplicative decomposition between purely microscopically and macroscopically varying components. The obtained results are consistently compared with previous works in the field, and can pave the way towards improvement of smart active materials currently utilised for engineering (possibly bio-inspired) purposes. Physics, Materials Science, Engineering, Physics"
        ],
        [
         "18",
         " A. Guergachi",
         "Author: A. Guergachi.\n Abstract: Analysis of long-term multichannel EEG signals for automatic seizure detection is an active area of research that has seen application of methods from different domains of signal processing and machine learning. The majority of approaches developed in this context consist of extraction of hand-crafted features that are used to train a classifier for eventual seizure detection. Approaches that are data-driven, do not use hand-crafted features, and use small amounts of patients' historical EEG data for classifier training are few in number. The approach presented in this paper falls in the latter category, and is based on a signal-derived empirical dictionary approach, which utilizes empirical mode decomposition (EMD) and discrete wavelet transform (DWT) based dictionaries learned using a framework inspired by traditional methods of dictionary learning. Three features associated with traditional dictionary learning approaches, namely projection coefficients, coefficient vector and reconstruction error, are extracted from both EMD and DWT based dictionaries for automated seizure detection. This is the first time these features have been applied for automatic seizure detection using an empirical dictionary approach. Small amounts of patients' historical multi-channel EEG data are used for classifier training, and multiple classifiers are used for seizure detection using newer data. In addition, the seizure detection results are validated using 5-fold cross-validation to rule out any bias in the results. The CHB-MIT benchmark database containing long-term EEG recordings of pediatric patients is used for validation of the approach, and seizure detection performance comparable to the state-of-the-art is obtained. Seizure detection is performed using five classifiers, thereby allowing a comparison of the dictionary approaches, features extracted, and classifiers used. The best seizure detection performance is obtained using EMD based dictionary and reconstruction error feature and support vector machine classifier, with accuracy, sensitivity and specificity values of 88.2, 90.3, and 88.1%, respectively. Comparison is also made with other recent studies using the same database. The methodology presented in this paper is shown to be computationally efficient and robust for patient-specific automatic seizure detection. A data-driven methodology utilizing a small amount of patients' historical data is hence demonstrated as a practical solution for automatic seizure detection. Medicine, Computer Science, Computer Science, Medicine"
        ],
        [
         "19",
         " A. Hafiane",
         "Author: A. Hafiane.\n Abstract: Big data streaming analytics has recently attracted much attention in the signal and information processing communities due to the fact that massive streaming datasets have been collected over the years. Among them, many modern data streams are represented as multidimensional arrays (aka tensors), and thus, streaming tensor decomposition or tensor tracking has become a promising tool to analyze such streaming data. In this paper, we propose a novel online algorithm called ROTDL for the problem of robust tensor tracking under the Tucker format. ROTDL is not only capable of tracking the underlying Tucker dictionary of multidimensional data streams over time, but also robust to sparse outliers. The proposed algorithm is specifically designed by using the alternating direction method of multipliers, block-coordinate descent, and recursive least-squares filtering techniques. Several experiments demonstrate the effectiveness of ROTDL for robust tensor tracking. Computer Science, Mathematics"
        ],
        [
         "20",
         " A. Hobolth",
         "Author: A. Hobolth.\n Abstract: Since its introduction, non-negative matrix factorization (NMF) has been a popular tool for extracting interpretable, low-dimensional representations of high-dimensional data. However, several recent studies have proposed replacing NMF with autoencoders. The increasing popularity of autoencoders warrants an investigation on whether this replacement is in general valid and reasonable. Moreover, the exact relationship between non-negative autoencoders and NMF has not been thoroughly explored. Thus, a main aim of this study is to investigate in detail the relationship between autoencoders and NMF. We define a non-negative linear autoencoder, AE-NMF, which is mathematically equivalent with convex NMF, a constrained version of NMF. The performance of NMF and the non-negative linear autoencoder is compared within the context of mutational signature extraction from simulated and real-world cancer genomics data. We find that the reconstructions based on NMF are more accurate compared with AE-NMF, while the signatures extracted using both methods exhibit comparable consistency and performance when externally validated. These findings suggest that AE-NMF, the linear non-negative autoencoders investigated in this article, do not provide an improvement of NMF in the field of mutational signature extraction. Our study serves as a foundation for understanding the theoretical implication of replacing NMF with non-negative autoencoders. Medicine, Computer Science, Computer Science, Biology"
        ],
        [
         "21",
         " A. Jetten",
         "Author: A. Jetten.\n Abstract: Feature finding is a common way to process untargeted mass spectrometry (MS) data to obtain a list of chemicals present in a sample. Most feature finding algorithms naïvely search for patterns of unique descriptors (e.g., m/z, retention time, and mobility) and provide a list of unannotated features. There is a need for solutions in processing untargeted MS data, independent of chemical or origin, to assess features based on measurement quality with the aim of improving interpretation. Here, we report the signal response evaluation as a method by which to assess the individual features observed in untargeted MS data. The basis of this method is the ubiquitous relationship between the amount and response in all MS measurements. Three different metrics with user-defined parameters can be used to assess the monotonic or linear relationship of each feature in a dilution series or multiple injection volumes. We demonstrate this approach in metabolomics data obtained from a uniform biological matrix (NIST SRM 1950) and a variable biological matrix (murine kidney tissue). The code is provided to facilitate implementation of this data processing method. Medicine, Chemistry"
        ],
        [
         "22",
         " A. Keil",
         "Author: A. Keil.\n Abstract: ABSTRACT Aversive conditioning changes visuocortical responses to conditioned cues, and the generalization of these changes to perceptually similar cues may provide mechanistic insights into anxiety and fear disorders. Yet, as in many areas of cognitive neuroscience, testing hypotheses about trial‐by‐trial dynamics in conditioning paradigms is challenged by poor single‐trial signal‐to‐noise ratios (SNR), missing trials, and inter‐individual differences. The present technical report demonstrates how a state‐of‐the‐art Bayesian workflow can overcome these issues, using a preliminary sample of simultaneously recorded EEG‐fMRI data. A preliminary group of observers (N = 24) viewed circular gratings varying in orientation, with only one orientation paired with an aversive outcome (noxious electric pulse). Gratings were flickered at 15 Hz to evoke steady‐state visual evoked potentials (ssVEPs), recorded with 31 channels of EEG in an MRI scanner. First, the benefits of a Bayesian multilevel structure are demonstrated on the fMRI data by improving a standard fMRI first‐level multiple regression. Next, the Bayesian modeling approach is demonstrated by applying a theory‐driven learning model to the EEG data. The multilevel structure of the Bayesian learning model informs and constrains estimates per participant, providing an interpretable generative model. In the example analysis provided in this report, it showed superior cross‐validation accuracy and provided insights into participant‐level learning dynamics. It also isolated the generalization effects of conditioning, providing improved statistical certainty. Lastly, missing trials were interpolated and weighted appropriately using the full model's structure. This is a critical aspect for single‐trial analyses of simultaneously recorded physiological measures because each added measure will typically increase the number of trials missing a complete set of observations. The present report aims to illustrate the utility of this analytical framework. It shows how models may be iteratively built and compared in a modern Bayesian workflow. Future models may use different conceptualizations of learning, allow integration of clinically relevant factors, and enable the fusion of different simultaneous recordings such as EEG, autonomic, behavioral, and hemodynamic data. Medicine, Psychology"
        ],
        [
         "23",
         " A. Kodukhov",
         "Author: A. Kodukhov.\n Abstract: Quantum key distribution (QKD) is a revolutionary cryptography response to the rapidly growing cyberattacks threat posed by quantum computing. Yet, the roadblock limiting the vast expanse of secure quantum communication is the exponential decay of the transmitted quantum signal with the distance. Today’s quantum cryptography is trying to solve this problem by focusing on quantum repeaters. However, efficient and secure quantum repetition at sufficient distances is still far beyond modern technology. Here, we shift the paradigm and build the long-distance security of the QKD upon the quantum foundations of the Second Law of Thermodynamics and end-to-end physical oversight over the transmitted optical quantum states. Our approach enables us to realize quantum states’ repetition by optical amplifiers keeping states’ wave properties and phase coherence. The unprecedented secure distance range attainable through our approach opens the door for the development of scalable quantum-resistant communication networks of the future. Physics, Medicine, Physics, Engineering"
        ],
        [
         "24",
         " A. Kulesza",
         "Author: A. Kulesza.\n Abstract: Health technology assessment (HTA) aims to be a systematic, transparent, unbiased synthesis of clinical efficacy, safety, and value of medical products (MPs) to help policymakers, payers, clinicians, and industry to make informed decisions. The evidence available for HTA has gaps—impeding timely prediction of the individual long-term effect in real clinical practice. Also, appraisal of an MP needs cross-stakeholder communication and engagement. Both aspects may benefit from extended use of modeling and simulation. Modeling is used in HTA for data-synthesis and health-economic projections. In parallel, regulatory consideration of model informed drug development (MIDD) has brought attention to mechanistic modeling techniques that could in fact be relevant for HTA. The ability to extrapolate and generate personalized predictions renders the mechanistic MIDD approaches suitable to support translation between clinical trial data into real-world evidence. In this perspective, we therefore discuss concrete examples of how mechanistic models could address HTA-related questions. We shed light on different stakeholder's contributions and needs in the appraisal phase and suggest how mechanistic modeling strategies and reporting can contribute to this effort. There are still barriers dissecting the HTA space and the clinical development space with regard to modeling: lack of an adapted model validation framework for decision-making process, inconsistent and unclear support by stakeholders, limited generalizable use cases, and absence of appropriate incentives. To address this challenge, we suggest to intensify the collaboration between competent authorities, drug developers and modelers with the aim to implement mechanistic models central in the evidence generation, synthesis, and appraisal of HTA so that the totality of mechanistic and clinical evidence can be leveraged by all relevant stakeholders. Medicine, Medicine, Economics"
        ],
        [
         "25",
         " A. Laghrib",
         "Author: A. Laghrib.\n Abstract: <abstract><p>The problem of interest in this paper is the mathematical and numerical analysis of a new non-variational model based on a high order non-linear PDE system resulting from image denoising. This model is motivated by involving the decomposition approach of $ H^{-1} $ norm suggested by Guo et al. <sup>[<xref ref-type=\"bibr\" rid=\"b1\">1</xref>,<xref ref-type=\"bibr\" rid=\"b2\">2</xref>]</sup> which is more appropriate to represent the small details in the textured image. Our model is based on a diffusion tensor that improves the behavior of the Perona-Malik diffusion directions in homogeneous regions and the Weickert model near tiny edges with a high diffusion order. A rigorous analysis of the existence and uniqueness of the weak solution of the proposed reaction-diffusion model is cheked in a suitable functional framework, using the Schauder fixed point theorem. Finally, we carry out a numerical result to show the effectiveness of our model by comparing the results obtained with some competitive models.</p></abstract> Computer Science, Mathematics, Engineering"
        ],
        [
         "26",
         " A. Leon-Garcia",
         "Author: A. Leon-Garcia.\n Abstract: This paper concerns the mechanism design for online resource allocation in a strategic setting. In this setting, a single supplier allocates capacity-limited resources to requests that arrive in a sequential and arbitrary manner. Each request is associated with an agent who may act selfishly to misreport the requirement and valuation of her request. The supplier charges payment from agents whose requests are satisfied, but incurs a load-dependent supply cost. The goal is to design an incentive compatible online mechanism, which determines not only the resource allocation of each request, but also the payment of each agent, so as to (approximately) maximize the social welfare (i.e., aggregate valuations minus supply cost). We study this problem under the framework of competitive analysis. The major contribution of this paper is the development of a unified approach that achieves the best-possible competitive ratios for setups with different supply costs. Specifically, we show that when there is no supply cost or the supply cost function is linear, our model is essentially a standard 0-1 knapsack problem, for which our approach achieves logarithmic competitive ratios that match the state-of-the-art (which is optimal). For the more challenging setup when the supply cost is strictly-convex, we provide online mechanisms, for the first time, that lead to the optimal competitive ratios as well. To the best of our knowledge, this is the first approach that unifies the characterization of optimal competitive ratios in online resource allocation for different setups including zero, linear and strictly-convex supply costs. Computer Science, Economics, Computer Science Author: A. Leon-Garcia.\n Abstract: This paper concerns the mechanism design for online resource allocation in a strategic setting. In this setting, a single supplier allocates capacity-limited resources to requests that arrive in a sequential and arbitrary manner. Each request is associated with an agent who may act selfishly to misreport the requirement and valuation of her request. The supplier charges payment from agents whose requests are satisfied, but incurs a load-dependent supply cost. The goal is to design an incentive compatible online mechanism, which determines not only the resource allocation of each request, but also the payment of each agent, so as to (approximately) maximize the social welfare (i.e., aggregate valuations minus supply cost). We study this problem under the framework of competitive analysis. The major contribution of this paper is the development of a unified approach that achieves the best-possible competitive ratios for setups with different supply costs. Specifically, we show that when there is no supply cost or the supply cost function is linear, our model is essentially a standard 0-1 knapsack problem, for which our approach achieves logarithmic competitive ratios that match the state-of-the-art (which is optimal). For the more challenging setup when the supply cost is strictly-convex, we provide online mechanisms, for the first time, that lead to the optimal competitive ratios as well. To the best of our knowledge, this is the first approach that unifies the characterization of optimal competitive ratios in online resource allocation for different setups including zero, linear and strictly-convex supply costs. Computer Science, Economics, Computer Science"
        ],
        [
         "27",
         " A. M. D. Jong",
         "Author: A. M. D. Jong.\n Abstract: Objective: The reconstruction of an input based on a sparse combination of signals, known as sparse coding, has found widespread use in signal processing. In this work, the combination of sparse coding with Kalman filtering is explored and its potential is shown on two use-cases. Methods: This work extends the Iterative Shrinkage and Thresholding Algorithm with a Kalman filter in the sparse domain. The resulting method may be implemented as a deep unfolded neural network and may be applied to any signal which has a sparse representation and a known or assumed relation between consecutive measurements. This method is evaluated on the use cases of noise reduction in the electrocardiogram (ECG) and the estimation of object motility. Results: For ECG denoising, the proposed method achieved an improvement in Signal-to-Noise ratio of 18.6 dB, which is comparable to state-of-the-art. In motility estimation, a correlation of 0.84 with ground truth simulations was found. Conclusion: The proposed method was shown to have advantages over sparse coding and Kalman filtering alone. Due to the low complexity and high generalizability of the proposed method, the implementation of context-specific knowledge or an extension to other applications can be readily made. Significance: The presented Kalman-ISTA algorithm is a resource-efficient method combining the promise of both sparse coding and Kalman filtering, making it well-suited for various applications. Medicine, Computer Science, Medicine, Computer Science, Engineering"
        ],
        [
         "28",
         " A. M. Seid",
         "Author: A. M. Seid.\n Abstract: Although vertical federated learning (VFL) has become a new paradigm of distributed machine learning for emerging multiparty joint modeling applications, how to effectively incentivize self-conscious clients to actively and reliably contribute to collaborative learning in VFL has become a critical issue. Existing efforts are inadequate to address this issue since the training sample size needs to be unified before model training in VFL. To this end, selfish clients should unconditionally and honestly declare their private information, such as model training costs and benefits. However, such an assumption is unrealistic. In this article, we develop the first Truthful incEntive mechAnism for VFL, <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbb {TEA}$ </tex-math></inline-formula>, to handle both information self-disclosure and social utility maximization. Specifically, we design a transfer payment rule via internalizing externalities, which bundles the clients’ utilities with the social utility, making truthful reporting by clients be a Nash equilibrium. Theoretically, we prove that <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbb {TEA}$ </tex-math></inline-formula> can achieve truthfulness and social utility maximization, as well as budget balance (BB) or individual rationality (IR). On this basis, we further design a sample size decision rule via linear programming (LP) relaxation to meet the requirements of different scenarios. Finally, extensive experiments on synthetic and real-world datasets validate the theoretical properties of <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbb {TEA}$ </tex-math></inline-formula> and demonstrate its superiority compared with the state-of-the-art. Computer Science, Computer Science"
        ],
        [
         "29",
         " A. Magner",
         "Author: A. Magner.\n Abstract: Sparse dictionary coding represents signals as linear combinations of a few dictionary atoms. It has been applied to images, time series, graph signals and multi-way spatio-temporal data by jointly employing temporal and spatial dictionaries. Data-agnostic analytical dictionaries, such as the discrete Fourier transform, wavelets and graph Fourier, have seen wide adoption due to efficient implementations and good practical performance. On the other hand, dictionaries learned from data offer sparser and more accurate solutions but require learning of both the dictionaries and the coding coefficients. This becomes especially challenging for multi-dictionary scenarios since encoding coefficients correspond to all atom combinations from the dictionaries. To address this challenge, we propose a low-rank coding model for 2-dictionary scenarios and study its data complexity. Namely, we establish a bound on the number of samples needed to learn dictionaries that generalize to unseen samples from the same distribution. We propose a convex relaxation solution, called AODL, whose exact solution we show also solves the original problem. We then solve this relaxation via alternating optimization between the sparse coding matrices and the learned dictionaries, which we prove to be convergent. We demonstrate its quality for data reconstruction and missing value imputation in both synthetic and real-world datasets. For a fixed reconstruction quality, AODL learns up to 90\\% sparser solutions compared to non-low-rank and analytical (fixed) dictionary baselines. In addition, the learned dictionaries reveal interpretable insights into patterns present within the samples used for training. Computer Science, Computer Science"
        ],
        [
         "30",
         " A. Majumdar",
         "Author: A. Majumdar.\n Abstract: Acoustic signals are considered as one of the vital and early indicators of machine health. However, an observed acoustic signal acquired in industrial setting is highly corrupted by the interference and background noise. To address this problem, in this letter, we present a novel two-stage technique for acoustic-based machine anomaly detection. In the first stage, beamforming is employed for source separation at a coarser level. Subsequently, pretrained dictionaries are used to estimate the individual source signals from the mixed signal. Once the sources are separated, a simple template matching approach is used to detect machine anomalies in the second stage. Performance evaluation is done using a publicly available malfunctioning industrial machine investigation and inspection dataset that contains the machine sounds from different industrial machines. The results clearly indicate the efficacy of the proposed two-stage method for machine anomaly detection, compared with other signal processing and deep learning techniques. Engineering, Computer Science"
        ],
        [
         "31",
         " A. Makhdoumi",
         "Author: A. Makhdoumi.\n Abstract: We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968 Computer Science, Computer Science, Economics"
        ],
        [
         "32",
         " A. Mali",
         "Author: A. Mali.\n Abstract: In this article, we propose a backpropagation-free approach to robotic control through the neuro-cognitive computational framework of neural generative coding (NGC), designing an agent completely built from predictive processing circuits that facilitate dynamic, online learning from sparse rewards, embodying the principles of planning-as-inference. Concretely, we craft an adaptive agent system, which we call active predictive coding (ActPC), that balances an internally-generated epistemic signal (meant to encourage intelligent exploration) with an internally-generated instrumental signal (meant to encourage goal-seeking behavior) to learn how to control various simulated robotic systems as well as a complex robotic arm using a realistic simulator, i.e., the Surreal Robotics Suite, for the block lifting task and the can pick-and-place problem. Notably, our results demonstrate that the proposed ActPC agent performs well in the face of sparse (extrinsic) reward signals and is competitive with or outperforms several powerful backpropagation-based reinforcement learning approaches. Computer Science, Computer Science, Engineering Author: A. Mali.\n Abstract: In this article, we propose a backpropagation-free approach to robotic control through the neuro-cognitive computational framework of neural generative coding (NGC), designing an agent built completely from powerful predictive coding/processing circuits that facilitate dynamic, online learning from sparse rewards, embodying the principles of planning-as-inference. Concretely, we craft an adaptive agent system, which we call active predictive coding (ActPC), that balances an internally-generated epistemic signal (meant to encourage intelligent exploration) with an internally-generated instrumental signal (meant to encourage goal-seeking behavior) to ultimately learn how to control various simulated robotic systems as well as a complex robotic arm using a realistic robotics simulator, i.e., the Surreal Robotics Suite, for the block lifting task and can pick-and-place problems. Notably, our experimental results demonstrate that our proposed ActPC agent performs well in the face of sparse (extrinsic) reward signals and is competitive with or outperforms several powerful backprop-based RL approaches. Computer Science, Computer Science"
        ],
        [
         "33",
         " A. Mamageishvili",
         "Author: A. Mamageishvili.\n Abstract: We show that in the single-parameter mechanism design environment, the only non-wasteful, symmetric, incentive compatible and Sybil-proof direct mechanism is a second price auction with symmetric tie-breaking. Thus, if there is private information, lotteries or other mechanisms that do not always allocate to a highest-value bidder are not Sybil-proof or not incentive compatible. Moreover, we show that our main (im)possibility result extends beyond linear valuations, but not to multi-unit object allocation with capacity constrained bidders. We also provide examples of mechanisms (with higher interim payoff for the bidders than a second price auction) that satisfy all of the other axioms and a weaker, Bayesian notion of Sybil-proofness. Thus, our (im)possibility result does not generalize to the Bayesian setting and we have a larger design space: With Sybil constraints, equivalence between dominant strategy and Bayesian implementation (that holds in classical single-parameter mechanism design without Sybils) no longer holds. Computer Science, Economics"
        ],
        [
         "34",
         " A. Mandpura",
         "Author: A. Mandpura.\n Abstract: In seismic data processing, denoising and reconstruction are the two steps for identification of resources in the earth subsurface layers. The seismic data quality is affected by random noise and interference during acquisition. Further, the noisy data may be incomplete with missing traces. In this work, we propose a method for incomplete seismic data denoising and reconstruction based on double sparsity dictionary learning (DSDL) with structure oriented filtering (SOF). The main function of the DSDL step is denoising and SOF is used for residual noise attenuation and filling the missing data points. The proposed method is tested on 2-D synthetic and field datasets. The test results show that the DSDL-SOF method has better noise attenuation and reconstruction in terms of signal-to-noise ratio and mean squared error as compared to existing methods. Computer Science, Engineering, Geology"
        ],
        [
         "35",
         " A. Manning",
         "Author: A. Manning.\n Abstract: nan Medicine, Medicine, Biology"
        ],
        [
         "36",
         " A. Maté",
         "Author: A. Maté.\n Abstract: Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the application of LLMs across a wide range of contexts. However, neural networks in general, and LLMs in particular, are known to be vulnerable to adversarial attacks, where an imperceptible change to the input can mislead the output of the model. This is a serious concern that impedes the use of LLMs on high-stakes applications, such as healthcare, where a wrong prediction can imply serious consequences. Even though there are many efforts on making LLMs more robust to adversarial attacks, there are almost no works that study how and where these vulnerabilities that make LLMs prone to adversarial attacks happen. Motivated by these facts, we explore how to localize and understand vulnerabilities, and propose a method, based on Mechanistic Interpretability (MI) techniques, to guide this process. Specifically, this method enables us to detect vulnerabilities related to a concrete task by (i) obtaining the subset of the model that is responsible for that task, (ii) generating adversarial samples for that task, and (iii) using MI techniques together with the previous samples to discover and understand the possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small model carrying out the task of predicting 3-letter acronyms to demonstrate its effectiveness on locating and understanding concrete vulnerabilities of the model. Computer Science, Computer Science"
        ],
        [
         "37",
         " A. Mazarguil",
         "Author: A. Mazarguil.\n Abstract: In this article, we introduce a method inspired by Graph Signal Processing (GSP) for the analysis of human motion based on the 3D positions of skeletal joints. Our approach uses a graph dictionary learning technique, in which each velocity sample is decomposed into a linear combination of a limited set of atoms acquired directly from the data. The efficacy of this methodology is evaluated using a dataset focused on upper limb elevations. We present features and visualizations, and validate the robustness of the approach through the construction of inter-and intra-subject distances. The features are also used as inputs for Human Activity Recognition with competitive results. The interpretability of the features and visualizations obtained from this method make it suitable for applications such as inter-individual comparisons or longitudinal follow-up of patients. Medicine, Computer Science, Computer Science, Engineering"
        ],
        [
         "38",
         " A. Mian",
         "Author: A. Mian.\n Abstract: In this article, we propose two algorithms to enhance the interpretability of the hyperbola in B-scans obtained with a ground penetrating radar (GPR). These hyperbolas are the responses of buried objects or cavities. To correctly detect and classify them, denoising is typically necessary for GPR images as the signal-to-noise ratio (SNR) is low, and the various interfaces naturally present in the Earth have a strong response. Both algorithms are based on a sparse convolutional coding model plus a low-rank component. It is solved through an alternating direction method of multipliers (ADMM) framework. In order to take into account the presence of outliers and the artifacts caused by the acquisition, the second algorithm is based on the Huber norm instead of the classic $L_{2}$ -norm. These algorithms are tested on a real dataset labeled by geophysicists. The results show the denoising efficiency of this approach, and in particular the robustness of the second algorithm. Computer Science, Engineering, Environmental Science, Computer Science"
        ],
        [
         "39",
         " A. Morrison",
         "Author: A. Morrison.\n Abstract: Simulations of neural activity at different levels of detail are ubiquitous in modern neurosciences, aiding the interpretation of experimental data and underlying neural mechanisms at the level of cells and circuits. Extracellular measurements of brain signals reflecting transmembrane currents throughout the neural tissue remain commonplace. The lower frequencies (≲ 300Hz) of measured signals generally stem from synaptic activity driven by recurrent interactions among neural populations and computational models should also incorporate accurate predictions of such signals. Due to limited computational resources, large-scale neuronal network models (≳ 106 neurons or so) often require reducing the level of biophysical detail and account mainly for times of action potentials (‘spikes’) or spike rates. Corresponding extracellular signal predictions have thus poorly accounted for their biophysical origin. Here we propose a computational framework for predicting spatiotemporal filter kernels for such extracellular signals stemming from synaptic activity, accounting for the biophysics of neurons, populations, and recurrent connections. Signals are obtained by convolving population spike rates by appropriate kernels for each connection pathway and summing the contributions. Our main results are that kernels derived via linearized synapse and membrane dynamics, distributions of cells, conduction delay, and volume conductor model allow for accurately capturing the spatiotemporal dynamics of ground truth extracellular signals from conductance-based multicompartment neuron networks. One particular observation is that changes in the effective membrane time constants caused by persistent synapse activation must be accounted for. The work also constitutes a major advance in computational efficacy of accurate, biophysics-based signal predictions from large-scale spike and rate-based neuron network models drastically reducing signal prediction times compared to biophysically detailed network models. This work also provides insight into how experimentally recorded low-frequency extracellular signals of neuronal activity may be approximately linearly dependent on spiking activity. A new software tool LFPykernels serves as a reference implementation of the framework. Author summary Understanding the brain’s function and activity in healthy and pathological states across spatial scales and times spanning entire lives is one of humanity’s great undertakings. In experimental and clinical work probing the brain’s activity, a variety of electric and magnetic measurement techniques are routinely applied. However interpreting the extracellularly measured signals remains arduous due to multiple factors, mainly the large number of neurons contributing to the signals and complex interactions occurring in recurrently connected neuronal circuits. To understand how neurons give rise to such signals, mechanistic modeling combined with forward models derived using volume conductor theory has proven to be successful, but this approach currently does not scale to the systems level (encompassing millions of neurons or more) where simplified or abstract neuron representations typically are used. Motivated by experimental findings implying approximately linear relationships between times of neuronal action potentials and extracellular population signals, we provide a biophysics-based method for computing causal filters relating spikes and extracellular signals that can be applied with spike times or rates of large-scale neuronal network models for predictions of population signals without relying on ad hoc approximations. Computer Science, Medicine, Biology, Computer Science"
        ],
        [
         "40",
         " A. Nayyar",
         "Author: A. Nayyar.\n Abstract: In this article, we consider the problem of designing an expected-revenue-maximizing mechanism for allocating multiple nonperishable goods of $k$ varieties to flexible consumers over $T$ time steps. In our model, a random number of goods of each variety may become available to the seller at each time, and a random number of consumers may enter the market at each time. Each consumer is present in the market for one time step and wants to consume one good of one of its desired varieties. Each consumer is associated with a flexibility level that indicates the varieties of goods it is equally interested in. A consumer’s flexibility level and the utility it gets from consuming a good of its desired varieties are its private information. We characterize the allocation rule for a Bayesian-incentive-compatible, individually rational, and expected-revenue-maximizing mechanism in terms of the solution to a dynamic program. The corresponding payment function is also specified in terms of the optimal allocation function. We leverage the structure of the consumers’ flexibility model to simplify the dynamic program. Our simplified dynamic program allows us to provide an explicit allocation procedure and a simple payment rule in terms of the solution of the dynamic program. Computer Science, Engineering, Economics"
        ],
        [
         "41",
         " A. Nieder",
         "Author: A. Nieder.\n Abstract: nan Biology, Biology"
        ],
        [
         "42",
         " A. Odisho",
         "Author: A. Odisho.\n Abstract: Automated mechanistic interpretation research has attracted great interest due to its potential to scale explanations of neural network internals to large models. Existing automated circuit discovery work relies on activation patching or its approximations to identify subgraphs in models for specific tasks (circuits). They often suffer from slow runtime, approximation errors, and specific requirements of metrics, such as non-zero gradients. In this work, we introduce contextual decomposition for transformers (CD-T) to build interpretable circuits in large language models. CD-T can produce circuits of arbitrary level of abstraction, and is the first able to produce circuits as fine-grained as attention heads at specific sequence positions efficiently. CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning, we are able to reduce circuit discovery runtime from hours to seconds compared to state-of-the-art baselines. On three standard circuit evaluation datasets (indirect object identification, greater-than comparisons, and docstring completion), we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes. In addition, we provide evidence that faithfulness of CD-T circuits is not due to random chance by showing our circuits are 80% more faithful than random circuits of up to 60% of the original model size. Finally, we show CD-T circuits are able to perfectly replicate original models' behavior (faithfulness $ = 1$) using fewer nodes than the baselines for all tasks. Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability, paving the way for new insights into the workings of large language models. Computer Science, Computer Science, Engineering"
        ],
        [
         "43",
         " A. Ozdaglar",
         "Author: A. Ozdaglar.\n Abstract: We consider a platform's problem of collecting data from privacy sensitive users to estimate an underlying parameter of interest. We formulate this question as a Bayesian-optimal mechanism design problem, in which an individual can share her (verifiable) data in exchange for a monetary reward or services, but at the same time has a (private) heterogeneous privacy cost which we quantify using differential privacy. We consider two popular differential privacy settings for providing privacy guarantees for the users: central and local. In both settings, we establish minimax lower bounds for the estimation error and derive (near) optimal estimators for given heterogeneous privacy loss levels for users. Building on this characterization, we pose the mechanism design problem as the optimal selection of an estimator and payments that will elicit truthful reporting of users' privacy sensitivities. Under a regularity condition on the distribution of privacy sensitivities we develop efficient algorithmic mechanisms to solve this problem in both privacy settings. Our mechanism in the central setting can be implemented in time O (n log n) where n is the number of users and our mechanism in the local setting admits a Polynomial Time Approximation Scheme (PTAS). The full paper is available at: https://arxiv.org/abs/2201.03968 Computer Science, Computer Science, Economics"
        ],
        [
         "44",
         " A. Pal",
         "Author: A. Pal.\n Abstract: nan Computer Science, Computer Science"
        ],
        [
         "45",
         " A. Pižurica",
         "Author: A. Pižurica.\n Abstract: nan Engineering, Computer Science, Mathematics"
        ],
        [
         "46",
         " A. Plaat",
         "Author: A. Plaat.\n Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on multi-step tasks, yet whether the generated\"thoughts\"reflect the true internal reasoning process is unresolved. We present the first feature-level causal study of CoT faithfulness. Combining sparse autoencoders with activation patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B while they tackle GSM8K math problems under CoT and plain (noCoT) prompting. Swapping a small set of CoT-reasoning features into a noCoT run raises answer log-probabilities significantly in the 2.8B model, but has no reliable effect in 70M, revealing a clear scale threshold. CoT also leads to significantly higher activation sparsity and feature interpretability scores in the larger model, signalling more modular internal computation. For example, the model's confidence in generating correct answers improves from 1.2 to 4.3. We introduce patch-curves and random-feature patching baselines, showing that useful CoT information is not only present in the top-K patches but widely distributed. Overall, our results indicate that CoT can induce more interpretable internal structures in high-capacity LLMs, validating its role as a structured prompting method. Computer Science, Computer Science"
        ],
        [
         "47",
         " A. Plaza",
         "Author: A. Plaza.\n Abstract: Subspace learning has been widely applied for feature extraction of hyperspectral images (HSIs) and achieved great success. However, the current methods still leave two problems that need to be further investigated. First, those methods mainly focus on finding one or multiple projection matrices for mapping the high-dimensional data into a low-dimensional subspace, which can only capture the information from each direction of high-order hyperspectral data separately. Second, the performance of feature extraction is barely satisfactory when the hyperspectral data is severely corrupted by noise. To address these issues, this article presents a t-linear tensor subspace learning (tLTSL) model for robust feature extraction of HSIs based on t-product projection. In the model, t-product projection is a new defined tensor transformation way similar to linear transformation in vector space, which can maximally capture the intrinsic structure of tensor data. The integrated tensor low-rank and sparse decomposition can effectively remove the noise corruption and the learned t-product projection can directly transform the high-order hyperspectral data into a subspace with information from all modes comprehensively considered. Moreover, a proposition related to tensor rank is proofed for interpreting the meaning of the tLTSL model. Extensive experiments are conducted on two different kinds of noise (i.e., simulated and real noise) corrupted HSI data, which validate the effectiveness of tLTSL. Computer Science, Environmental Science, Computer Science, Engineering"
        ],
        [
         "48",
         " A. Poznyak",
         "Author: A. Poznyak.\n Abstract: A theme that become common knowledge of the literature is the difficulty of developing a mechanism that is compatible with individual incentives that simultaneously result in efficient decisions that maximize the total reward. In this paper, we suggest an analytical method for computing a mechanism design. This problem is explored in the context of a framework, in which the players follow an average utility in a non-cooperative Markov game with incomplete state information. All of the Nash equilibria are approximated in a sequential process. We describe a method for the derivative of the player’s equilibrium that instruments the design of the mechanism. In addition, it showed the convergence and rate of convergence of the proposed method. For computing the mechanism, we consider an extension of the Markov model for which it is introduced a new variable that represents the product of the mechanism design and the joint strategy. We derive formulas to recover the variables of interest: mechanisms, strategy, and distribution vector. The mechanism design and equilibrium strategies computation differ from those in previous literature. A numerical example presents the usefulness and effectiveness of the proposed method. Computer Science, Economics, Mathematics, Computer Science"
        ],
        [
         "49",
         " A. Routray",
         "Author: A. Routray.\n Abstract: Multi-modal image fusion (MMIF) enhances the information content of the fused image by combining the unique as well as common features obtained from different modality sensor images, improving visualization, object detection, and many more tasks. In this work, we introduce an interpretable network for the MMIF task, named FNet, based on an l0-regularized multi-modal convolutional sparse coding (MCSC) model. Specifically, for solving the l0-regularized CSC problem, we develop an algorithm unrolling-based l0-regularized sparse coding (LZSC) block. Given different modality source images, FNet first separates the unique and common features from them using the LZSC block and then these features are combined to generate the final fused image. Additionally, we propose an l0-regularized MCSC model for the inverse fusion process. Based on this model, we introduce an interpretable inverse fusion network named IFNet, which is utilized during FNet's training. Extensive experiments show that FNet achieves high-quality fusion results across five different MMIF tasks. Furthermore, we show that FNet enhances downstream object detection in visible-thermal image pairs. We have also visualized the intermediate results of FNet, which demonstrates the good interpretability of our network. Computer Science, Computer Science, Engineering"
        ],
        [
         "50",
         " A. Sarsenbekova",
         "Author: A. Sarsenbekova.\n Abstract: This research presents the results of a combined numerical and experimental study of the thermal decomposition behavior of copolymers based on polypropylene glycol fumarate phthalate. The thermal decomposition of polymers plays a key role in various fields, such as waste recycling and energy recovery, and in the development of new materials. The objective of this study is to model the degradation kinetics using thermogravimetric data, matrix-based numerical methods, and quantum chemical calculations. To solve the resulting systems of linear algebraic equations (SLAEs), matrix decomposition algorithms (QR, SVD, and Cholesky) were employed, which enabled the determination of activation energy values for the process. Comparison of the activation energy (Ea) results obtained using the decomposition method of Cholesky (207.21 kJ/mol), normal equations (205.22 kJ/mol), singular value decomposition (206.23 kJ/mol), and QR decomposition (206.23 kJ/mol) showed minor changes that were associated with the features of each method. Quantum chemical calculations based on density functional theory (DFT) at the B3LYP/6-31G(d) level were performed to analyze the molecular structure and interpret the IR spectra. This study establishes that the content of functional groups (ether and ester) and the type of chemical bonds exert critical influences on the decomposition mechanism and associated thermal parameters. The results confirm that the polymer’s structural architecture governs its thermal stability. The scientific novelty of this work lies in the integration of numerical approximation methods and quantum chemical analysis for investigating the thermal behavior of polymers. This approach is applied for the first time to copolymers of this composition and may be employed in the design of heat-resistant materials for agricultural and environmental applications. Medicine, Mathematics, Materials Science"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3116
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_list</th>\n",
       "      <th>author_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Alhassan</td>\n",
       "      <td>Author: A. Alhassan.\\n Abstract: The Board pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Arafa</td>\n",
       "      <td>Author: A. Arafa.\\n Abstract: Mathematical sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. B. Sagingalieva</td>\n",
       "      <td>Author: A. B. Sagingalieva.\\n Abstract: Quantu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Banerjee</td>\n",
       "      <td>Author: A. Banerjee.\\n Abstract: Recent years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A. Barbeira</td>\n",
       "      <td>Author: A. Barbeira.\\n Abstract: Genetic regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>Zishuo Zhao</td>\n",
       "      <td>Author:Zishuo Zhao.\\n Abstract: The security o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>Ziyang Lou</td>\n",
       "      <td>Author:Ziyang Lou.\\n Abstract: Despite rapid a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>Zou Fan</td>\n",
       "      <td>Author:Zou Fan.\\n Abstract: Bearing fault diag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>Zuozhi Liu</td>\n",
       "      <td>Author:Zuozhi Liu.\\n Abstract: The detection o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>nan</td>\n",
       "      <td>Author:nan.\\n Abstract: nan Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3116 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             authors_list                                        author_info\n",
       "1             A. Alhassan  Author: A. Alhassan.\\n Abstract: The Board pla...\n",
       "2                A. Arafa  Author: A. Arafa.\\n Abstract: Mathematical sim...\n",
       "3      A. B. Sagingalieva  Author: A. B. Sagingalieva.\\n Abstract: Quantu...\n",
       "4             A. Banerjee  Author: A. Banerjee.\\n Abstract: Recent years ...\n",
       "5             A. Barbeira  Author: A. Barbeira.\\n Abstract: Genetic regul...\n",
       "...                   ...                                                ...\n",
       "3112          Zishuo Zhao  Author:Zishuo Zhao.\\n Abstract: The security o...\n",
       "3113           Ziyang Lou  Author:Ziyang Lou.\\n Abstract: Despite rapid a...\n",
       "3114              Zou Fan  Author:Zou Fan.\\n Abstract: Bearing fault diag...\n",
       "3115           Zuozhi Liu  Author:Zuozhi Liu.\\n Abstract: The detection o...\n",
       "3116                  nan            Author:nan.\\n Abstract: nan Mathematics\n",
       "\n",
       "[3116 rows x 2 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_authors_df_for_emb = unique_authors_df_for_emb[unique_authors_df_for_emb['authors_list'] != '']\n",
    "unique_authors_df_for_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc4f3f0",
   "metadata": {},
   "source": [
    "E5 large is a widely used embedding model with great performance across different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "54765093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0b5ec742",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_data_list = lesswrong_df_for_emb['usr_info'].tolist()\n",
    "semantic_data_list = unique_authors_df_for_emb['author_info'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "12c1fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_data_embeddings = model.encode(lw_data_list)\n",
    "semantic_data_embeddings = model.encode(lw_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a242bd8",
   "metadata": {},
   "source": [
    "Both authors from lesswrong and semantic scholar are encoded and compared using similtarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "88b4b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing semantic search to find matches...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lesswrong_user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matched_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d3bcf60f-585d-4c82-b1fd-337eaf9d16ff",
       "rows": [
        [
         "0",
         "Eliezer_Yudkowsky",
         " A. Alhassan",
         "1.0"
        ],
        [
         "1",
         "Eliezer_Yudkowsky",
         " A. Grillo",
         "0.8828"
        ],
        [
         "2",
         "Eliezer_Yudkowsky",
         " A. Froemelt",
         "0.8679"
        ],
        [
         "3",
         "Eliezer_Yudkowsky",
         " A. Hobolth",
         "0.8429"
        ],
        [
         "4",
         "Eliezer_Yudkowsky",
         " A. Darzi",
         "0.8422"
        ],
        [
         "5",
         "Raemon",
         " A. Arafa",
         "1.0"
        ],
        [
         "6",
         "Raemon",
         " A. Hobolth",
         "0.8519"
        ],
        [
         "7",
         "Raemon",
         " A. Cherif",
         "0.8507"
        ],
        [
         "8",
         "Raemon",
         " A. Guergachi",
         "0.85"
        ],
        [
         "9",
         "Raemon",
         " A. Frigessi",
         "0.8479"
        ],
        [
         "10",
         "Zvi",
         " A. B. Sagingalieva",
         "1.0"
        ],
        [
         "11",
         "Zvi",
         " A. Endert",
         "0.9043"
        ],
        [
         "12",
         "Zvi",
         " A. Darzi",
         "0.8859"
        ],
        [
         "13",
         "Zvi",
         " A. Grillo",
         "0.8726"
        ],
        [
         "14",
         "Zvi",
         " A. Battle",
         "0.8598"
        ],
        [
         "15",
         "RobbBB",
         " A. Banerjee",
         "1.0"
        ],
        [
         "16",
         "RobbBB",
         " A. Hobolth",
         "0.8325"
        ],
        [
         "17",
         "RobbBB",
         " A. Alhassan",
         "0.8288"
        ],
        [
         "18",
         "RobbBB",
         " A. Grillo",
         "0.8274"
        ],
        [
         "19",
         "RobbBB",
         " A. D. Blackwell",
         "0.8265"
        ],
        [
         "20",
         "ryan_greenblatt",
         " A. Barbeira",
         "1.0"
        ],
        [
         "21",
         "ryan_greenblatt",
         " A. Cherif",
         "0.8605"
        ],
        [
         "22",
         "ryan_greenblatt",
         " A. Darzi",
         "0.8492"
        ],
        [
         "23",
         "ryan_greenblatt",
         " A. Endert",
         "0.8476"
        ],
        [
         "24",
         "ryan_greenblatt",
         " A. B. Sagingalieva",
         "0.8413"
        ],
        [
         "25",
         "ricraz",
         " A. Battle",
         "1.0"
        ],
        [
         "26",
         "ricraz",
         " A. Endert",
         "0.876"
        ],
        [
         "27",
         "ricraz",
         " A. B. Sagingalieva",
         "0.8598"
        ],
        [
         "28",
         "ricraz",
         " A. Grillo",
         "0.8504"
        ],
        [
         "29",
         "ricraz",
         " A. Barbeira",
         "0.8405"
        ],
        [
         "30",
         "lsusr",
         " A. Bentbib",
         "1.0"
        ],
        [
         "31",
         "lsusr",
         " A. Elshekhipy",
         "0.857"
        ],
        [
         "32",
         "lsusr",
         " A. Hafiane",
         "0.857"
        ],
        [
         "33",
         "lsusr",
         " A. Bloch",
         "0.8514"
        ],
        [
         "34",
         "lsusr",
         " A. Frigessi",
         "0.8404"
        ],
        [
         "35",
         "orthonormal",
         " A. Bloch",
         "1.0"
        ],
        [
         "36",
         "orthonormal",
         " A. Hafiane",
         "0.9318"
        ],
        [
         "37",
         "orthonormal",
         " A. Elshekhipy",
         "0.9225"
        ],
        [
         "38",
         "orthonormal",
         " A. Endert",
         "0.8656"
        ],
        [
         "39",
         "orthonormal",
         " A. Frigessi",
         "0.8545"
        ],
        [
         "40",
         "evhub",
         " A. Catarino",
         "1.0"
        ],
        [
         "41",
         "evhub",
         " A. Guergachi",
         "0.8923"
        ],
        [
         "42",
         "evhub",
         " A. Hobolth",
         "0.8807"
        ],
        [
         "43",
         "evhub",
         " A. Frigessi",
         "0.8649"
        ],
        [
         "44",
         "evhub",
         " A. Cherif",
         "0.8494"
        ],
        [
         "45",
         "Buck",
         " A. Cherif",
         "1.0"
        ],
        [
         "46",
         "Buck",
         " A. Guergachi",
         "0.8774"
        ],
        [
         "47",
         "Buck",
         " A. Barbeira",
         "0.8605"
        ],
        [
         "48",
         "Buck",
         " A. Arafa",
         "0.8507"
        ],
        [
         "49",
         "Buck",
         " A. Catarino",
         "0.8494"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesswrong_user</th>\n",
       "      <th>matched_author</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>A. Alhassan</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>A. Grillo</td>\n",
       "      <td>0.8828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>A. Froemelt</td>\n",
       "      <td>0.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>A. Hobolth</td>\n",
       "      <td>0.8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eliezer_Yudkowsky</td>\n",
       "      <td>A. Darzi</td>\n",
       "      <td>0.8422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>A. Hobolth</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>A. Catarino</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>A. Guergachi</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>A. Arafa</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>thomas-kwa</td>\n",
       "      <td>A. Frigessi</td>\n",
       "      <td>0.8517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesswrong_user matched_author  similarity_score\n",
       "0   Eliezer_Yudkowsky    A. Alhassan            1.0000\n",
       "1   Eliezer_Yudkowsky      A. Grillo            0.8828\n",
       "2   Eliezer_Yudkowsky    A. Froemelt            0.8679\n",
       "3   Eliezer_Yudkowsky     A. Hobolth            0.8429\n",
       "4   Eliezer_Yudkowsky       A. Darzi            0.8422\n",
       "..                ...            ...               ...\n",
       "95         thomas-kwa     A. Hobolth            1.0000\n",
       "96         thomas-kwa    A. Catarino            0.8807\n",
       "97         thomas-kwa   A. Guergachi            0.8600\n",
       "98         thomas-kwa       A. Arafa            0.8519\n",
       "99         thomas-kwa    A. Frigessi            0.8517\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 5 most similar authors for each LessWrong user\n",
    "print(\"\\nPerforming semantic search to find matches...\")\n",
    "search_results = util.semantic_search(lw_data_embeddings, semantic_data_embeddings, top_k=5)\n",
    "\n",
    "# --- Process the results into a clean DataFrame ---\n",
    "\n",
    "results_list = []\n",
    "# The search_results list corresponds to each user in your original lw_data_list\n",
    "for i, user_hits in enumerate(search_results):\n",
    "    # Get the username from your original dataframe\n",
    "    username = lesswrong_df_for_emb.iloc[i]['username']\n",
    "    \n",
    "    # Each 'user_hits' contains the top matches for that user\n",
    "    for hit in user_hits:\n",
    "        # 'corpus_id' is the index of the matching author in your semantic_data_list\n",
    "        author_name = unique_authors_df_for_emb.iloc[hit['corpus_id']]['authors_list']\n",
    "        score = hit['score']\n",
    "        \n",
    "        results_list.append({\n",
    "            'lesswrong_user': username,\n",
    "            'matched_author': author_name,\n",
    "            'similarity_score': round(score, 4)\n",
    "        })\n",
    "\n",
    "# Create the final DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f68c7b",
   "metadata": {},
   "source": [
    "Embedding results seem to be a wrong, maybe the methology is not adequate enough to process it,\n",
    "For now Id suggest re-trying and evaluate using more data from both sources and adding an hybrid search (first fuzzy then embeddings) approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
